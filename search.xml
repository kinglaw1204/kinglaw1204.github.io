<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Spring Boot中的事务是如何实现的</title>
      <link href="/2020/03/28/spring-boot-transaction/"/>
      <url>/2020/03/28/spring-boot-transaction/</url>
      
        <content type="html"><![CDATA[<p><img src="https://cdn.pixabay.com/photo/2020/03/18/06/06/street-4942809_1280.jpg" alt=""></p><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>一直在用SpringBoot中的<code>@Transactional</code>来做事务管理，但是很少没想过SpringBoot是如何实现事务管理的，今天从源码入手，看看<code>@Transactional</code>是如何实现事务的，最后我们结合源码的理解，自己动手写一个类似的注解来实现事务管理，帮助我们加深理解。</p><blockquote><p>阅读说明：本文假设你具备Java基础，同时对事务有基本的了解和使用。</p></blockquote><h2 id="事务的相关知识"><a href="#事务的相关知识" class="headerlink" title="事务的相关知识"></a>事务的相关知识</h2><p>开始看源码之前，我们先回顾下事务的相关知识。</p><h3 id="事务的隔离级别"><a href="#事务的隔离级别" class="headerlink" title="事务的隔离级别"></a>事务的隔离级别</h3><p>事务为什么需要隔离级别呢？这是因为在并发事务情况下，如果没有隔离级别会导致如下问题：</p><ul><li><p><strong>脏读(Dirty Read)</strong> ：当A事务对数据进行修改，但是这种修改还没有提交到数据库中，B事务同时在访问这个数据，由于没有隔离，B获取的数据有可能被A事务回滚，这就导致了数据不一致的问题。</p></li><li><p><strong>丢失修改(Lost To Modify)</strong>: 当A事务访问数据100，并且修改为100-1=99，同时B事务读取数据也是100，修改数据100-1=99，最终两个事务的修改结果为99，但是实际是98。事务A修改的数据被丢失了。</p></li><li><p><strong>不可重复读(Unrepeatable Read)</strong>：指A事务在读取数据X=100的时候，B事务把数据X=100修改为X=200,这个时候A事务第二次读取数据X的时候，发现X=200了，导致了在整个A事务期间，两次读取数据X不一致了，这就是不可重复读。</p></li><li><p><strong>幻读(Phantom Read)</strong>：幻读和不可重复读类似。幻读表现在，当A事务读取表数据时候，只有3条数据，这个时候B事务插入了2条数据，当A事务再次读取的时候，发现有5条记录了，平白无故多了2条记录，就像幻觉一样。</p></li></ul><p><strong>不可重复读 VS 幻读</strong></p><p>  <strong>不可重复读的重点是修改</strong> <strong>:</strong><br>  同样的条件 ,  你读取过的数据 ,  再次读取出来发现值不一样了，重点在更新操作。<br>  <strong>幻读的重点在于新增或者删除</strong><br>  同样的条件 ,  第 1 次和第 2 次读出来的记录数不一样，重点在增删操作。</p><p>所以，为了避免上述的问题，事务中就有了隔离级别的概念，在Spring中定义了五种表示隔离级别的常量：</p><table><thead><tr><th>常量</th><th>说明</th></tr></thead><tbody><tr><td>TransactionDefinition.ISOLATION_DEFAULT</td><td>数据库默认的隔离级别，MySQL默认采用的 REPEATABLE_READ隔离级别</td></tr><tr><td>TransactionDefinition.ISOLATION_READ_UNCOMMITTED</td><td>最低的隔离级别，允许读取未提交的数据变更，<strong>可能会导致脏读、幻读或不可重复读</strong>。</td></tr><tr><td>TransactionDefinition.ISOLATION_READ_COMMITTED</td><td>允许读取并发事务已经提交的数据，<strong>可以阻止脏读，但是幻读或不可重复读仍有可能发生</strong>。</td></tr><tr><td>TransactionDefinition.ISOLATION_REPEATABLE_READ</td><td>对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，<strong>可以阻止脏读和不可重复读，但幻读仍有可能发生。</strong>MySQL中通过MVCC解决了该隔离级别下出现幻读的可能。</td></tr><tr><td>TransactionDefinition.ISOLATION_SERIALIZABLE</td><td>串行化隔离级别，<strong>该级别可以防止脏读、不可重复读以及幻读</strong>，但是串行化会影响性能。</td></tr></tbody></table><h3 id="Spring中事务的传播机制"><a href="#Spring中事务的传播机制" class="headerlink" title="Spring中事务的传播机制"></a>Spring中事务的传播机制</h3><p>为什么Spring中要搞一套事务的传播机制呢？这是Spring给我们提供的事务增强工具，主要是解决方法之间调用，事务如何处理的问题。比如有方法A、方法B和方法C，在A中调用了方法B和方法C。伪代码如下：</p><pre><code>MethodA{    MethodB；    MethodC;}MethodB{}MethodC{}</code></pre><p>假设三个方法中都开启了自己的事务，那么他们之间是什么关系呢？<code>MethodA</code>的回滚会影响<code>MethodB</code>和<code>MethodC</code>吗？Spring中的事务传播机制就是解决这个问题的。</p><p>Spring中定义了七种事务传播行为：</p><table><thead><tr><th>类型</th><th>说明</th></tr></thead><tbody><tr><td>PROPAGATION_REQUIRED</td><td>如果当前没有事务，就新建一个事务，如果已经存在一个事务中，加入到这个事务中。这是最常见的选择</td></tr><tr><td>PROPAGATION_SUPPORTS</td><td>支持当前事务，如果当前没有事务，就以非事务方式执行。</td></tr><tr><td>PROPAGATION_MANDATORY</td><td>使用当前的事务，如果当前没有事务，就抛出异常。</td></tr><tr><td>PROPAGATION_REQUIRES_NEW</td><td>新建事务，如果当前存在事务，把当前事务挂起。</td></tr><tr><td>PROPAGATION_NOT_SUPPORTED</td><td>以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。</td></tr><tr><td>PROPAGATION_NEVER</td><td>以非事务方式执行，如果当前存在事务，则抛出异常。</td></tr><tr><td>PROPAGATION_NESTED</td><td>如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与PROPAGATION_REQUIRED类似的操作。</td></tr></tbody></table><p>这七种传播机制是如何影响事务的，感兴趣的同学可以阅读<a href="https://segmentfault.com/a/1190000013341344" target="_blank" rel="noopener">这篇文章</a>。</p><h2 id="如何实现异常回滚的"><a href="#如何实现异常回滚的" class="headerlink" title="如何实现异常回滚的"></a>如何实现异常回滚的</h2><p>回顾完了事务的相关知识，接下来我们正式来研究下Spring Boot中如何通过<code>@Transactional</code>来管理事务的，我们重点看看它是如何实现回滚的。</p><p>在Spring中<code>TransactionInterceptor</code>和<code>PlatformTransactionManager</code>这两个类是整个事务模块的核心，<code>TransactionInterceptor</code>负责拦截方法执行，进行判断是否需要提交或者回滚事务。<code>PlatformTransactionManager</code>是Spring 中的事务管理接口，真正定义了事务如何回滚和提交。我们重点研究下这两个类的源码。</p><p><code>TransactionInterceptor</code>类中的代码有很多，我简化一下逻辑，方便说明：</p><pre><code>    //以下代码省略部分内容    public Object invoke(MethodInvocation invocation) throws Throwable {    //获取事务调用的目标方法        Class&lt;?&gt; targetClass = (invocation.getThis() != null ? AopUtils.getTargetClass(invocation.getThis()) : null);    //执行带事务调用        return invokeWithinTransaction(invocation.getMethod(), targetClass, invocation::proceed);    }</code></pre><p>invokeWithinTransaction 简化逻辑如下：</p><pre><code>    //TransactionAspectSupport.class    //省略了部分代码    protected Object invokeWithinTransaction(Method method, @Nullable Class&lt;?&gt; targetClass,            final InvocationCallback invocation) throws Throwable {            Object retVal;            try {            //调用真正的方法体                retVal = invocation.proceedWithInvocation();            }            catch (Throwable ex) {                // 如果出现异常，执行事务异常处理                completeTransactionAfterThrowing(txInfo, ex);                throw ex;            }            finally {            //最后做一下清理工作，主要是缓存和状态等                cleanupTransactionInfo(txInfo);            }            //如果没有异常，直接提交事务。            commitTransactionAfterReturning(txInfo);            return retVal;    }</code></pre><p>事务出现异常回滚的逻辑<code>completeTransactionAfterThrowing</code>如下：</p><pre><code>//省略部分代码protected void completeTransactionAfterThrowing(@Nullable TransactionInfo txInfo, Throwable ex) {                //判断是否需要回滚，判断的逻辑就是看有没有声明事务属性，同时判断是不是在目前的这个异常中执行回滚。            if (txInfo.transactionAttribute != null &amp;&amp; txInfo.transactionAttribute.rollbackOn(ex)) {                //执行回滚                    txInfo.getTransactionManager().rollback(txInfo.getTransactionStatus());            }             else {                        //否则不需要回滚，直接提交即可。                    txInfo.getTransactionManager().commit(txInfo.getTransactionStatus());            }        }    }</code></pre><p>上面的代码已经把Spring的事务的基本原理说清楚了，如何进行判断执行事务，如何回滚。下面到了真正执行回滚逻辑的代码中<code>PlatformTransactionManager</code>接口的子类，我们以JDBC的事务为例，<code>DataSourceTransactionManager</code>就是jdbc的事务管理类。跟踪上面的代码<code>rollback(txInfo.getTransactionStatus())</code>可以发现最终执行的代码如下：</p><pre><code>@Override    protected void doRollback(DefaultTransactionStatus status) {        DataSourceTransactionObject txObject = (DataSourceTransactionObject) status.getTransaction();        Connection con = txObject.getConnectionHolder().getConnection();        if (status.isDebug()) {            logger.debug(&quot;Rolling back JDBC transaction on Connection [&quot; + con + &quot;]&quot;);        }        try {        //调用jdbc的 rollback进行回滚事务。            con.rollback();        }        catch (SQLException ex) {            throw new TransactionSystemException(&quot;Could not roll back JDBC transaction&quot;, ex);        }    }</code></pre><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>这里小结下Spring 中事务的实现思路，Spring 主要依靠 <code>TransactionInterceptor</code> 来拦截执行方法体，判断是否开启事务，然后执行事务方法体，方法体中<code>catch</code>住异常,接着判断是否需要回滚，如果需要回滚就委托真正的<code>TransactionManager</code> 比如JDBC中的<code>DataSourceTransactionManager</code>来执行回滚逻辑。提交事务也是同样的道理。</p><p>这里用个流程图展示下思路：</p><p><img src="https://s1.ax1x.com/2020/03/29/GV0aOx.png" alt="GV0aOx.png"></p><h2 id="手写一个注解实现事务回滚"><a href="#手写一个注解实现事务回滚" class="headerlink" title="手写一个注解实现事务回滚"></a>手写一个注解实现事务回滚</h2><p>我们弄清楚了Spring的事务执行流程，那我们可以模仿着自己写一个注解，实现遇到指定异常就回滚的功能。这里持久层就以最简单的JDBC为例。我们先梳理下需求，首先注解我们可以基于Spring 的AOP来实现，接着既然是JDBC,那么我们需要一个类来帮我们管理连接，用来判断异常是否回滚或者提交。梳理完就开干吧。</p><p><strong>首先加入依赖</strong></p><pre><code>             &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt;        &lt;/dependency&gt;</code></pre><p><strong>新增一个注解</strong></p><pre><code class="java">/** * @description: * @author: luozhou  * @create: 2020-03-29 17:05 **/@Target({ElementType.METHOD})@Retention(RetentionPolicy.RUNTIME)@Inherited@Documentedpublic @interface MyTransaction {    //指定异常回滚    Class&lt;? extends Throwable&gt;[] rollbackFor() default {};}</code></pre><p><strong>新增连接管理器</strong></p><p>该类帮助我们管理连接，该类的核心功能是把取出的连接对象绑定到线程上，方便在AOP处理中取出，进行提交或者回滚操作。</p><pre><code class="java">/** * @description: * @author: luozhou  * @create: 2020-03-29 21:14 **/@Componentpublic class DataSourceConnectHolder {    @Autowired    DataSource dataSource;    /**     * 线程绑定对象     */    ThreadLocal&lt;Connection&gt; resources = new NamedThreadLocal&lt;&gt;(&quot;Transactional resources&quot;);    public Connection getConnection() {        Connection con = resources.get();        if (con != null) {            return con;        }        try {            con = dataSource.getConnection();            //为了体现事务，全部设置为手动提交事务            con.setAutoCommit(false);        } catch (SQLException e) {            e.printStackTrace();        }        resources.set(con);        return con;    }    public void cleanHolder() {        Connection con = resources.get();        if (con != null) {            try {                con.close();            } catch (SQLException e) {                e.printStackTrace();            }        }        resources.remove();    }}</code></pre><p><strong>新增一个切面</strong></p><p>这部分是事务处理的核心，先获取注解上的异常类，然后捕获住执行的异常，判断异常是不是注解上的异常或者其子类，如果是就回滚，否则就提交。</p><pre><code class="java">/** * @description: * @author: luozhou  * @create: 2020-03-29 17:08 **/@Aspect@Componentpublic class MyTransactionAopHandler {    @Autowired    DataSourceConnectHolder connectHolder;    Class&lt;? extends Throwable&gt;[] es;    //拦截所有MyTransaction注解的方法    @org.aspectj.lang.annotation.Pointcut(&quot;@annotation(luozhou.top.annotion.MyTransaction)&quot;)    public void Transaction() {    }    @Around(&quot;Transaction()&quot;)    public Object TransactionProceed(ProceedingJoinPoint proceed) throws Throwable {        Object result = null;        Signature signature = proceed.getSignature();        MethodSignature methodSignature = (MethodSignature) signature;        Method method = methodSignature.getMethod();        if (method == null) {            return result;        }        MyTransaction transaction = method.getAnnotation(MyTransaction.class);        if (transaction != null) {            es = transaction.rollbackFor();        }        try {            result = proceed.proceed();        } catch (Throwable throwable) {            //异常处理            completeTransactionAfterThrowing(throwable);            throw throwable;        }        //直接提交        doCommit();        return result;    }        /**        * 执行回滚，最后关闭连接和清理线程绑定        */    private void doRollBack() {        try {            connectHolder.getConnection().rollback();        } catch (SQLException e) {            e.printStackTrace();        } finally {            connectHolder.cleanHolder();        }    }        /**        *执行提交，最后关闭连接和清理线程绑定        */    private void doCommit() {        try {            connectHolder.getConnection().commit();        } catch (SQLException e) {            e.printStackTrace();        } finally {            connectHolder.cleanHolder();        }    }        /**        *异常处理，捕获的异常是目标异常或者其子类，就进行回滚，否则就提交事务。        */    private void completeTransactionAfterThrowing(Throwable throwable) {        if (es != null &amp;&amp; es.length &gt; 0) {            for (Class&lt;? extends Throwable&gt; e : es) {                if (e.isAssignableFrom(throwable.getClass())) {                    doRollBack();                }            }        }        doCommit();    }}</code></pre><p><strong>测试验证</strong></p><p>创建一个tb_test表，表结构如下：</p><pre><code class="sql">SET NAMES utf8mb4;SET FOREIGN_KEY_CHECKS = 0;-- ------------------------------ Table structure for tb_test-- ----------------------------DROP TABLE IF EXISTS `tb_test`;CREATE TABLE `tb_test` (  `id` int(11) NOT NULL,  `email` varchar(255) DEFAULT NULL,  PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=latin1;SET FOREIGN_KEY_CHECKS = 1;</code></pre><p>编写一个Service，<code>saveTest</code>方法调用了2个插入语句，同时声明了<code>@MyTransaction</code>事务注解，遇到<code>NullPointerException</code>就进行回滚，最后我们执行了除以0操作，会抛出<code>ArithmeticException</code>。我们用单元测试看看数据是否会回滚。</p><pre><code class="Java">/** * @description: * @author: luozhou kinglaw1204@gmail.com * @create: 2020-03-29 22:05 **/@Servicepublic class MyTransactionTest implements TestService {    @Autowired    DataSourceConnectHolder holder;        //一个事务中执行两个sql插入   @MyTransaction(rollbackFor = NullPointerException.class)    @Override    public void saveTest(int id) {        saveWitharamters(id, &quot;luozhou@gmail.com&quot;);        saveWitharamters(id + 10, &quot;luozhou@gmail.com&quot;);        int aa = id / 0;    }        //执行sql   private void saveWitharamters(int id, String email) {        String sql = &quot;insert into tb_test values(?,?)&quot;;        Connection connection = holder.getConnection();        PreparedStatement stmt = null;        try {            stmt = connection.prepareStatement(sql);            stmt.setInt(1, id);            stmt.setString(2, email);            stmt.executeUpdate();        } catch (SQLException e) {            e.printStackTrace();        }    }}</code></pre><p>单元测试</p><pre><code class="java">@SpringBootTest@RunWith(SpringRunner.class)class SpringTransactionApplicationTests {    @Autowired    private TestService service;    @Test    void contextLoads() throws SQLException {        service.saveTest(1);    }}</code></pre><p><img src="https://oscimg.oschina.net/oscnet/up-dbd04bcead04db61095a10ccb95b9708435.gif" alt=""></p><p>上图代码声明了事务对<code>NullPointerException</code>异常进行回滚，运行中遇到了<code>ArithmeticException</code>异常，所以是不会回滚的，我们在右边的数据库中刷新发现数据正常插入成功了，说明并没有回滚。</p><p><img src="https://oscimg.oschina.net/oscnet/up-d53fcc045c4e87ea4317409245aa9b6b54a.gif" alt=""></p><p>我们把回滚的异常类改为<code>ArithmeticException</code>,把原数据清空再执行一次，出现了<code>ArithmeticException</code>异常，这个时候查看数据库是没有记录新增成功了，这说明事物进行回滚了，表明我们的注解起作用了。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文最开始回顾了事务的相关知识，并发事务会导致<strong>脏读</strong>、<strong>丢失修改</strong>、<strong>不可重复读</strong>、<strong>幻读</strong>，为了解决这些问题，数据库中就引入了事务的隔离级别，隔离级别包括：<strong>读未提交</strong>、<strong>读提交</strong>、<strong>可重复读</strong>和<strong>串行化</strong>。</p><p>Spring中增强了事务的概念，为了解决方法A、方法B和方法C之间的事务关系，引入了事务传播机制的概念。</p><p>Spring中的<code>@Transactional</code>注解的事务实现主要通过<code>TransactionInterceptor</code>拦截器来进行实现的，拦截目标方法，然后判断异常是不是目标异常，如果是目标异常就行进行回滚，否则就进行事务提交。</p><p>最后我们自己通过JDBC结合Spring的AOP自己写了个<code>@MyTransactional</code>的注解，实现了遇到指定异常回滚的功能。</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring Boot </tag>
            
            <tag> 事务 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>西藏旅游⊙准备篇</title>
      <link href="/2020/02/29/Tibet-Travel-Guide/"/>
      <url>/2020/02/29/Tibet-Travel-Guide/</url>
      
        <content type="html"><![CDATA[<h2 id="前记"><a href="#前记" class="headerlink" title="前记"></a>前记</h2><p>也有很多小伙伴们，希冀着未来一天，也能踏上去西藏的路。<br>那么问题也就接踵而至，应该准备些什么呢？选择怎么样的交通工具呢？是不是真的很容易高反？是不是提前吃红景天各种什么药物呢？是不是真的很容易晒黑呢？等等等一系列问题。</p><h2 id="身体准备篇"><a href="#身体准备篇" class="headerlink" title="身体准备篇"></a>身体准备篇</h2><p> 首先，沿途的风景很美，放轻松，没有必要谈反色变，当然也需要提前调整一下。</p><p>例如有规律锻炼习惯的朋友，尤其是喜欢长跑的，做有氧运动，建议提前停半年，再去愉快的旅行。粥哥就吃亏在只停了三个月，成功高反，完美与亚丁错过。</p><p>肺活量越大，越容易高反，反之，例如我，基本没啥感觉，除了！蹦跶，跳呀，跑呀，就我个人而言，快走10米，有跑出800最佳成绩的感觉。就是那种心跳加速，蹦跶到嗓子眼的感觉，需要大口大口喘气，口干舌燥的感觉。</p><p>例如去爬亚丁，看牛奶海和五色海，其实论山的陡峭程度，还是山脚到山顶的里程数，相比深圳的梧桐山，还是长沙的岳麓山，或是西安的骊山，还是贺州姑婆山，真是小巫见大巫，完全不能相提并论。但是！亚丁在高原上呀！一招制胜，对于一个爬山速度并不慢的人来说，爬了足足两个半小时，爬五步休息一下。当然是无氧携带的情况下。</p><p>我是完全不建议已有高反的朋友去的，就像是粥哥，那天就乖乖在酒店休息了。我们领队非常贴心，让携带着氧气罐，但再三强调，如果不是万不得已，这玩意不要用，太容易产生依赖性了。</p><p>真是这样的，一路上见着氧气罐不离口的朋友，其实不是真的高反缺氧，而是心理缺氧。</p><p>粥哥其实当时在色达那晚，高反是最严重的，恶心想吐，无胃口，心跳加速，嘴唇乌紫，当晚送去医院吸氧，但后来也没有氧气罐不离手，事实证明，吸氧是有依赖心理。当然有的人的确是反应强烈，一定要量力而行，从自身身体出发，实在扛不住赶紧回到海拔低的地区。</p><p>也有朋友问，网传的红景天是抗高反的良药。都说了是网传，这也许是药业公司的营销攻略，当然我也不知道，言归正传，其实，半信半疑，当时买心理安慰，我和粥哥提前半个月就吃这个红景天胶囊，事实证明，粥哥成功高反。</p><h2 id="必备物品篇"><a href="#必备物品篇" class="headerlink" title="必备物品篇"></a>必备物品篇</h2><p>那路途上，必备物品呢？三样！太阳眼镜，防晒霜，厚衣服！（其他旅行物品就不赘述。）</p><p>太阳眼镜，我知道！装逼神器，拍照必备！没错！墨镜拍照效果的确不错！但最重要的用途是，保护眼睛！雪山的光发射，完全超乎我的想象。这也是我看《攀登者》主要吐槽乐趣之一。</p><p>去亚丁那天，好巧不巧，我居然把墨镜忘记在酒店。幸好同行的人美心美的小姐姐多带了一幅太阳眼镜，要不然那仙乃日的反射光足以让我眼瞎。那光太强烈了，你取下眼镜，那眼都睁不开。所以一定要记得带太阳眼镜！</p><p>防晒霜。应该就不需要太累赘地表述原因了吧？其实我几乎我和粥哥每天都很认真抹防晒霜，每个两三小时会再补抹，但是回来时，那肤色都黑了几个八度呀。</p><p>厚衣服。高原地区不仅昼夜温差大，而且阳光下和阴面温差也大。我们去已经是五月底六月初，拉萨出发还是艳阳高照，到羊湖时，已经是漫天飞雪了。所以厚衣服一定要时刻预备着。</p><h2 id="出行方式篇"><a href="#出行方式篇" class="headerlink" title="出行方式篇"></a>出行方式篇</h2><p>说到出行方式，我相信很多人都想自己驾辆越野车，在318国道或是青藏线上飞驰，看看那云那山，秒变电影明星。</p><p>说实话，这就是我当初的想法，开辆牧马人飞驰在天地间，别说多得劲。但是再三思量，我们还是报了私人团，四个人一辆越野车，当然你是土豪可以一个人包一辆车，你随意。有熟悉川藏青路况的领队，兼职司机。后来事实证明太明智了，当粥哥入藏区（川西的藏族区）第二天就高反，当时真是自驾，那真是叫天天不应，叫地地不灵。</p><p>虽然说现在路况什么都很好，但是那是川西，一过了金沙江，入西藏，那条路因为涨洪冲击力太大，施工部队在那抢修，说是抢修，那路实在是不堪入目，你开自己的车去，肯定分分钟心疼，磕磕碰碰少不了，一路上看到很多私家车不是保险杠撞到七零八落，就是车身刮了碰了，更别说底盘。我们摇摇晃晃几个小时才到芒康。</p><p>入藏之后，十八道弯，七十二道拐，不是车龄好多年的司机，那路真是不好开。也不是你好好开车，别人也就不惹你，一路上大挂车非常多。尤其是青藏线上的大挂车络绎不绝，时不时来个生死时速。大挂车来个速度与激情，差点就殃及我们这些旁边的车辆，让我们目瞪口呆。</p><p>所以如果是第一次入藏，我是不建议自驾，第一是不清楚路况，第二是不知道自己的身体状况。真想自驾可以第二次入藏，摸清楚一点底之后再自驾。</p><p>再说到飞机出行，我们没有直飞过拉萨或者川西的稻城，我也不知道具体情况，但只是听别人说飞机是最容易高反的出行方法之一，因为海拔几小时内巨升，身体很难适应。有很多人一下飞机就坐返程飞机回去了。</p><h2 id="尾声"><a href="#尾声" class="headerlink" title="尾声"></a>尾声</h2><p>十六天的川进青出历程，让我此生难忘；我想，这也是为什么很多人把去西藏列入此生必去的原因吧。</p><p>当然这个准备篇没有事无巨细地介绍，只是根据自己当初准备时最为疑惑的事项做了简单阐述，当然也是我认为很重要的准备。</p><p>西藏是一个让人流连忘返的地方，是一个值得一去再去的地方。阿里路线，或者滇藏线，我想我有生之年一定会去，后会有期。</p>]]></content>
      
      
      <categories>
          
          <category> 旅游 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 西藏 </tag>
            
            <tag> 攻略 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Tomcat是如何实现异步Servlet的</title>
      <link href="/2020/02/28/tomcat-synchrony/"/>
      <url>/2020/02/28/tomcat-synchrony/</url>
      
        <content type="html"><![CDATA[<p><img src="https://github.com/kinglaw1204/blogImage/blob/master/Tomcat%E8%A7%A3%E6%9E%90/%E5%BC%82%E6%AD%A5Servlet/cat-cover.jpg?raw=true" alt="tomcat"></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>通过我之前的Tomcat系列文章，相信看我博客的同学对Tomcat应该有一个比较清晰的了解了，在前几篇博客我们讨论了Tomcat在SpringBoot框架中是如何启动的，讨论了Tomcat的内部组件是如何设计以及请求是如何流转的，那么我们这篇博客聊聊Tomcat的异步Servlet，Tomcat是如何实现异步Servlet的以及异步Servlet的使用场景。</p><h2 id="手撸一个异步的Servlet"><a href="#手撸一个异步的Servlet" class="headerlink" title="手撸一个异步的Servlet"></a>手撸一个异步的Servlet</h2><p>我们直接借助SpringBoot框架来实现一个Servlet,这里只展示Servlet代码：</p><pre><code>@WebServlet(urlPatterns = &quot;/async&quot;,asyncSupported = true)@Slf4jpublic class AsyncServlet extends HttpServlet {    ExecutorService executorService =Executors.newSingleThreadExecutor();    @Override     protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {        //开启异步,获取异步上下文        final AsyncContext ctx = req.startAsync();        // 提交线程池异步执行        executorService.execute(new Runnable() {            @Override            public void run() {                try {                    log.info(&quot;async Service 准备执行了&quot;);                    //模拟耗时任务                    Thread.sleep(10000L);                    ctx.getResponse().getWriter().print(&quot;async servlet&quot;);                    log.info(&quot;async Service 执行了&quot;);                } catch (IOException e) {                    e.printStackTrace();                } catch (InterruptedException e) {                    e.printStackTrace();                }                //最后执行完成后完成回调。                ctx.complete();            }        });    }</code></pre><p>上面的代码实现了一个异步的Servlet,实现了<code>doGet</code>方法注意在SpringBoot中使用需要再启动类加上<code>@ServletComponentScan</code>注解来扫描Servlet。既然代码写好了，我们来看看实际运行效果。</p><p><img src="https://github.com/kinglaw1204/blogImage/blob/master/Tomcat%E8%A7%A3%E6%9E%90/%E5%BC%82%E6%AD%A5Servlet/async%20Servlet%20result.png?raw=true" alt=""></p><p>我们发送一个请求后，看到页面有响应，同时，看到请求时间花费了10.05s,那么我们这个Servlet算是能正常运行啦。有同学肯定会问，这不是异步servlet吗？你的响应时间并没有加快，有什么用呢？对，我们的响应时间并不能加快，还是会取决于我们的业务逻辑，但是我们的异步servlet请求后，依赖于业务的异步执行，我们可以立即返回，也就是说，Tomcat的线程可以立即回收，默认情况下，Tomcat的核心线程是<strong>10</strong>，最大线程数是<strong>200</strong>,我们能及时回收线程，也就意味着我们能处理更多的请求，能够增加我们的吞吐量，这也是异步Servlet的主要作用。</p><h2 id="异步Servlet的内部原理"><a href="#异步Servlet的内部原理" class="headerlink" title="异步Servlet的内部原理"></a>异步Servlet的内部原理</h2><p>了解完异步Servlet的作用后，我们来看看，Tomcat是如何是先异步Servlet的。其实上面的代码，主要核心逻辑就两部分，<code>final AsyncContext ctx = req.startAsync()</code>和<code>ctx.complete()</code>那我们来看看他们究竟做了什么？</p><pre><code>   public AsyncContext startAsync(ServletRequest request,            ServletResponse response) {        if (!isAsyncSupported()) {            IllegalStateException ise =                    new IllegalStateException(sm.getString(&quot;request.asyncNotSupported&quot;));            log.warn(sm.getString(&quot;coyoteRequest.noAsync&quot;,                    StringUtils.join(getNonAsyncClassNames())), ise);            throw ise;        }        if (asyncContext == null) {            asyncContext = new AsyncContextImpl(this);        }        asyncContext.setStarted(getContext(), request, response,                request==getRequest() &amp;&amp; response==getResponse().getResponse());        asyncContext.setTimeout(getConnector().getAsyncTimeout());        return asyncContext;    }</code></pre><p>我们发现<code>req.startAsync()</code>只是保存了一个异步上下文，同时设置一些基础信息，比如<code>Timeout</code>,顺便提一下，这里设置的默认超时时间是<strong>30S</strong>，如果你的异步处理逻辑超过<strong>30S</strong>,此时执行<code>ctx.complete()</code>就会抛出IllegalStateException 异常。</p><p>我们来看看<code>ctx.complete()</code>的逻辑</p><pre><code>  public void complete() {        if (log.isDebugEnabled()) {            logDebug(&quot;complete   &quot;);        }        check();        request.getCoyoteRequest().action(ActionCode.ASYNC_COMPLETE, null);    }//类：AbstractProcessor  public final void action(ActionCode actionCode, Object param) {    case ASYNC_COMPLETE: {            clearDispatches();            if (asyncStateMachine.asyncComplete()) {                processSocketEvent(SocketEvent.OPEN_READ, true);            }            break;        }     }    //类：AbstractProcessor protected void processSocketEvent(SocketEvent event, boolean dispatch) {        SocketWrapperBase&lt;?&gt; socketWrapper = getSocketWrapper();        if (socketWrapper != null) {            socketWrapper.processSocket(event, dispatch);        }    }    //类：AbstractEndpointpublic boolean processSocket(SocketWrapperBase&lt;S&gt; socketWrapper,            SocketEvent event, boolean dispatch) {        //省略部分代码            SocketProcessorBase&lt;S&gt; sc = null;            if (processorCache != null) {                sc = processorCache.pop();            }            if (sc == null) {                sc = createSocketProcessor(socketWrapper, event);            } else {                sc.reset(socketWrapper, event);            }            Executor executor = getExecutor();            if (dispatch &amp;&amp; executor != null) {                executor.execute(sc);            } else {                sc.run();            }        return true;    }</code></pre><p>所以，这里最终会调用<code>AbstractEndpoint</code>的<code>processSocket</code>方法，之前看过我前面博客的同学应该有印象，<code>EndPoint</code>是用来接受和处理请求的，接下来就会交给<code>Processor</code>去进行协议处理。</p><pre><code>类：AbstractProcessorLightpublic SocketState process(SocketWrapperBase&lt;?&gt; socketWrapper, SocketEvent status)            throws IOException {        //省略部分diam        SocketState state = SocketState.CLOSED;        Iterator&lt;DispatchType&gt; dispatches = null;        do {            if (dispatches != null) {                DispatchType nextDispatch = dispatches.next();                state = dispatch(nextDispatch.getSocketStatus());            } else if (status == SocketEvent.DISCONNECT) {            } else if (isAsync() || isUpgrade() || state == SocketState.ASYNC_END) {                state = dispatch(status);                if (state == SocketState.OPEN) {                    state = service(socketWrapper);                }            } else if (status == SocketEvent.OPEN_WRITE) {                state = SocketState.LONG;            } else if (status == SocketEvent.OPEN_READ){                state = service(socketWrapper);            } else {                state = SocketState.CLOSED;            }        } while (state == SocketState.ASYNC_END ||                dispatches != null &amp;&amp; state != SocketState.CLOSED);        return state;    }</code></pre><p>这部分是重点，<code>AbstractProcessorLight</code>会根据<code>SocketEvent</code>的状态来判断是不是要去调用<code>service(socketWrapper)</code>,该方法最终会去调用到容器，从而完成业务逻辑的调用，我们这个请求是执行完成后调用的，肯定不能进容器了，不然就是死循环了，这里通过<code>isAsync()</code>判断，就会进入<code>dispatch(status)</code>,最终会调用<code>CoyoteAdapter</code>的<code>asyncDispatch</code>方法</p><pre><code>public boolean asyncDispatch(org.apache.coyote.Request req, org.apache.coyote.Response res,            SocketEvent status) throws Exception {        //省略部分代码        Request request = (Request) req.getNote(ADAPTER_NOTES);        Response response = (Response) res.getNote(ADAPTER_NOTES);        boolean success = true;        AsyncContextImpl asyncConImpl = request.getAsyncContextInternal();        try {            if (!request.isAsync()) {                response.setSuspended(false);            }            if (status==SocketEvent.TIMEOUT) {                if (!asyncConImpl.timeout()) {                    asyncConImpl.setErrorState(null, false);                }            } else if (status==SocketEvent.ERROR) {            }            if (!request.isAsyncDispatching() &amp;&amp; request.isAsync()) {                WriteListener writeListener = res.getWriteListener();                ReadListener readListener = req.getReadListener();                if (writeListener != null &amp;&amp; status == SocketEvent.OPEN_WRITE) {                    ClassLoader oldCL = null;                    try {                        oldCL = request.getContext().bind(false, null);                        res.onWritePossible();//这里执行浏览器响应，写入数据                        if (request.isFinished() &amp;&amp; req.sendAllDataReadEvent() &amp;&amp;                                readListener != null) {                            readListener.onAllDataRead();                        }                    } catch (Throwable t) {                    } finally {                        request.getContext().unbind(false, oldCL);                    }                }                 }            }            //这里判断异步正在进行，说明这不是一个完成方法的回调，是一个正常异步请求，继续调用容器。            if (request.isAsyncDispatching()) {                connector.getService().getContainer().getPipeline().getFirst().invoke(                        request, response);                Throwable t = (Throwable) request.getAttribute(RequestDispatcher.ERROR_EXCEPTION);                if (t != null) {                    asyncConImpl.setErrorState(t, true);                }            }            //注意，这里，如果超时或者出错，request.isAsync()会返回false，这里是为了尽快的输出错误给客户端。            if (!request.isAsync()) {                //这里也是输出逻辑                request.finishRequest();                response.finishResponse();            }            //销毁request和response            if (!success || !request.isAsync()) {                updateWrapperErrorCount(request, response);                request.recycle();                response.recycle();            }        }        return success;    }</code></pre><p>上面的代码就是<code>ctx.complete()</code>执行最终的方法了（当然省略了很多细节），完成了数据的输出，最终输出到浏览器。</p><p>这里有同学可能会说，我知道异步执行完后，调用<code>ctx.complete()</code>会输出到浏览器，但是，第一次doGet请求执行完成后，Tomcat是怎么知道不用返回到客户端的呢？关键代码在<code>CoyoteAdapter</code>中的<code>service</code>方法，部分代码如下：</p><pre><code>  postParseSuccess = postParseRequest(req, request, res, response);            //省略部分代码            if (postParseSuccess) {                request.setAsyncSupported(                        connector.getService().getContainer().getPipeline().isAsyncSupported());                connector.getService().getContainer().getPipeline().getFirst().invoke(                        request, response);            }            if (request.isAsync()) {                async = true;               } else {               //输出数据到客户端                request.finishRequest();                response.finishResponse();            if (!async) {                updateWrapperErrorCount(request, response);                //销毁request和response                request.recycle();                response.recycle();            }</code></pre><p>这部分代码在调用完<code>Servlet</code>后，会通过<code>request.isAsync()</code>来判断是否是异步请求，如果是异步请求，就设置<code>async = true</code>。如果是非异步请求就执行输出数据到客户端逻辑，同时销毁<code>request</code>和<code>response</code>。这里就完成了请求结束后不响应客户端的操作。</p><h2 id="为什么说Spring-Boot的-EnableAsync注解不是异步Servlet"><a href="#为什么说Spring-Boot的-EnableAsync注解不是异步Servlet" class="headerlink" title="为什么说Spring Boot的@EnableAsync注解不是异步Servlet"></a>为什么说Spring Boot的@EnableAsync注解不是异步Servlet</h2><p>因为之前准备写本篇文章的时候就查询过很多资料，发现很多资料写SpringBoot异步编程都是依赖于<code>@EnableAsync</code>注解，然后在<code>Controller</code>用多线程来完成业务逻辑，最后汇总结果，完成返回输出。这里拿一个掘金大佬的文章来举例《<a href="https://juejin.im/post/5d9e7cfa6fb9a04e1f12ec02" target="_blank" rel="noopener">新手也能看懂的 SpringBoot 异步编程指南</a>》，这篇文章写得很通俗易懂，非常不错，从业务层面来说，确实是异步编程，但是有一个问题，抛开业务的并行处理来说，针对整个请求来说，并不是异步的，也就是说不能立即释放Tomcat的线程，从而不能达到异步Servlet的效果。这里我参考上文也写了一个demo，我们来验证下，为什么它不是异步的。</p><pre><code>@RestController@Slf4jpublic class TestController {    @Autowired    private TestService service;    @GetMapping(&quot;/hello&quot;)    public String test() {        try {            log.info(&quot;testAsynch Start&quot;);            CompletableFuture&lt;String&gt; test1 = service.test1();            CompletableFuture&lt;String&gt; test2 = service.test2();            CompletableFuture&lt;String&gt; test3 = service.test3();            CompletableFuture.allOf(test1, test2, test3);            log.info(&quot;test1=====&quot; + test1.get());            log.info(&quot;test2=====&quot; + test2.get());            log.info(&quot;test3=====&quot; + test3.get());        } catch (InterruptedException e) {            e.printStackTrace();        } catch (ExecutionException e) {            e.printStackTrace();        }        return &quot;hello&quot;;    }@Servicepublic class TestService {    @Async(&quot;asyncExecutor&quot;)    public CompletableFuture&lt;String&gt; test1() throws InterruptedException {        Thread.sleep(3000L);        return CompletableFuture.completedFuture(&quot;test1&quot;);    }    @Async(&quot;asyncExecutor&quot;)    public CompletableFuture&lt;String&gt; test2() throws InterruptedException {        Thread.sleep(3000L);        return CompletableFuture.completedFuture(&quot;test2&quot;);    }    @Async(&quot;asyncExecutor&quot;)    public CompletableFuture&lt;String&gt; test3() throws InterruptedException {        Thread.sleep(3000L);        return CompletableFuture.completedFuture(&quot;test3&quot;);    }}@SpringBootApplication@EnableAsyncpublic class TomcatdebugApplication {    public static void main(String[] args) {        SpringApplication.run(TomcatdebugApplication.class, args);    }    @Bean(name = &quot;asyncExecutor&quot;)    public Executor asyncExecutor() {        ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();        executor.setCorePoolSize(3);        executor.setMaxPoolSize(3);        executor.setQueueCapacity(100);        executor.setThreadNamePrefix(&quot;AsynchThread-&quot;);        executor.initialize();        return executor;    }</code></pre><p>这里我运行下，看看效果</p><p><img src="https://github.com/kinglaw1204/blogImage/blob/master/Tomcat%E8%A7%A3%E6%9E%90/%E5%BC%82%E6%AD%A5Servlet/Spring%20boot%20%E5%BC%82%E6%AD%A51.gif?raw=true" alt=""></p><p>这里我请求之后，在调用容器执行业务逻辑之前打了一个断点，然后在返回之后的同样打了一个断点，在<code>Controller</code>执行完之后，请求才回到了<code>CoyoteAdapter</code>中，并且判断<code>request.isAsync()</code>,根据图中看到，是为<code>false</code>,那么接下来就会执行<code>request.finishRequest()</code>和<code>response.finishResponse()</code><br>来执行响应的结束，并销毁请求和响应体。很有趣的事情是，我实验的时候发现，在执行<code>request.isAsync()</code>之前，浏览器的页面上已经出现了响应体，这是SpringBoot框架已经通过<code>StringHttpMessageConverter</code>类中的<code>writeInternal</code>方法已经进行输出了。</p><p><strong>以上分析的核心逻辑就是</strong>，Tomcat的线程执行<code>CoyoteAdapter</code>调用容器后，必须要等到请求返回，然后再判断是否是异步请求，再处理请求，然后执行完毕后，线程才能进行回收。而我一最开始的异步Servlet例子，执行完doGet方法后，就会立即返回，也就是会直接到<code>request.isAsync()</code>的逻辑，然后整个线程的逻辑执行完毕，线程被回收。</p><h2 id="聊聊异步Servlet的使用场景"><a href="#聊聊异步Servlet的使用场景" class="headerlink" title="聊聊异步Servlet的使用场景"></a>聊聊异步Servlet的使用场景</h2><p>分析了这么多，那么异步Servlet的使用场景有哪些呢？其实我们只要抓住一点就可以分析了，就是异步Servlet提高了系统的吞吐量，可以接受更多的请求。假设web系统中Tomcat的线程不够用了，大量请求在等待，而此时Web系统应用层面的优化已经不能再优化了，也就是无法缩短业务逻辑的响应时间了，这个时候，如果想让减少用户的等待时间，提高吞吐量，可以尝试下使用异步Servlet。</p><p><strong>举一个实际的例子</strong>：比如做一个短信系统，短信系统对实时性要求很高，所以要求等待时间尽可能短，而发送功能我们实际上是委托运营商去发送的，也就是说我们要调用接口，假设并发量很高，那么这个时候业务系统调用我们的发送短信功能，就有可能把我们的Tomcat线程池用完，剩下的请求就会在队列中等待，那这个时候，短信的延时就上去了，为了解决这个问题，我们可以引入异步Servlet,接受更多的短信发送请求，从而减少短信的延时。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这篇文章我从手写一个异步Servlet来开始，分析了异步Servlet的作用，以及Tomcat内部是如何实现异步Servlet的，然后我也根据互联网上流行的SpringBoot异步编程来进行说明，其在Tomcat内部并不是一个异步的Servlet。最后，我谈到了异步Servlet的使用场景，分析了什么情况下可以尝试异步Servlet。</p>]]></content>
      
      
      <categories>
          
          <category> Tomcat </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Tomcat </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>你写的Java对象究竟占多少内存？</title>
      <link href="/2020/02/27/java-code-used-memory/"/>
      <url>/2020/02/27/java-code-used-memory/</url>
      
        <content type="html"><![CDATA[<p><a href="https://cdn.pixabay.com/photo/2015/12/06/09/17/silhouette-1079240_1280.jpg" target="_blank" rel="noopener" title="memory"><img src="https://cdn.pixabay.com/photo/2015/12/06/09/17/silhouette-1079240_1280.jpg" alt="memory" title="memory"></a></p><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>Java 作为一个面向对象语言，给我们带来了多态，继承，封装等特性，使得我们可以利用这些特性很轻松的就能构建出易于扩展，易于维护的代码。作为一个<code>Javaer</code>，天天搞“对象”，那你写的对象究竟占用了多少内存呢？我们来看看你的“对象”是如何“败家”的。</p><blockquote><p>本文环境：jdk1.8_64</p></blockquote><h2 id="Java-对象头内存模型"><a href="#Java-对象头内存模型" class="headerlink" title="Java 对象头内存模型"></a>Java 对象头内存模型</h2><p>我们先来看看，一个Java 对象的内存模型是怎么样的？由于我们的虚拟机是分为32位和64位，那肯定它们的模型也是有区别的，下面我列出列32位虚拟机和64位虚拟机下的<code>Java</code>对象头内存模型。<br><img src="http://ww1.sinaimg.cn/large/a3a1b4f8gy1gcglfre0b6j21xq0ps191.jpg" alt="32位虚拟机"></p><p><img src="http://ww1.sinaimg.cn/large/a3a1b4f8gy1gcglfrguhaj21zo0ni4dn.jpg" alt="64位虚拟机"></p><p><img src="http://ww1.sinaimg.cn/large/a3a1b4f8gy1gcglfrhfbjj220w0n0h0x.jpg" alt="64位带指针压缩"></p><p>因为笔者的本地环境是<code>jdk1.8</code>,64位虚拟机，这里我以64位虚拟机（开启指针压缩）来分析，因为默认情况下，<code>jdk1.8</code> 在64位虚拟机默认开启指针压缩。</p><p>Java 对象头主要包括两部分，第一部分就是 <code>Mark Word</code>，这也是 <code>Java</code> 锁实现原理中重要的一环，另外一部分是 <code>Klass Word</code>。</p><p><strong>Klass Word</strong>  这里其实是虚拟机设计的一个<code>oop-klass model</code>模型，这里的<code>OOP</code>是指<code>Ordinary Object Pointer</code>（普通对象指针），看起来像个指针实际上是藏在指针里的对象。而 <code>klass</code> 则包含 元数据和方法信息，用来描述 <code>Java</code> 类。它在64位虚拟机开启压缩指针的环境下占用 32bits 空间。</p><p><strong>Mark Word</strong> 是我们分析的重点，这里也会设计到锁的相关知识。<code>Mark Word</code> 在64位虚拟机环境下占用 64bits 空间。整个<code>Mark Word</code>的分配有几种情况：</p><ol><li><strong>未锁定（Normal）：</strong> 哈希码（<code>identity_hashcode</code>）占用31bits，分代年龄（<code>age</code>）占用4 bits，偏向模式（<code>biased_lock</code>）占用1 bits，锁标记（<code>lock</code>）占用2 bits，剩余26bits 未使用(也就是全为0)</li><li><strong>可偏向（Biased）：</strong> 线程id 占54bits，<code>epoch</code> 占2 bits，分代年龄（<code>age</code>）占用4 bits，偏向模式（biased_lock）占用1 bits，锁标记（lock）占用2 bits，剩余 1bit 未使用。</li><li><strong>轻量锁定（Lightweight Locked）</strong>： 锁指针占用62bits，锁标记（<code>lock</code>）占用2 bits。</li><li><strong>重量级锁定（Heavyweight Locked）</strong>：锁指针占用62bits，锁标记（<code>lock</code>）占用2 bits。</li><li><strong>GC 标记</strong>：标记位占2bits，其余为空（也就是填充0）</li></ol><p>以上就是我们对Java对象头内存模型的解析，只要是Java对象，那么就肯定会包括对象头，也就是说这部分内存占用是避免不了的。<strong>所以，在笔者64位虚拟机，Jdk1.8（开启了指针压缩）的环境下，任何一个对象，啥也不做，只要声明一个类，那么它的内存占用就至少是96bits，也就是至少12字节。</strong></p><h2 id="验证模型"><a href="#验证模型" class="headerlink" title="验证模型"></a>验证模型</h2><p>我们来写点代码来验证一下上述的内存模型，这里推荐openjdk的<a href="https://openjdk.java.net/projects/code-tools/jol/" target="_blank" rel="noopener">jol工具</a>，它可以帮助你查看对象内存的占用情况。</p><p>首先添加maven依赖</p><pre><code>        &lt;dependency&gt;            &lt;groupId&gt;org.openjdk.jol&lt;/groupId&gt;            &lt;artifactId&gt;jol-core&lt;/artifactId&gt;            &lt;version&gt;0.10&lt;/version&gt;        &lt;/dependency&gt;</code></pre><p>我们先来看看，如果只是新建一个普通的类，什么属性也不添加，占用的空间是多少？</p><pre><code>/** * @description: * @author: luozhou * @create: 2020-02-26 10:00 **/public class NullObject {}</code></pre><p>按照我们之前的Java对象内存模型分析，一个空对象，那就是只有一个对象头部，在指针压缩的条件下会占用 96 bit，也就是12byte。</p><p>运行工具查看空间占用</p><pre><code> public static void main(String[] args) {        System.out.println(ClassLayout.parseInstance(new NullObject()).toPrintable());    }</code></pre><p>上面这行代码会解析你新建一个NullObject对象，占用了多少内存。我们执行看看结果如何：</p><p><img src="http://ww1.sinaimg.cn/large/a3a1b4f8gy1gcglfroknnj21p80bijtk.jpg" alt="内存占用"></p><p>这里我们发现结果显示：<code>Instance size：16 bytes</code>,结果就是16字节，我们之前预测的12字节不一样，为什么会这样呢？我们看到上图中有3行 object header，每个占用4字节，所以头部就是12字节，这里和我们的计算是一致的，最后一行是虚拟机填充的4字节，<strong>那为什么虚拟机要填充4个字节呢？</strong></p><h2 id="内存对齐"><a href="#内存对齐" class="headerlink" title="内存对齐"></a>内存对齐</h2><p>想要知道为什么虚拟机要填充4个字节，我们需要了解什么是内存对齐？</p><p>我们程序员看内存是这样的：</p><p><img src="http://ww1.sinaimg.cn/large/a3a1b4f8gy1gcglfrboktj20b9033dfs.jpg" alt=""></p><p>上图表示一个坑一个萝卜的内存读取方式。但实际上 CPU 并不会以一个一个字节去读取和写入内存。相反 CPU 读取内存是一块一块读取的，块的大小可以为 2、4、6、8、16 字节等大小。块大小我们称其为内存访问粒度。如下图：</p><p><img src="http://ww1.sinaimg.cn/large/a3a1b4f8gy1gcglfrkdcfj20hh03ddfu.jpg" alt=""></p><p>假设一个32位平台的 CPU，那它就会以4字节为粒度去读取内存块。那为什么需要内存对齐呢？主要有两个原因：</p><ul><li>平台（移植性）原因：不是所有的硬件平台都能够访问任意地址上的任意数据。例如：特定的硬件平台只允许在特定地址获取特定类型的数据，否则会导致异常情况。</li><li>性能原因：若访问未对齐的内存，将会导致 CPU 进行两次内存访问，并且要花费额外的时钟周期来处理对齐及运算。而本身就对齐的内存仅需要一次访问就可以完成读取动作。</li></ul><p>我用图例来说明 CPU 访问非内存对齐的过程：</p><p><img src="http://ww1.sinaimg.cn/large/a3a1b4f8gy1gcglfrf3r0j20e80acwew.jpg" alt=""></p><p>在上图中，假设CPU 是一次读取4字节，在这个连续的8字节的内存空间中，如果我的数据没有对齐，存储的内存块在地址1，2，3，4中，那CPU的读取就会需要进行两次读取，另外还有额外的计算操作：</p><ol><li>CPU 首次读取未对齐地址的第一个内存块，读取 0-3 字节。并移除不需要的字节 0。</li><li>CPU 再次读取未对齐地址的第二个内存块，读取 4-7 字节。并移除不需要的字节 5、6、7 字节。</li><li>合并 1-4 字节的数据。</li><li>合并后放入寄存器。</li></ol><p>所以，没有进行内存对齐就会导致CPU进行额外的读取操作，并且需要额外的计算。如果做了内存对齐，CPU可以直接从地址0开始读取，一次就读取到想要的数据，不需要进行额外读取操作和运算操作，节省了运行时间。<strong>我们用了空间换时间，这就是为什么我们需要内存对齐。</strong></p><p>回到Java空对象填充了4个字节的问题，<strong>因为原字节头是12字节，64位机器下，内存对齐的话就是128位，也就是16字节，所以我们还需要填充4个字节。</strong></p><h2 id="非空对象占用内存计算"><a href="#非空对象占用内存计算" class="headerlink" title="非空对象占用内存计算"></a>非空对象占用内存计算</h2><p>我们知道了一个空对象是占用16字节，那么一个非空对象究竟占用多少字节呢？我们还是写一个普通类来验证下：</p><pre><code>public class TestNotNull {    private NullObject nullObject=new NullObject();    private int a;}</code></pre><p>这个演示类中引入了别的对象，我们知道<code>int</code>类型是占用4个字节,<code>NullObject</code>对象占用16字节，对象头占12字节，<strong>还有一个很重要的情况 <code>NullObject</code>在当前这个类中是一个引用，所以不会存真正的对象，而只存引用地址</strong>，引用地址占4字节，所以总共就是12+4+4=20字节，内存对齐后就是24字节。我们来验证下是不是这个结果：</p><pre><code>public static void main(String[] args) {        //打印实例的内存布局        System.out.println(ClassLayout.parseInstance(new TestNotNull()).toPrintable());        //打印对象的所有相关内存占用        System.out.println(GraphLayout.parseInstance(new TestNotNull()).toPrintable());        //打印对象的所有内存结果并统计         System.out.println(GraphLayout.parseInstance(new TestNotNull()).toFootprint());    }</code></pre><p>结果如下：</p><p><img src="http://ww1.sinaimg.cn/large/a3a1b4f8gy1gcglfrq8v7j21w00woafm.jpg" alt=""></p><p>我们可以看到<code>TestNotNull</code>的类占用空间是24字节，其中头部占用12字节，变量<code>a</code>是<code>int</code>类型，占用4字节,变量<code>nullObject</code>是引用，占用了4字节，最后填充了4个字节，总共是24个字节，与我们之前的预测一致。<strong>但是，因为我们实例化了<code>NullObject</code>,这个对象一会存在于内存中，所以我们还需要加上这个对象的内存占用16字节，那总共就是24bytes+16bytes=40bytes。我们图中最后的统计打印结果也是40字节，所以我们的分析正确。</strong></p><p>这也是如何分析一个对象真正的占用多少内存的思路，根据这个思路加上openJDK的jol工具就可以基本的掌握自己写的“对象”究竟败家了你多少内存。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文我主要讲述了如何分析一个Java对象究竟占用多少内存空间，主要总结点如下：</p><ol><li>Java对象头部内存模型在32位虚拟机和64位虚拟机是不一样的，64位虚拟机又分为开启指针压缩和不开启指针压缩两种对象头模型，所以总共有3种对象头模型。</li><li>内存对齐主要是因为平台的原因和性能的原因，本文主要解析的是性能方面的原因。</li><li>空对象的内存占用计算注意要计算内存对齐，非空对象的内存计算注意加上引用内存占用和原实例对象的空间占用。</li></ol><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>1.<a href="http://cr.openjdk.java.net/~lfoltan/bug_jdk8067480/src/share/vm/oops/klass.hpp.html" target="_blank" rel="noopener">http://cr.openjdk.java.net/~lfoltan/bug_jdk8067480/src/share/vm/oops/klass.hpp.html</a></p><p>2.<a href="https://gist.github.com/arturmkrtchyan/43d6135e8a15798cc46c" target="_blank" rel="noopener">https://gist.github.com/arturmkrtchyan/43d6135e8a15798cc46c</a></p><p>3.<a href="https://weekly-geekly.github.io/articles/447848/index.html" target="_blank" rel="noopener">https://weekly-geekly.github.io/articles/447848/index.html</a></p><p>4.<a href="https://developer.ibm.com/articles/pa-dalign/" target="_blank" rel="noopener">https://developer.ibm.com/articles/pa-dalign/</a></p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Jvm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker是如何实现隔离的</title>
      <link href="/2020/01/21/docker-islotion/"/>
      <url>/2020/01/21/docker-islotion/</url>
      
        <content type="html"><![CDATA[<p><img src="https://cdn.pixabay.com/photo/2015/01/15/14/51/wal-600387_1280.png" alt=""></p><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>容器化技术在当前云计算、微服务等体系下大行其道，而 Docker 便是容器化技术的典型，对于容器化典型的技术，我们有必要弄懂它，所以这篇文章，我会来分析下 Docker 是如何实现隔离技术的，Docker 与虚拟机又有哪些区别呢？接下来，我们开始逐渐揭开它的面纱。</p><h2 id="从运行一个容器开始"><a href="#从运行一个容器开始" class="headerlink" title="从运行一个容器开始"></a>从运行一个容器开始</h2><p>我们开始运行一个简单的容器，这里以<code>busybox</code>镜像为例，它是一个常用的Linux工具箱，可以用来执行很多Linux命令，我们以它为镜像启动容器方便来查看容器内部环境。<br>执行命令：</p><pre><code>docker run -it --name demo_docker busybox /bin/sh</code></pre><p>这条命令的意思是：启动一个<code>busybox</code>镜像的 Docker 容器，<code>-it</code>参数表示给容器提供一个输出/输出的交互环境，也就是TTY。<code>/bin/sh</code>表示容器交互运行的命令或者程序。</p><h2 id="进程的隔离"><a href="#进程的隔离" class="headerlink" title="进程的隔离"></a>进程的隔离</h2><p>执行成功后我们就会进入到了 Docker 容器内部,我们执行<code>ps -ef</code> 查看进程</p><pre><code>/ # ps -efPID   USER     TIME  COMMAND    1 root      0:00 /bin/sh    8 root      0:00 ps -ef</code></pre><p>使用<code>top</code>命令查看进程资源</p><pre><code>Mem: 1757172K used, 106080K free, 190676K shrd, 129872K buff, 998704K cachedCPU:  0.0% usr  0.2% sys  0.0% nic 99.6% idle  0.0% io  0.0% irq  0.0% sirqLoad average: 0.00 0.01 0.05 2/497 9  PID  PPID USER     STAT   VSZ %VSZ CPU %CPU COMMAND    1     0 root     S     1300  0.0   1  0.0 /bin/sh    9     1 root     R     1292  0.0   3  0.0 top</code></pre><p>而我们在宿主机查看下当前执行容器的进程<code>ps -ef|grep busybox</code></p><pre><code>root       5866   5642  0 01:19 pts/4    00:00:00 /usr/bin/docker-current run -it --name demo_docker busybox /bin/shroot       5952   5759  0 01:20 pts/11   00:00:00 grep --color=auto busybox</code></pre><p>这里我们可以知道，对于宿主机 <code>docker run</code>执行命令启动的只是一个进程，它的<code>pid</code>是5866。而对于容器程序本身来说，它被隔离了，在容器内部都只能看到自己内部的进程，那 Docker 是如何做到的呢？它其实是借助了Linux内核的<code>Namespace</code>技术来实现的，这里我结合一段C程序来模拟一下进程的隔离。</p><pre><code>#define _GNU_SOURCE#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;sys/wait.h&gt;#include &lt;stdio.h&gt;#include &lt;sched.h&gt;#include &lt;signal.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/mount.h&gt;/* 定义一个给 clone 用的栈，栈大小1M */#define STACK_SIZE (1024 * 1024)static char container_stack[STACK_SIZE];char* const container_args[] = {    &quot;/bin/bash&quot;,    NULL};int container_main(void* arg){    printf(&quot;容器进程[%5d] ----进入容器!\n&quot;,getpid());    mount(&quot;proc&quot;, &quot;/proc&quot;, &quot;proc&quot;, 0, NULL);    /**执行/bin/bash */    execv(container_args[0], container_args);    printf(&quot;出错啦!\n&quot;);    return 1;}int main(){    printf(&quot;宿主机进程[%5d] - 开始一个容器!\n&quot;,getpid());    /* 调用clone函数 */    int container_pid = clone(container_main, container_stack+STACK_SIZE,  CLONE_NEWPID | CLONE_NEWNS | SIGCHLD, NULL);    /* 等待子进程结束 */    waitpid(container_pid, NULL, 0);    printf(&quot;宿主机 - 容器结束!\n&quot;);    return 0;}</code></pre><p>考虑到很多同学对C语言不是很熟悉，我这里简单解释下这段程序，这段程序主要就是执行<code>clone()</code>函数，去克隆一个进程，而克隆执行的程序就是我们的<code>container_main</code>函数，接着下一个参数就是栈空间，然后<code>CLONE_NEWPID</code>和<code>CLONE_NEWNS</code> 表示Linux NameSpace的调用类别，分别表示创建新的进程命名空间和 挂载命名空间。</p><ul><li><p><code>CLONE_NEWPID</code>会让执行的程序内部重新编号<code>PID</code>，也就是从<code>1</code>号进程开始</p></li><li><p><code>CLONE_NEWNS</code> 会克隆新的挂载环境出来，通过在子进程内部重新挂载<code>proc</code>文件夹，可以屏蔽父进程的进程信息。</p></li></ul><p>我们执行一下这段程序来看看效果。</p><p><strong>编译</strong></p><pre><code>gcc container.c -o container</code></pre><p><strong>执行</strong></p><pre><code>[root@host1 luozhou]# ./container 宿主机进程[ 6061] - 开始一个容器!容器进程[    1] ----进入容器!</code></pre><p>这里我们看到输出在宿主机看来，这个程序的<code>PID</code>是<code>6061</code>，在克隆的子进程来看，它的<code>PID</code>是<code>1</code>，我们执行<code>ps -ef</code> 查看一下进程列表</p><pre><code>[root@host1 luozhou]# ps -efUID         PID   PPID  C STIME TTY          TIME CMDroot          1      0  0 01:46 pts/2    00:00:00 /bin/bashroot         10      1  0 01:48 pts/2    00:00:00 ps -ef</code></pre><p>我们发现确实只有容器内部的进程在运行了，再执行<code>top</code>命令</p><pre><code>   PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                                                                                       1 root      20   0  115576   2112   1628 S   0.0  0.1   0:00.00 bash                                                                                                         11 root      20   0  161904   2124   1544 R   0.0  0.1   0:00.00 top  </code></pre><p>结果也只有2个进程的信息。</p><p>这就是容器隔离进程的基本原理了，Docker主要就是借助 Linux 内核技术Namespace来做到隔离的，其实包括我后面要说到文件的隔离，资源的隔离都是在新的命名空间下通过<code>mount</code>挂载的方式来隔离的。</p><h2 id="文件的隔离"><a href="#文件的隔离" class="headerlink" title="文件的隔离"></a>文件的隔离</h2><p>了解完进程的隔离，相信你们已经对 Docker 容器的隔离玩法就大概的印象了，我们接下来看看，Docker 内部的文件系统如何隔离，也就是你在 Docker 内部执行 <code>ls</code> 显示的文件夹和文件如何来的。</p><p>我们还是以前面的 Docker 命令为例，执行<code>ls</code></p><pre><code>bin   dev   etc   home  proc  root  run   sys   tmp   usr   var</code></pre><p>我们发现容器内部已经包含了这些文件夹了，那么这些文件夹哪里来的呢？我们先执行<code>docker info</code>来看看我们的 Docker 用到的文件系统是什么？</p><pre><code>Server Version: 1.13.1Storage Driver: overlay2</code></pre><p>我的版本是1.13.1，存储驱动是<code>overlay2</code>,不同的存储驱动在 Docker 中表现不一样，但是原理类似，我们来看看 Docker 如何借助<code>overlay2</code>来变出这么多文件夹的。我们前面提到过，Docker都是通过mount 去挂载的,我们先找到我们的容器实例id.</p><p>执行<code>docker ps -a |grep demo_docker</code></p><pre><code>c0afd574aea7        busybox                         &quot;/bin/sh&quot;                42 minutes ago      Up 42 minutes </code></pre><p>我们再根据我们的容器ID 去查找挂载信息，执行<code>cat /proc/mounts | grep c0afd574aea7</code></p><pre><code>shm /var/lib/docker/containers/c0afd574aea716593ceb4466943bbd13e3a081bf84da0779ee43600de0df384b/shm tmpfs rw,context=&quot;system_u:object_r:container_file_t:s0:c740,c923&quot;,nosuid,nodev,noexec,relatime,size=65536k 0 0</code></pre><p>这里出现了一个挂载信息，但是这个记录不是我们的重点，我们需要找到<code>overlay2</code>的挂载信息，所以这里我们还需要执行一个命令:<code>cat /proc/mounts | grep system_u:object_r:container_file_t:s0:c740,c923</code></p><pre><code>overlay /var/lib/docker/overlay2/9c9318031bc53dfca45b6872b73dab82afcd69f55066440425c073fe681109d3/merged overlay rw,context=&quot;system_u:object_r:container_file_t:s0:c740,c923&quot;,relatime,lowerdir=/var/lib/docker/overlay2/l/FWESUOVO6DYTXBBJIQBPUWLN6K:/var/lib/docker/overlay2/l/XPKQU6AMUX3AKLAX2BR6V4JQ3R,upperdir=/var/lib/docker/overlay2/9c9318031bc53dfca45b6872b73dab82afcd69f55066440425c073fe681109d3/diff,workdir=/var/lib/docker/overlay2/9c9318031bc53dfca45b6872b73dab82afcd69f55066440425c073fe681109d3/work 0 0shm /var/lib/docker/containers/c0afd574aea716593ceb4466943bbd13e3a081bf84da0779ee43600de0df384b/shm tmpfs rw,context=&quot;system_u:object_r:container_file_t:s0:c740,c923&quot;,nosuid,nodev,noexec,relatime,size=65536k 0 0</code></pre><p>这里<code>overlay</code>挂载并没有和容器id关联起来，所以我们直接根据容器id是找不到 <code>overlay</code>挂载信息的，这里借助了<code>context</code> 去关联的，所以我们通过<code>context</code>就找到了我们挂载的地址啦。我们进入目录看看结果</p><pre><code>[root@host1 l]# ls /var/lib/docker/overlay2/9c9318031bc53dfca45b6872b73dab82afcd69f55066440425c073fe681109d3/mergedbin  dev  etc  home  proc  root  run  sys  tmp  usr  var</code></pre><p>我们发现这个和我们容器的目录是一致的，我们在这个目录下创建一个新的目录，然后看看容器内部是不是会出现新的目录。<br><img src="https://github.com/kinglaw1204/blogImage/blob/master/Docker%E6%98%AF%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E9%9A%94%E7%A6%BB%E7%9A%84/Docker%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E9%9A%94%E7%A6%BB.gif?raw=true" alt="文件系统隔离" title="文件系统隔离"></p><p>上面的图片验证了容器内部的文件内容和挂载的<code>/var/lib/docker/overlay2/ID/merged</code>下是一致的，这就是Docker文件系统隔离的基本原理。</p><h2 id="资源的限制"><a href="#资源的限制" class="headerlink" title="资源的限制"></a>资源的限制</h2><p>玩过 Docker 的同学肯定知道，Docker 还是可以限制资源使用的，比如 CPU 和内存等，那这部分是如何实现的呢？<br>这里就涉及到Linux的另外一个概念<code>Cgroups</code>技术,它是为进程设置资源限制的重要手段，在Linux 中，一切皆文件，所以<code>Cgroups</code>技术也会体现在文件中，我们执行<code>mount -t cgroup</code> 就可以看到<code>Cgroups</code>的挂载情况</p><pre><code>cgroup on /sys/fs/cgroup/systemd type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,xattr,release_agent=/usr/lib/systemd/systemd-cgroups-agent,name=systemd)cgroup on /sys/fs/cgroup/devices type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,devices)cgroup on /sys/fs/cgroup/net_cls,net_prio type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,net_prio,net_cls)cgroup on /sys/fs/cgroup/hugetlb type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,hugetlb)cgroup on /sys/fs/cgroup/perf_event type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,perf_event)cgroup on /sys/fs/cgroup/freezer type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,freezer)cgroup on /sys/fs/cgroup/blkio type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,blkio)cgroup on /sys/fs/cgroup/cpu,cpuacct type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,cpuacct,cpu)cgroup on /sys/fs/cgroup/pids type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,pids)cgroup on /sys/fs/cgroup/memory type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,memory)cgroup on /sys/fs/cgroup/cpuset type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,cpuset)</code></pre><p>我们看到上面挂载的目录有包括 <code>cpu</code>和<code>memory</code> 那我们猜测大概就是在这个文件夹下面配置限制信息的了。我们跑一个容器来验证下，执行命令：</p><pre><code>docker run -d --name=&#39;cpu_set_demo&#39; --cpu-period=100000 --cpu-quota=20000 busybox md5sum /dev/urandom </code></pre><p>这个命令表示我们需要启动一个容器，这个容器一直产生随机数进行md5计算来消耗CPU，<code>--cpu-period=100000 --cpu-quota=20000</code>表示限制 CPU 使用率在20%，关于这两个参数的详细说明可以点击<a href="https://www.kernel.org/doc/Documentation/scheduler/sched-bwc.txt" target="_blank" rel="noopener">这里</a></p><p><img src="https://github.com/kinglaw1204/blogImage/blob/master/Docker%E6%98%AF%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E9%9A%94%E7%A6%BB%E7%9A%84/cpuset.png?raw=true" alt="进程top" title="进程top"></p><p>我们查看进程消耗情况发现 刚刚启动的容器资源确实被限制在20%，说明 Docker 的CPU限制参数起作用了，那对应在我们的<code>cgroup</code> 文件夹下面是怎么设置的呢？<br>同样，这里的配置肯定是和容器实例id挂钩的，我的文件路径是在<code>/sys/fs/cgroup/cpu/system.slice/docker-5bbf589ae223b347c0d10b7e97cd1461ef82149a6d7fb144e8b01fcafecad036.scope</code>下，<code>5bbf589ae223b347c0d10b7e97cd1461ef82149a6d7fb144e8b01fcafecad036</code> 就是我们启动的容器id了。</p><p>切换到上面的文件夹下，查看我们设置的参数：</p><pre><code>[root@host1]# cat cpu.cfs_period_us100000[root@host1]# cat cpu.cfs_quota_us 20000</code></pre><p>发现这里我们的容器启动设置参数一样,也就是说通过这里的文件值来限制容器的cpu使用情况。这里需要注意的是，不同的Linux版本 Docker Cgroup 文件位置可能不一样，有些是在<code>/sys/fs/cgroup/cpu/docker/ID/</code> 下。</p><h2 id="与传统虚拟机技术的区别"><a href="#与传统虚拟机技术的区别" class="headerlink" title="与传统虚拟机技术的区别"></a>与传统虚拟机技术的区别</h2><p>经过前面的进程、文件系统、资源限制分析，详细各位已经对 Docker 的隔离原理有了基本的认识，那么它和传统的虚拟机技术有和区别呢？这里贴一个网上的Docker和虚拟机区别的图</p><p><img src="https://github.com/kinglaw1204/blogImage/blob/master/Docker%E6%98%AF%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E9%9A%94%E7%A6%BB%E7%9A%84/docker%20%E4%B8%8E%E4%BC%A0%E7%BB%9F%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8C%BA%E5%88%AB.jpg?raw=true" alt="图片来源极客时间" title="图片来源极客时间"></p><p>这张图应该可以清晰的展示了虚拟机技术和 Docker 技术的区别了，虚拟机技术是完全虚拟出一个单独的系统，有这个系统去处理应用的各种运行请求，所以它实际上对于性能来说是有影响的。而 Docker 技术 完全是依赖 Linux 内核特性 Namespace 和Cgroup 技术来实现的，本质来说：你运行在容器的应用在宿主机来说还是一个普通的进程，还是直接由宿主机来调度的，相对来说，性能的损耗就很少，这也是 Docker 技术的重要优势。</p><p>Docker 技术由于 还是一个普通的进程，所以隔离不是很彻底，还是共用宿主机的内核，在隔离级别和安全性上没有虚拟机高，这也是它的一个劣势。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这篇文章我通过实践来验证了 Docker 容器技术在进程、文件系统、资源限制的隔离原理，最后也比较了虚拟机和 Docker 技术的区别，总的来说 Docker技术由于是一个普通的宿主机进程，所以具有性能优势，而虚拟机由于完全虚拟系统，所以具备了高隔离性和安全性的优势，两者互有优缺点。不过容器化是当下的趋势，相信随着技术的成熟，目前的隔离不彻底的问题也能解决，容器化走天下不是梦。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="http://people.redhat.com/vgoyal/papers-presentations/vault-2017/vivek-overlayfs-and-containers-presentation-valult-2017.pdf" target="_blank" rel="noopener">http://people.redhat.com/vgoyal/papers-presentations/vault-2017/vivek-overlayfs-and-containers-presentation-valult-2017.pdf</a></li><li><a href="https://docs.docker.com/v17.09/engine/userguide/storagedriver/overlayfs-driver/" target="_blank" rel="noopener">https://docs.docker.com/v17.09/engine/userguide/storagedriver/overlayfs-driver/</a></li><li><a href="https://lwn.net/Articles/259217" target="_blank" rel="noopener">https://lwn.net/Articles/259217</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> Docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>从1+1=2来理解Java字节码</title>
      <link href="/2019/12/30/analyse-java-code/"/>
      <url>/2019/12/30/analyse-java-code/</url>
      
        <content type="html"><![CDATA[<p><img src="https://cdn.pixabay.com/photo/2019/12/18/20/04/fantasy-4704796_1280.jpg" alt=""></p><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>前不久《深入理解Java虚拟机》第三版发布了，赶紧买来看了看新版的内容，这本书更新了很多新版本虚拟机的内容，还对以前的部分内容进行了重构，还是值得去看的。本着复习和巩固的态度，我决定来编译一个简单的类文件来分析Java的字节码内容，来帮助理解和巩固Java字节码知识，希望也对阅读本文的你有所帮助。</p><blockquote><p>说明：本次采用的环境是OpenJdk12</p></blockquote><h2 id="编译“1-1”代码"><a href="#编译“1-1”代码" class="headerlink" title="编译“1+1”代码"></a>编译“1+1”代码</h2><p>首先我们需要写个简单的小程序，1+1的程序，学习就要从最简单的1+1开始，代码如下：</p><pre><code>package top.luozhou.test;/** * @description: * @author: luozhou * @create: 2019-12-25 21:28 **/public class TestJava {    public static void main(String[] args) {        int a=1+1;        System.out.println(a);    }}</code></pre><p>写好java类文件后，首先执行命令<code>javac TestJava.java</code> 编译类文件，生成<code>TestJava.class</code>。<br>然后执行反编译命令<code>javap -verbose TestJava</code>，字节码结果显示如下：</p><pre><code>  Compiled from &quot;TestJava.java&quot;public class top.luozhou.test.TestJava  minor version: 0  major version: 56  flags: ACC_PUBLIC, ACC_SUPERConstant pool:   #1 = Methodref          #5.#14         // java/lang/Object.&quot;&lt;init&gt;&quot;:()V   #2 = Fieldref           #15.#16        // java/lang/System.out:Ljava/io/PrintStream;   #3 = Methodref          #17.#18        // java/io/PrintStream.println:(I)V   #4 = Class              #19            // top/luozhou/test/TestJava   #5 = Class              #20            // java/lang/Object   #6 = Utf8               &lt;init&gt;   #7 = Utf8               ()V   #8 = Utf8               Code   #9 = Utf8               LineNumberTable  #10 = Utf8               main  #11 = Utf8               ([Ljava/lang/String;)V  #12 = Utf8               SourceFile  #13 = Utf8               TestJava.java  #14 = NameAndType        #6:#7          // &quot;&lt;init&gt;&quot;:()V  #15 = Class              #21            // java/lang/System  #16 = NameAndType        #22:#23        // out:Ljava/io/PrintStream;  #17 = Class              #24            // java/io/PrintStream  #18 = NameAndType        #25:#26        // println:(I)V  #19 = Utf8               top/luozhou/test/TestJava  #20 = Utf8               java/lang/Object  #21 = Utf8               java/lang/System  #22 = Utf8               out  #23 = Utf8               Ljava/io/PrintStream;  #24 = Utf8               java/io/PrintStream  #25 = Utf8               println  #26 = Utf8               (I)V{  public top.luozhou.test.TestJava();    descriptor: ()V    flags: ACC_PUBLIC    Code:      stack=1, locals=1, args_size=1         0: aload_0         1: invokespecial #1                  // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V         4: return      LineNumberTable:        line 8: 0  public static void main(java.lang.String[]);    descriptor: ([Ljava/lang/String;)V    flags: ACC_PUBLIC, ACC_STATIC    Code:      stack=2, locals=2, args_size=1         0: iconst_2         1: istore_1         2: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;         5: iload_1         6: invokevirtual #3                  // Method java/io/PrintStream.println:(I)V         9: return      LineNumberTable:        line 10: 0        line 11: 2        line 12: 9}</code></pre><h2 id="解析字节码"><a href="#解析字节码" class="headerlink" title="解析字节码"></a>解析字节码</h2><p><strong>1.基础信息</strong></p><p>上述结果删除了部分不影响解析的冗余信息，接下来我们便来解析字节码的结果。</p><pre><code> minor version: 0 次版本号，为0表示未使用 major version: 56 主版本号，56表示jdk12，表示只能运行在jdk12版本以及之后的虚拟机中</code></pre><pre><code>flags: ACC_PUBLIC, ACC_SUPER</code></pre><p><code>ACC_PUBLIC</code>:这就是一个是否是public类型的访问标志。</p><p><code>ACC_SUPER</code>: 这个falg是为了解决通过 <code>invokespecial</code> 指令调用 super 方法的问题。可以将它理解成 Java 1.0.2 的一个缺陷补丁，只有通过这样它才能正确找到 super 类方法。从 Java 1.0.2 开始，编译器始终会在字节码中生成 ACC_SUPER 访问标识。感兴趣的同学可以点击<a href="https://bugs.openjdk.java.net/browse/JDK-6527033" target="_blank" rel="noopener">这里</a>来了解更多。</p><p><strong>2.常量池</strong></p><p>接下来，我们将要分析常量池,你也可以对照上面整体的字节码来理解。</p><pre><code>#1 = Methodref          #5.#14         // java/lang/Object.&quot;&lt;init&gt;&quot;:()V</code></pre><p>这是一个方法引用，这里的<code>#5</code>表示索引值，然后我们可以发现索引值为5的字节码如下</p><pre><code>#5 = Class              #20            // java/lang/Object</code></pre><p>它表示这是一个<code>Object</code>类，同理<code>#14</code>指向的是一个<code>&quot;&lt;init&gt;&quot;:()V</code>表示引用的是初始化方法。</p><pre><code>#2 = Fieldref           #15.#16        // java/lang/System.out:Ljava/io/PrintStream;</code></pre><p>上面这段表示是一个字段引用，同样引用了<code>#15</code>和<code>#16</code>,实际上引用的就是<code>java/lang/System</code>类中的<code>PrintStream</code>对象。其他的常量池分析思路是一样的，鉴于篇幅我就不一一说明了，只列下其中的几个关键类型和信息。</p><p><code>NameAndType</code>:这个表示是名称和类型的常量表，可以指向方法名称或者字段的索引，在上面的字节码中都是表示的实际的方法。</p><p><code>Utf8</code>：<strong>我们经常使用的是字符编码，但是这个不是只有字符编码的意思</strong>，它表示一种字符编码是<code>Utf8</code>的字符串。它是虚拟机中最常用的表结构，你可以理解为它可以描述方法，字段，类等信息。<br>比如：</p><pre><code>#4 = Class              #19 #19 = Utf8               top/luozhou/test/TestJava</code></pre><p>这里表示<code>#4</code>这个索引下是一个类，然后指向的类是<code>#19</code>,<code>#19</code>是一个<code>Utf8</code>表，最终存放的是<code>top/luozhou/test/TestJava</code>,那么这样一连接起来就可以知道<code>#4</code>位置引用的类是<code>top/luozhou/test/TestJava</code>了。</p><p><strong>3.构造方法信息</strong></p><p>接下来，我们分析下构造方法的字节码，我们知道，一个类初始化的时候最先执行它的构造方法，如果你没有写构造方法，系统会默认给你添加一个无参的构造方法。</p><pre><code>public top.luozhou.test.TestJava();    descriptor: ()V    flags: ACC_PUBLIC    Code:      stack=1, locals=1, args_size=1         0: aload_0         1: invokespecial #1                  // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V         4: return      LineNumberTable:        line 8: 0</code></pre><p><code>descriptor: ()V</code> :表示这是一个没有返回值的方法。</p><p><code>flags: ACC_PUBLIC</code>:是公共方法。</p><p><code>stack=1, locals=1, args_size=1</code> :表示栈中的数量为1，局部变量表中的变量为1，调用参数也为1。</p><p>这里为什么都是1呢？这不是默认的构造方法吗？哪来的参数？其实Java语言有一个潜规则：<strong>在任何实例方法里面都可以通过<code>this</code>来访问到此方法所属的对象</strong>。而这种机制的实现就是通过Java编译器在编译的时候作为入参传入到方法中了，熟悉<code>python</code>语言的同学肯定会知道，在<code>python</code>中定义一个方法总会传入一个<code>self</code>的参数,这也是传入此实例的引用到方法内部，Java只是把这种机制后推到编译阶段完成而已。所以，这里的1都是指<code>this</code>这个参数而已。</p><pre><code>         0: aload_0         1: invokespecial #1                  // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V         4: return    LineNumberTable:        line 8: 0</code></pre><p>经过上面这个分析对于这个构造方法表达的意思也就很清晰了。</p><p><code>aload_0</code>:表示把局部变量表中的第一个变量加载到栈中，也就是<code>this</code>。</p><p><code>invokespecial</code>:直接调用初始化方法。</p><p><code>return</code>:调用完毕方法结束。</p><p><code>LineNumberTable:</code>这是一个行数的表，用来记录字节码的偏移量和代码行数的映射关系。<code>line 8: 0</code>表示，源码中第8行对应的就是偏移量<code>0</code>的字节码，因为是默认的构造方法，所以这里并无法直观体现出来。</p><p>另外这里会执行<code>Object</code>的构造方法是因为，<code>Object</code>是所有类的父类，子类的构造要先构造父类的构造方法。</p><p><strong>4.main方法信息</strong></p><pre><code>public static void main(java.lang.String[]);    descriptor: ([Ljava/lang/String;)V    flags: ACC_PUBLIC, ACC_STATIC    Code:      stack=2, locals=2, args_size=1         0: iconst_2         1: istore_1         2: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;         5: iload_1         6: invokevirtual #3                  // Method java/io/PrintStream.println:(I)V         9: return      LineNumberTable:        line 10: 0        line 11: 2        line 12: 9</code></pre><p>有了之前构造方法的分析，我们接下来分析<code>main</code>方法也会熟悉很多，重复的我就略过了，这里重点分析<code>code</code>部分。</p><p><code>stack=2, locals=2, args_size=1</code>:这里的栈和局部变量表为2，参数还是为1。这是为什么呢？因为<code>main</code>方法中声明了一个变量<code>a</code>,所以局部变量表要加一个，栈也是，所以他们是2。那为什么<code>args_size</code>还是1呢？你不是说默认会把<code>this</code>传入的吗？应该是2啊。<strong>注意：之前说的是在任何实例方法中，而这个main方法是一个静态方法，静态方法直接可以通过类+方法名访问，并不需要实例对象，所以这里就没必要传入了</strong>。</p><p><code>0: iconst_2</code>:将<code>int</code>类型2推送到栈顶。</p><p><code>1: istore_1</code>:将栈顶<code>int</code>类型数值存入第二个本地变量。</p><p><code>2: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;</code>:获取<code>PrintStream</code>类。</p><p><code>5: iload_1</code>: 把第二个<code>int</code>型本地变量推送到栈顶。</p><p><code>6: invokevirtual #3                  // Method java/io/PrintStream.println:(I)V</code>:调用<code>println</code>方法。</p><p><code>9: return</code>:调用完毕结束方法。</p><p>这里的<code>LineNumberTable</code>是有源码的，我们可以对照下我前面描述是否正确：<br><img src="https://github.com/kinglaw1204/blogImage/blob/master/1+1%E7%90%86%E8%A7%A3%E5%AD%97%E8%8A%82%E7%A0%81/sourceCode.png?raw=true" alt=""></p><p><code>line 10: 0</code>: 第10行表示<code>0: iconst_2</code>字节码，这里我们发现编译器直接给我们计算好了把2推送到栈顶了。</p><p><code>line 11: 2</code>:第11行源码对应的是<code>2: getstatic</code> 获取输出的静态类<code>PrintStream</code>。</p><p><code>line 12: 9</code>:12行源码对应的是<code>return</code>，表示方法结束。</p><p>这里我也画了一个动态图片来演示<code>main</code>方法执行的过程，希望能够帮助你理解：<br><img src="https://github.com/kinglaw1204/blogImage/blob/master/1+1%E7%90%86%E8%A7%A3%E5%AD%97%E8%8A%82%E7%A0%81/main%E6%96%B9%E6%B3%95gif.gif?raw=true" alt=""></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这篇文章我从1+1的的源码编译开始，分析了生成后的Java字节码，包括类的基本信息，常量池，方法调用过程等，通过这些分析，我们对Java字节码有了比较基本的了解，也知道了Java编译器会把优化手段通过编译好的字节码体现出来，比如我们的1+1=2，字节码字节赋值一个2给变量，而不是进行加法运算，从而优化了我们的代码，提搞了执行效率。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="https://bugs.openjdk.java.net/browse/JDK-6527033" target="_blank" rel="noopener">https://bugs.openjdk.java.net/browse/JDK-6527033</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 字节码 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Consul集群版容器化部署与应用集成</title>
      <link href="/2019/12/04/deploy-consul-docker/"/>
      <url>/2019/12/04/deploy-consul-docker/</url>
      
        <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>由于公司目前的主要产品使用的注册中心是<code>consul</code>，<code>consul</code>需要用集群来保证高可用，传统的方式（Nginx/HAProxy）会有单点故障问题，为了解决该问题，我开始研究如何只依赖<code>consul</code>做集群的注册的方式，经过一天的折腾，总算验证了可以通过<a href="https://github.com/penggle/spring-cloud-consul" target="_blank" rel="noopener">集群版ConsulClient</a>来进行集群注册，在部署实施过程中也遇到了一些问题，特此记录分享，希望能对有需要的同学有帮助。</p><h2 id="主机版集群和docker版集群对比"><a href="#主机版集群和docker版集群对比" class="headerlink" title="主机版集群和docker版集群对比"></a>主机版集群和docker版集群对比</h2><p>client+server转发模式的集群部署涉及到两种选择，第一种是直接主机模式部署，2个<code>client</code>+3个<code>server</code>，每个<code>consul</code>实例部署一台主机（适合土豪使用），此种模式的好处就是简单暴力，而且运维相对简单。此种模式的架构部署图如下：<br><img src="https://github.com/kinglaw1204/blogImage/blob/master/consul%20docker%E9%83%A8%E7%BD%B2/%E4%B8%BB%E6%9C%BA%E6%A8%A1%E5%BC%8F%E9%83%A8%E7%BD%B2%E5%9B%BE.png?raw=true" alt="主机模式部署"></p><p>我们选择的是另外一种经济节约模式，<code>docker</code>化部署，好处就是节约资源，劣势就是要管理许多<code>docker</code>镜像，在有引入k8s这些容器管理平台之前，后续<code>docker</code>的运维会比较麻烦，这种模式的架构部署图如下：</p><p><img src="https://github.com/kinglaw1204/blogImage/blob/master/consul%20docker%E9%83%A8%E7%BD%B2/%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8Fdocker%E9%83%A8%E7%BD%B2%E5%9B%BEv1.1.png?raw=true" alt="docker模式部署"></p><p>通过以上两种模式的架构图我们很清楚的就能知道主机部署模式是最简单直接的，而<code>docker</code>的模式虽然节省了资源，但是加大了复杂性，增加了运维的难度。但是这种模式应该是在目前容器化的环境下很好的选择，原因很简单，因为充分的利用了资源，容器的运维可以交给容器运维平台去完成，比如k8s等。下面我们来实践下如何进行容器化的<code>consul</code>集群部署。</p><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>这里准备了两台虚拟主机，由于是虚拟的主机，对外ip是一样的，所以我们以端口区分。</p><pre><code>主机A:192.168.23.222:10385 内网ip:192.168.236.3主机B:192.168.23.222:10585 内网ip:192.168.236.5</code></pre><h2 id="部署配置"><a href="#部署配置" class="headerlink" title="部署配置"></a>部署配置</h2><p><strong>步骤一：主机安装Docker环境</strong>(以Centos为例)</p><pre><code class="shell">yum install docker</code></pre><p><strong>步骤二：拉取Consul镜像进行部署</strong></p><pre><code class="shell">docker pull consul</code></pre><p><strong>步骤三：给主机Docker分配ip段，防止多主机ip重复</strong></p><ol><li>在主机A编辑<code>docker</code>的<code>/etc/docker/daemon.json</code>文件，添加下面的内容</li></ol><pre><code class="json"> &quot;bip&quot;: &quot;172.17.1.252/24&quot;</code></pre><ol start="2"><li>在主机B编辑<code>docker</code>的<code>/etc/docker/daemon.json</code>文件，添加下面的内容</li></ol><pre><code class="json">  &quot;bip&quot;: &quot;172.17.2.252/24&quot;</code></pre><p>这里的配置是给主机的<code>docker</code>实例分配ip，因为后续<code>docker</code>会进行跨主机注册，如果默认注册的话，<code>docker</code>是用的主机内网，从而导致ip重复，所以这里手动进行ip分配,当然上述的ip配置你可以自定义。</p><p><strong>步骤四：在主机A部署Consul</strong></p><p><strong>Node1:</strong></p><pre><code class="shell">           docker run -d --name=node_31 --restart=always \               -e &#39;CONSUL_LOCAL_CONFIG={&quot;skip_leave_on_interrupt&quot;: true}&#39; \               -p 11300:8300 \               -p 11301:8301 \               -p 11301:8301/udp \               -p 11302:8302/udp \               -p 11302:8302 \               -p 11400:8400 \               -p 11500:8500 \               -p 11600:8600 \               consul agent -server -join=172.17.1.1  -bootstrap-expect=3 -node=node31 \               -data-dir=/consul/data/ -client 0.0.0.0 -ui</code></pre><p>  这里重点说明几个参数：</p><p><code>--name</code>:是<code>docker</code>容器的名字，每个容器实例不一样</p><p><code>-node</code>:是<code>consul</code>节点的名字，每个节点不一样</p><p><code>-bootstrap-expect</code>:是启动集群期望至少多少个节点，这里设置是3个。</p><p><code>-data-dir</code>:是<code>consul</code>的数据中心的目录，必须给与<code>consul</code>读写权限，否则启动会报错。</p><p>  启动成功后，执行命令查看<code>consul</code>的节点。</p><pre><code>  docker exec -t node_31 consul members</code></pre><p>  显示结果如下：</p><pre><code>  Node    Address          Status  Type    Build  Protocol  DC   Segmentnode31  172.17.1.1:8301  alive   server  1.6.2  2         dc1  &lt;all&gt;</code></pre><p>  这说明第一个节点正常启动了，接下来正常启动主机A剩下的节点。</p><p><strong>Node2:</strong></p><pre><code>docker run -d --name=node_32 --restart=always \             -e &#39;CONSUL_LOCAL_CONFIG={&quot;skip_leave_on_interrupt&quot;: true}&#39; \             -p 9300:8300 \             -p 9301:8301 \             -p 9301:8301/udp \             -p 9302:8302/udp \             -p 9302:8302 \             -p 9400:8400 \             -p 9500:8500 \             -p 9600:8600 \             consul agent -server -join=172.17.1.1  -bootstrap-expect=3 -node=node32 \             -data-dir=/consul/data/ -client 0.0.0.0 -ui</code></pre><p><strong>Node3:</strong></p><pre><code>          docker run -d --name=node_33 --restart=always \             -e &#39;CONSUL_LOCAL_CONFIG={&quot;skip_leave_on_interrupt&quot;: true}&#39; \             -p 10300:8300 \             -p 10301:8301 \             -p 10301:8301/udp \             -p 10302:8302/udp \             -p 10302:8302 \             -p 10400:8400 \             -p 10500:8500 \             -p 10600:8600 \             consul agent -server -join=172.17.1.1  -bootstrap-expect=3 -node=node33 \             -data-dir=/consul/data/ -client 0.0.0.0 -ui</code></pre><p>三个节点启动完毕后，执行命令，查看节点的状态：</p><pre><code>docker exec -t node_31 consul operator raft list-peers</code></pre><p>结果如下：</p><pre><code>Node    ID                                    Address          State     Voter  RaftProtocolnode32  ee186aef-5f8a-976b-2a33-b20bf79e7da9  172.17.1.2:8300  follower  true   3node33  d86b6b92-19e6-bb00-9437-f988b6dac4b2  172.17.1.3:8300  follower  true   3node31  0ab60093-bed5-be77-f551-6051da7fe790  172.17.1.1:8300  leader    true   3</code></pre><p>这里已经显示，三个<code>server</code>的节点已经完成了集群部署，并且选举了<code>node_31</code>作为主节点。最后给该主机集群部署一个client就大功告成了。</p><p><strong>Node4（client节点）</strong></p><pre><code>   docker run -d --name=node_34  --restart=always \            -e &#39;CONSUL_LOCAL_CONFIG={&quot;leave_on_terminate&quot;: true}&#39; \            -p 8300:8300 \            -p 8301:8301 \            -p 8301:8301/udp \            -p 8302:8302/udp \            -p 8302:8302 \            -p 8400:8400 \            -p 8500:8500 \            -p 8600:8600 \            consul agent -retry-join=172.17.1.1  \            -node-id=$(uuidgen | awk &#39;{print tolower($0)}&#39;) \            -node=node34 -client 0.0.0.0 -ui</code></pre><p>执行<code>docker exec -t node_31 consul members</code>命令，结果如下：</p><pre><code>Node    Address          Status  Type    Build  Protocol  DC   Segmentnode31  172.17.1.1:8301  alive   server  1.6.2  2         dc1  &lt;all&gt;node32  172.17.1.2:8301  alive   server  1.6.2  2         dc1  &lt;all&gt;node33  172.17.1.3:8301  alive   server  1.6.2  2         dc1  &lt;all&gt;node34  172.17.1.4:8301  alive   client  1.6.2  2         dc1  &lt;default&gt;</code></pre><p>这里说明，主机A的<code>consul</code>节点全部启动完成，并且完成了集群部署，可以说这就是一个单主机版的<code>consul</code>集群，那么接下来我们要做的就是把主机B的<code>consul</code>加入到主机A的集群中即可。</p><p><strong>步骤五：在主机B部署Consul</strong></p><p><strong>Node5</strong></p><pre><code>       docker run -d --name=node_51 --restart=always \               -e &#39;CONSUL_LOCAL_CONFIG={&quot;skip_leave_on_interrupt&quot;: true}&#39; \               -p 11300:8300 \               -p 11301:8301 \               -p 11301:8301/udp \               -p 11302:8302/udp \               -p 11302:8302 \               -p 11400:8400 \               -p 11500:8500 \               -p 11600:8600 \               consul agent -server -join=172.17.1.1  -bootstrap-expect=3 -node=node_51 \               -data-dir=/consul/data/ -client 0.0.0.0 -ui</code></pre><p><strong>Node6</strong></p><pre><code>       docker run -d --name=node_52 --restart=always \               -e &#39;CONSUL_LOCAL_CONFIG={&quot;skip_leave_on_interrupt&quot;: true}&#39; \               -p 9300:8300 \               -p 9301:8301 \               -p 9301:8301/udp \               -p 9302:8302/udp \               -p 9302:8302 \               -p 9400:8400 \               -p 9500:8500 \               -p 9600:8600 \               consul agent -server -join=172.17.1.1  -bootstrap-expect=3 -node=node_52 \               -data-dir=/consul/data/ -client 0.0.0.0 -ui</code></pre><p><strong>Node7</strong></p><pre><code>       docker run -d --name=node_53 --restart=always \               -e &#39;CONSUL_LOCAL_CONFIG={&quot;skip_leave_on_interrupt&quot;: true}&#39; \               -p 10300:8300 \               -p 10301:8301 \               -p 10301:8301/udp \               -p 10302:8302/udp \               -p 10302:8302 \               -p 10400:8400 \               -p 10500:8500 \               -p 10600:8600 \               consul agent -server -join=172.17.1.1  -bootstrap-expect=3 -node=node_53 \               -data-dir=/consul/data/ -client 0.0.0.0 -ui</code></pre><p> 主机B的三个server节点部署完成后，我们执行命令<code>docker exec -t node_51 consul members</code>查看下集群节点状态</p><pre><code> Node     Address          Status  Type    Build  Protocol  DC   Segmentnode_51  172.17.2.1:8301  alive   server  1.6.2  2         dc1  &lt;all&gt;</code></pre><p>为什么只有<code>node_51</code>这个单独的节点呢？是不是节点的问题？我们在主机B中查询同样查询一下，结果如下：</p><pre><code>node31  172.17.1.1:8301  alive   server  1.6.2  2         dc1  &lt;all&gt;node32  172.17.1.2:8301  alive   server  1.6.2  2         dc1  &lt;all&gt;node33  172.17.1.3:8301  alive   server  1.6.2  2         dc1  &lt;all&gt;node34  172.17.1.4:8301  alive   client  1.6.2  2         dc1  &lt;default&gt;</code></pre><p>主机A的节点只有他们自己机器的节点，主机B中的节点全部未注册过来，这是为什么呢？原因就是<code>consul</code>绑定的ip是容器的内网ip，主机内部通讯是可以的，跨主机通讯是无法通过内网地址进行通讯的，那么我们怎么做呢？我们通过路由规则进行转发即可，把主机A请求主机B容器的内网地址转发到主机B即可，这里就体现出我们开始给容器分配ip的作用了。<br>我们在主机A执行如下命令:</p><pre><code>route add -net 172.17.2.0 netmask 255.255.255.0 gw 192.168.236.5</code></pre><p>这条命令的意思是，添加一个路由规则<code>172.17.2.1~172.17.2.254</code>范围的ip请求，全部转发到<code>192.168.236.5</code>地址下，也就是我们的主机B。<br>同理主机B也执行如下命令：</p><pre><code>route add -net 172.17.1.0 netmask 255.255.255.0 gw 192.168.236.3</code></pre><p>添加完成后，在执行<code>docker exec -t node_53 consul members</code>命令：</p><pre><code>Node     Address          Status  Type    Build  Protocol  DC   Segmentnode31   172.17.1.1:8301  alive   server  1.6.2  2         dc1  &lt;all&gt;node32   172.17.1.2:8301  alive   server  1.6.2  2         dc1  &lt;all&gt;node33   172.17.1.3:8301  alive   server  1.6.2  2         dc1  &lt;all&gt;node_51  172.17.2.1:8301  alive   server  1.6.2  2         dc1  &lt;all&gt;node_52  172.17.2.2:8301  alive   server  1.6.2  2         dc1  &lt;all&gt;node_53  172.17.2.3:8301  alive   server  1.6.2  2         dc1  &lt;all&gt;node34   172.17.1.4:8301  alive   client  1.6.2  2         dc1  &lt;default&gt;</code></pre><p>集群加入就成功了，这就完成了跨主机的docker容器加入。<br>最后给主机B部署一个<code>client</code></p><p><strong>Node8(client节点)</strong></p><pre><code> docker run -d --name=node_54  --restart=always \            -e &#39;CONSUL_LOCAL_CONFIG={&quot;leave_on_terminate&quot;: true}&#39; \            -p 8300:8300 \            -p 8301:8301 \            -p 8301:8301/udp \            -p 8302:8302/udp \            -p 8302:8302 \            -p 8400:8400 \            -p 8500:8500 \            -p 8600:8600 \            consul agent -retry-join=172.17.1.1  \            -node-id=$(uuidgen | awk &#39;{print tolower($0)}&#39;) \            -node=node54 -client 0.0.0.0 -ui</code></pre><p>最后的集群节点全部加入成功了，结果如下：</p><pre><code>node31   172.17.1.1:8301  alive   server  1.6.2  2         dc1  &lt;all&gt;node32   172.17.1.2:8301  alive   server  1.6.2  2         dc1  &lt;all&gt;node33   172.17.1.3:8301  alive   server  1.6.2  2         dc1  &lt;all&gt;node_51  172.17.2.1:8301  alive   server  1.6.2  2         dc1  &lt;all&gt;node_52  172.17.2.2:8301  alive   server  1.6.2  2         dc1  &lt;all&gt;node_53  172.17.2.3:8301  alive   server  1.6.2  2         dc1  &lt;all&gt;node34   172.17.1.4:8301  alive   client  1.6.2  2         dc1  &lt;default&gt;node54   172.17.2.4:8301  alive   client  1.6.2  2         dc1  &lt;default&gt;</code></pre><p>执行节点状态命令<code>docker exec -t node_31 consul operator raft list-peers</code>：</p><pre><code>node32   ee186aef-5f8a-976b-2a33-b20bf79e7da9  172.17.1.2:8300  follower  true   3node33   d86b6b92-19e6-bb00-9437-f988b6dac4b2  172.17.1.3:8300  follower  true   3node31   0ab60093-bed5-be77-f551-6051da7fe790  172.17.1.1:8300  leader    true   3node_51  cfac3b67-fb47-8726-fa31-158516467792  172.17.2.1:8300  follower  true   3node_53  31679abe-923f-0eb7-9709-1ed09980ca9d  172.17.2.3:8300  follower  true   3node_52  207eeb6d-57f2-c65f-0be6-079c402f6afe  172.17.2.2:8300  follower  true   3</code></pre><p>这样一个包含6个<code>server</code>+2个<code>client</code>的<code>consul</code>容器化集群就部署完成了，我们查看<code>consul</code>的<code>web</code>面板如下：<br><img src="https://github.com/kinglaw1204/blogImage/blob/master/consul%20docker%E9%83%A8%E7%BD%B2/consul%E8%8A%82%E7%82%B9%E6%B3%A8%E5%86%8C%E5%9B%BE.png?raw=true" alt="consul节点注册"></p><h2 id="应用集成"><a href="#应用集成" class="headerlink" title="应用集成"></a>应用集成</h2><p>集群版本的<code>consul</code>我们就部署好了，那么我们如何与应用集成呢？我们只要集成集群版本的<code>consul</code>注册客户端就行了。<br>首先加入依赖</p><pre><code>        &lt;dependency&gt;        &lt;groupId&gt;com.github.penggle&lt;/groupId&gt;        &lt;artifactId&gt;spring-cloud-starter-consul-cluster&lt;/artifactId&gt;        &lt;version&gt;2.1.0.RELEASE&lt;/version&gt;    &lt;/dependency&gt;</code></pre><p>第二步在<code>bootstrap.yml|properties</code>中指定<code>spring.cloud.consul.host</code>为多节点，如下所示：</p><pre><code>spring.cloud.consul.host=192.168.23.222:10385,192.168.23.222:10585</code></pre><p>如果想输出注册的相关日志的话也可以在logback上加上日志配置</p><pre><code>&lt;logger name=&quot;org.springframework.cloud.consul&quot; level=&quot;TRACE&quot;/&gt;</code></pre><p>这样配置完成后启动成功就能看到我们的应用注册成功了，下图是我测试的注册成功的效果：<br><img src="https://github.com/kinglaw1204/blogImage/blob/master/consul%20docker%E9%83%A8%E7%BD%B2/%E5%BA%94%E7%94%A8%E6%B3%A8%E5%86%8C%E8%AF%A6%E6%83%85.png?raw=true" alt=""></p><p>这里显示我的应用节点分别都注册到了集群的2个<code>client</code>上面，通过<code>client</code>的代理转发请求到健康的<code>server</code>，从而实现了<code>consul</code>的高可用。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这篇文章没有研究什么技术干货，纯粹是工作经验分享，主要讲了<code>consul</code>集群部署的方式，传统模式可以通过<code>HAProxy</code>来完成集群的部署，但是这种方式的弊端很明显，通过虚拟ip还是可能会指向故障的节点，所以我们用<code>consul</code>的<code>client</code>+<code>server</code>模式的集群部署，通过<code>docker</code>化来充分利用了机器的资源，只需要2台机器就能完成集群的高可用效果。</p>]]></content>
      
      
      <categories>
          
          <category> Docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
            <tag> Consul </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Tomcat中的容器是如何处理请求的</title>
      <link href="/2019/09/09/Tomcat-container/"/>
      <url>/2019/09/09/Tomcat-container/</url>
      
        <content type="html"><![CDATA[<p><img src="https://cdn.pixabay.com/photo/2014/07/10/17/18/battleship-389274_1280.jpg" alt=""></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>上一篇《<a href="http://www.luozhou.top/2019/08/26/Tomcat-connector/" target="_blank" rel="noopener">Tomcat中的连接器是如何设计的</a>》介绍了Tomcat中连接器的设计，我们知道连接器是负责监听网络端口，获取连接请求，然后转换符合Servlet标准的请求，交给容器去处理，那么我们这篇文章将顺着上一篇文章的思路，看看一个请求到了容器，容器是如何请求的。</p><blockquote><p>说明：本文tomcat版本是9.0.21，不建议零基础读者阅读。</p></blockquote><h2 id="从Adapter中说起"><a href="#从Adapter中说起" class="headerlink" title="从Adapter中说起"></a>从Adapter中说起</h2><p> 我们继续跟着上篇文章<code>Adapter</code>的源码，继续分析，上篇文章结尾的源码如下：</p><pre><code>  //源码1.类：  CoyoteAdapter implements Adapterpublic void service(org.apache.coyote.Request req, org.apache.coyote.Response res)            throws Exception {        Request request = (Request) req.getNote(ADAPTER_NOTES);        Response response = (Response) res.getNote(ADAPTER_NOTES);        postParseSuccess = postParseRequest(req, request, res, response);            if (postParseSuccess) {                //check valves if we support async                request.setAsyncSupported(                        connector.getService().getContainer().getPipeline().isAsyncSupported());                // Calling the container                connector.getService().getContainer().getPipeline().getFirst().invoke(                        request, response);            }    }</code></pre><p>上面的源码的主要作用就是获取到容器，然后调用<code>getPipeline()</code>获取<code>Pipeline</code>，最后去<code>invoke</code>调用，我们来看看这个<code>Pipeline</code>是做什么的。</p><pre><code>//源码2.Pipeline接口public interface Pipeline extends Contained {  public Valve getBasic();  public void setBasic(Valve valve);  public void addValve(Valve valve);  public Valve[] getValves();  public void removeValve(Valve valve);  public Valve getFirst();  public boolean isAsyncSupported();  public void findNonAsyncValves(Set&lt;String&gt; result);}//源码3. Valve接口public interface Valve { public Valve getNext(); public void setNext(Valve valve); public void backgroundProcess(); public void invoke(Request request, Response response)        throws IOException, ServletException; public boolean isAsyncSupported();</code></pre><p>我们从字面上可以理解<code>Pipeline</code>就是管道，而<code>Valve</code>就是阀门，实际上在Tomcat中的作用也是和字面意思差不多。每个容器都有一个管道，而管道中又有多个阀门。我们通过后面的分析来证明这一点。</p><h2 id="管道-阀门（Pipeline-Valve）"><a href="#管道-阀门（Pipeline-Valve）" class="headerlink" title="管道-阀门（Pipeline-Valve）"></a>管道-阀门（Pipeline-Valve）</h2><p>我们看到上面的源码是<code>Pipeline</code>和<code>Valve</code>的接口，<code>Pipeline</code>主要是设置<code>Valve</code>,而<code>Valve</code>是一个链表，然后可以进行<code>invoke</code>方法的调用。我们回顾下这段源码：</p><pre><code>//源码4connector.getService().getContainer().getPipeline().getFirst().invoke(                        request, response);</code></pre><p>这里是直接获取容器的管道，然后获取第一个<code>Valve</code>进行调用。我们在之前提到过<code>Valve</code>是一个链表，这里只调用第一个，也就是可以通过Next去调用到最后一个。我们再回顾下我们第一篇文章《<a href="http://www.luozhou.top/2019/08/12/Tomcat-start-in-springboot/" target="_blank" rel="noopener">Tomcat在SpringBoot中是如何启动的</a>》中提到过，容器是分为4个子容器,分别为<code>Engine</code>、<code>Host</code>、<code>Context</code>、<code>Wrapper</code>,他们同时也是父级和子级的关系，<code>Engine</code>&gt;<code>Host</code>&gt;<code>Context</code>&gt;<code>Wrapper</code>。</p><p>我之前提到过，每个容器都一个<code>Pipeline</code>,那么这个是怎么体现出来的呢？我们看容器的接口源码就可以发现,<code>Pipeline</code>是容器接口定义的一个基本属性：</p><pre><code>//源码5.public interface Container extends Lifecycle {    //省略其他代码  /**     * Return the Pipeline object that manages the Valves associated with     * this Container.     *     * @return The Pipeline     */    public Pipeline getPipeline();}</code></pre><p>我们知道了每个容器都有一个管道(<code>Pipeline</code>)，管道中有许多阀门(<code>Valve</code>),<code>Valve</code>可以进行链式调用，那么问题来了，父容器管道中的<code>Valve</code>怎么调用到子容器中的<code>Valve</code>呢？在<code>Pipeline</code>的实现类<code>StandardPipeline</code>中，我们发现了如下源码：</p><pre><code> /**// 源码6.     * The basic Valve (if any) associated with this Pipeline.     */    protected Valve basic = null;       /**     * The first valve associated with this Pipeline.     */    protected Valve first = null;     public void addValve(Valve valve) {        //省略部分代码        // Add this Valve to the set associated with this Pipeline        if (first == null) {            first = valve;            valve.setNext(basic);        } else {            Valve current = first;            while (current != null) {                //这里循环设置Valve，保证最后一个是basic                if (current.getNext() == basic) {                    current.setNext(valve);                    valve.setNext(basic);                    break;                }                current = current.getNext();            }        }        container.fireContainerEvent(Container.ADD_VALVE_EVENT, valve);    }</code></pre><p>根据如上代码，我们知道了<code>basic</code>是一个管道(<code>Pipeline</code>)中的最后一个阀门，按道理只要最后一个阀门是下一个容器的第一个阀门就可以完成全部的链式调用了。我们用一个请求debug下看看是不是和我们的猜测一样，我们在<code>CoyoteAdapter</code>中的<code>service</code>方法中打个断点，效果如下：<br><img src="https://github.com/kinglaw1204/blogImage/blob/master/tomcat-container/CoyoteAdapter.png?raw=true" alt=""></p><p>这里我们可以知道，在适配器调用容器的时候，也就是调用<code>Engine</code>的管道，只有一个阀门，也就是basic，值为<code>StandardEngineValve</code>。我们发现这个阀门的invoke方法如下：</p><pre><code>//源码7.public final void invoke(Request request, Response response)        throws IOException, ServletException {        // Select the Host to be used for this Request        Host host = request.getHost();        if (host == null) {            // HTTP 0.9 or HTTP 1.0 request without a host when no default host            // is defined. This is handled by the CoyoteAdapter.            return;        }        if (request.isAsyncSupported()) {            request.setAsyncSupported(host.getPipeline().isAsyncSupported());        }        // Ask this Host to process this request        host.getPipeline().getFirst().invoke(request, response);    }</code></pre><p>我们继续debug查看结果如下：<br><img src="https://github.com/kinglaw1204/blogImage/blob/master/tomcat-container/StandardEngineValve.png?raw=true" alt=""></p><p>所以这里的<code>basic</code>实际上将会调用到<code>Host</code>容器的管道(<code>Pipeline</code>)和阀门(<code>Valve</code>),也就是说，每个容器管道中的<code>basic</code>是负责调用下一个子容器的阀门。我用一张图来表示：</p><p><img src="https://github.com/kinglaw1204/blogImage/blob/master/tomcat-container/Valve.png?raw=true" alt=""></p><p>这张图清晰的描述了，Tomcat内部的容器是如何流转请求的，从连接器（<code>Connector</code>）过来的请求会进入<code>Engine</code>容器，<code>Engine</code>通过管道(<code>Pieline</code>)中的阀门(<code>Valve</code>)来进行链式调用，最后的<code>basic</code>阀门是负责调用下一个容器的第一个阀门的，一直调用到<code>Wrapper</code>,然后<code>Wrapper</code>再执行<code>Servlet</code>。</p><p>我们看看<code>Wrapper</code>源码，是否真的如我们所说：</p><pre><code>//源码8. public final void invoke(Request request, Response response)        throws IOException, ServletException {            //省略部分源码        Servlet servlet = null;        if (!unavailable) {            servlet = wrapper.allocate();        }        // Create the filter chain for this request        ApplicationFilterChain filterChain =                ApplicationFilterFactory.createFilterChain(request, wrapper, servlet);         filterChain.doFilter(request.getRequest(),                                    response.getResponse());                }</code></pre><p>看到这里，你可能会说这里明明只是创建了过滤器(<code>Filter</code>)并且去调用而已，并没有去调用<code>Servlet</code><br>，没错，这里确实没有去调用<code>Servlet</code>，但是我们知道，过滤器(<code>Filter</code>)是在<code>Servlet</code>之前执行的，也就是说，<code>filterChain.doFilter</code>执行完之后变会执行<code>Servlet</code>。我们看看<code>ApplicationFilterChain</code>的源码是否如我们所说：</p><pre><code>//源码9. public void doFilter(ServletRequest request, ServletResponse response)        throws IOException, ServletException {        //省略部分代码        internalDoFilter(request,response);    }//源码10.   private void internalDoFilter(ServletRequest request,                                  ServletResponse response)        throws IOException, ServletException {        //省略部分代码        // Call the next filter if there is one        if (pos &lt; n) {         //省略部分代码            ApplicationFilterConfig filterConfig = filters[pos++];            Filter filter = filterConfig.getFilter();            filter.doFilter(request, response, this);            return;        }        //调用servlet        // We fell off the end of the chain -- call the servlet instance        servlet.service(request, response);</code></pre><p>通过源码我们发现，在调用完所有的过滤器(<code>Filter</code>)之后，<code>servlet</code>就开始调用<code>service</code>。我们看看<code>servlet</code>的实现类</p><p><img src="https://github.com/kinglaw1204/blogImage/blob/master/tomcat-container/servlet.png?raw=true" alt=""></p><p>这里我们熟悉的<code>HttpServlet</code>和<code>GenericServlet</code>是<code>Tomcat</code>包的类，实际上只有<code>HttpServlet</code>，因为<code>GenericServlet</code>是<code>HttpServlet</code>的父类。后面就是移交给了框架去处理了,Tomcat内部的请求已经到此是完成了。</p><h2 id="Tomcat的多应用隔离实现"><a href="#Tomcat的多应用隔离实现" class="headerlink" title="Tomcat的多应用隔离实现"></a>Tomcat的多应用隔离实现</h2><p>我们知道，Tomcat是支持部署多个应用的，那么Tomcat是如何支持多应用的部署呢？是怎么保证多个应用之间不会混淆的呢？要想弄懂这个问题，我们还是要回到适配器去说起，回到<code>service</code>方法</p><pre><code>//源码11.类：CoyoteAdapterpublic void service(org.apache.coyote.Request req, org.apache.coyote.Response res)            throws Exception {            //省略部分代码            // Parse and set Catalina and configuration specific            // request parameters            //处理URL映射            postParseSuccess = postParseRequest(req, request, res, response);            if (postParseSuccess) {                //check valves if we support async                request.setAsyncSupported(                        connector.getService().getContainer().getPipeline().isAsyncSupported());                // Calling the container                connector.getService().getContainer().getPipeline().getFirst().invoke(                        request, response);            }}</code></pre><p>我们在之前的源码中只谈到了<code>connector.getService().getContainer().getPipeline().getFirst().invoke( request, response)</code> 这段代码，这部分代码是调用容器，但是在调用容器之前有个<code>postParseRequest</code>方法是用来处理映射请求的，我们跟进看看源码：</p><pre><code>//源码12.类：CoyoteAdapter protected boolean postParseRequest(org.apache.coyote.Request req, Request request,            org.apache.coyote.Response res, Response response) throws IOException, ServletException {        省略部分代码        boolean mapRequired = true;         while (mapRequired) {            // This will map the the latest version by default            connector.getService().getMapper().map(serverName, decodedURI,                    version, request.getMappingData());            //没有找到上下文就报404错误                    if (request.getContext() == null) {                // Don&#39;t overwrite an existing error                if (!response.isError()) {                    response.sendError(404, &quot;Not found&quot;);                }                // Allow processing to continue.                // If present, the error reporting valve will provide a response                // body.                return true;            }                    }</code></pre><p>这里就是循环去处理Url映射，如果<code>Context</code>没有找到，就返回404错误，我们继续看源码：</p><pre><code>//源码13.类：Mapperpublic void map(MessageBytes host, MessageBytes uri, String version,                    MappingData mappingData) throws IOException {        if (host.isNull()) {            String defaultHostName = this.defaultHostName;            if (defaultHostName == null) {                return;            }            host.getCharChunk().append(defaultHostName);        }        host.toChars();        uri.toChars();        internalMap(host.getCharChunk(), uri.getCharChunk(), version, mappingData);    }    //源码14.类：Mapper private final void internalMap(CharChunk host, CharChunk uri,            String version, MappingData mappingData) throws IOException {        //省略部分代码        // Virtual host mapping 处理Host映射        MappedHost[] hosts = this.hosts;        MappedHost mappedHost = exactFindIgnoreCase(hosts, host);         //省略部分代码        if (mappedHost == null) {             mappedHost = defaultHost;            if (mappedHost == null) {                return;            }        }        mappingData.host = mappedHost.object;        // Context mapping 处理上下文映射        ContextList contextList = mappedHost.contextList;        MappedContext[] contexts = contextList.contexts;        //省略部分代码        if (context == null) {            return;        }        mappingData.context = contextVersion.object;        mappingData.contextSlashCount = contextVersion.slashCount;        // Wrapper mapping 处理Servlet映射        if (!contextVersion.isPaused()) {            internalMapWrapper(contextVersion, uri, mappingData);        }    }    </code></pre><p>由于上面的源码比较多，我省略了很多代码，保留了能理解主要逻辑的代码，总的来说就是处理Url包括三部分，映射<code>Host</code>，映射<code>Context</code>和映射<code>Servlet</code>(为了节省篇幅，具体细节源码请感兴趣的同学自行研究)。</p><p>这里我们可以发现一个细节，就是三个处理逻辑都是紧密关联的，只有<code>Host</code>不为空才会处理<code>Context</code>,对于<code>Servlet</code>也是同理。所以这里我们只要<code>Host</code>配置不同，那么后面所有的子容器都是不同的，也就完成了应用隔离的效果。但是对于SpringBoot内嵌Tomcat方式(使用jar包启动)来说，并不具备实现多应用的模式，本身一个应用就是一个Tomcat。</p><p>为了便于理解，我也画了一张多应用隔离的图，这里我们假设有两个域名<code>admin.luozhou.com</code>和<code>web.luozhou.com</code> 然后我每个域名下部署2个应用，分别是<code>User</code>,<code>log</code>,<code>blog</code>,<code>shop</code>。那么当我去想去添加用户的时候，我就会请求<code>admin.luozhou.com</code>域名下的<code>User</code>的<code>Context</code>下面的<code>add</code>的Servlet(<strong>说明：这里例子设计不符合实际开发原则，add这种粒度应该是框架中的controller完成，而不是Servlet</strong>)。</p><p><img src="https://github.com/kinglaw1204/blogImage/blob/master/tomcat-container/Context.png?raw=true" alt=""></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这篇文章我们研究了Tomcat中容器是如何处理请求的，我们来回顾下内容：</p><ul><li>连接器把请求丢给适配器适配后调用容器(<code>Engine</code>)</li><li>容器内部是通过管道(<code>Pieline</code>)-阀门(<code>Valve</code>)模式完成容器的调用的,父容器调用子容器主要通过一个<code>basic</code>的阀门来完成的。</li><li>最后一个子容器<code>wrapper</code>完成调用后就会构建过滤器来进行过滤器调用，调用完成后就到了Tomcat内部的最后一步，调用servlet。也可以理解我们常用的<code>HttpServlet</code>，所有基于<code>Servlet</code>规范的框架在这里就进入了框架流程（包括SpringBoot）。</li><li>最后我们还分析了Tomcat是如何实现多应用隔离的，通过多应用的隔离分析，我们也明白了为什么Tomcat要设计如此多的子容器，多子容器可以根据需要完成不同粒度的隔离级别来实现不同的场景需求。</li></ul>]]></content>
      
      
      <categories>
          
          <category> Tomcat </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Tomcat </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Tomcat中的连接器是如何设计的</title>
      <link href="/2019/08/26/Tomcat-connector/"/>
      <url>/2019/08/26/Tomcat-connector/</url>
      
        <content type="html"><![CDATA[<h2 id="上期回顾"><a href="#上期回顾" class="headerlink" title="上期回顾"></a>上期回顾</h2><p>上一篇文章《<a href="http://localhost:4000/2019/08/12/Tomcat-start-in-springboot/" target="_blank" rel="noopener">Tomcat在SpringBoot中是如何启动的</a>》从main方法启动说起，窥探了SpringBoot是如何启动Tomcat的，在分析Tomcat中我们重点提到了，Tomcat主要包括2个组件，连接器（Connector）和容器（Container）以及他们的内部结构图，那么今天我们来分析下Tomcat中的连接器是怎么设计的以及它的作用是什么。</p><blockquote><p>说明：本文tomcat版本是9.0.21，不建议零基础读者阅读。</p></blockquote><h2 id="从连接器（Connector）源码说起"><a href="#从连接器（Connector）源码说起" class="headerlink" title="从连接器（Connector）源码说起"></a>从连接器（Connector）源码说起</h2><p>既然是来解析连接器（Connector），那么我们直接从源码入手，后面所有源码我会剔除不重要部分，所以会忽略大部分源码细节，只关注流程。源码如下（高能预警，大量代码）：</p><pre><code>public class Connector extends LifecycleMBeanBase  {    public Connector() {        this(&quot;org.apache.coyote.http11.Http11NioProtocol&quot;);    }    public Connector(String protocol) {        boolean aprConnector = AprLifecycleListener.isAprAvailable() &amp;&amp;                AprLifecycleListener.getUseAprConnector();        if (&quot;HTTP/1.1&quot;.equals(protocol) || protocol == null) {            if (aprConnector) {                protocolHandlerClassName = &quot;org.apache.coyote.http11.Http11AprProtocol&quot;;            } else {                protocolHandlerClassName = &quot;org.apache.coyote.http11.Http11NioProtocol&quot;;            }        } else if (&quot;AJP/1.3&quot;.equals(protocol)) {            if (aprConnector) {                protocolHandlerClassName = &quot;org.apache.coyote.ajp.AjpAprProtocol&quot;;            } else {                protocolHandlerClassName = &quot;org.apache.coyote.ajp.AjpNioProtocol&quot;;            }        } else {            protocolHandlerClassName = protocol;        }        // Instantiate protocol handler        ProtocolHandler p = null;        try {            Class&lt;?&gt; clazz = Class.forName(protocolHandlerClassName);            p = (ProtocolHandler) clazz.getConstructor().newInstance();        } catch (Exception e) {            log.error(sm.getString(                    &quot;coyoteConnector.protocolHandlerInstantiationFailed&quot;), e);        } finally {            this.protocolHandler = p;        }        // Default for Connector depends on this system property        setThrowOnFailure(Boolean.getBoolean(&quot;org.apache.catalina.startup.EXIT_ON_INIT_FAILURE&quot;));    }</code></pre><p>我们来看看Connector的构造方法，其实只做了一件事情，就是根据协议设置对应的<code>ProtocolHandler</code>,根据名称我们知道，这是协议处理类，所以连接器内部的一个重要子模块就是<code>ProtocolHandler</code>。</p><h2 id="关于生命周期"><a href="#关于生命周期" class="headerlink" title="关于生命周期"></a>关于生命周期</h2><p>我们看到<code>Connector</code>继承了<code>LifecycleMBeanBase</code>，我们来看看<code>Connector</code>的最终继承关系：</p><p><img src="https://github.com/kinglaw1204/blogImage/blob/master/tomcat-connector/extend.png?raw=true" alt=""></p><p>我们看到最终实现的是<code>Lifecycle</code>接口,我们看看这个接口是何方神圣。我把其接口的注释拿下来解释下</p><pre><code>/** * Common interface for component life cycle methods.  Catalina components * may implement this interface (as well as the appropriate interface(s) for * the functionality they support) in order to provide a consistent mechanism * to start and stop the component. *            start() *  ----------------------------- *  |                           | *  | init()                    | * NEW -»-- INITIALIZING        | * | |           |              |     ------------------«----------------------- * | |           |auto          |     |                                        | * | |          \|/    start() \|/   \|/     auto          auto         stop() | * | |      INITIALIZED --»-- STARTING_PREP --»- STARTING --»- STARTED --»---  | * | |         |                                                            |  | * | |destroy()|                                                            |  | * | --»-----«--    ------------------------«--------------------------------  ^ * |     |          |                                                          | * |     |         \|/          auto                 auto              start() | * |     |     STOPPING_PREP ----»---- STOPPING ------»----- STOPPED -----»----- * |    \|/                               ^                     |  ^ * |     |               stop()           |                     |  | * |     |       --------------------------                     |  | * |     |       |                                              |  | * |     |       |    destroy()                       destroy() |  | * |     |    FAILED ----»------ DESTROYING ---«-----------------  | * |     |                        ^     |                          | * |     |     destroy()          |     |auto                      | * |     --------»-----------------    \|/                         | * |                                 DESTROYED                     | * |                                                               | * |                            stop()                             | * ----»-----------------------------»------------------------------ * * Any state can transition to FAILED. * * Calling start() while a component is in states STARTING_PREP, STARTING or * STARTED has no effect. * * Calling start() while a component is in state NEW will cause init() to be * called immediately after the start() method is entered. * * Calling stop() while a component is in states STOPPING_PREP, STOPPING or * STOPPED has no effect. * * Calling stop() while a component is in state NEW transitions the component * to STOPPED. This is typically encountered when a component fails to start and * does not start all its sub-components. When the component is stopped, it will * try to stop all sub-components - even those it didn&#39;t start. * * Attempting any other transition will throw {@link LifecycleException}. * * &lt;/pre&gt; * The {@link LifecycleEvent}s fired during state changes are defined in the * methods that trigger the changed. No {@link LifecycleEvent}s are fired if the * attempted transition is not valid.</code></pre><p>这段注释翻译就是，这个接口是提供给组件声明周期管理的，并且提供了声明周期流转图。这里我们只需要知道正常流程即可：</p><blockquote><p>New—&gt;Init()—-&gt;Start()—-&gt;Stop()—&gt;Destory()</p></blockquote><h2 id="从生命周期探索连接器"><a href="#从生命周期探索连接器" class="headerlink" title="从生命周期探索连接器"></a>从生命周期探索连接器</h2><p>根据上面的生命周期说明，我们可以知道连接器（<code>Connector</code>）就是按照如此的声明周期管理的，所以我们找到了线索，所以连接器肯定会先初始化然后再启动。我们查看其<code>initInternal()</code>方法可以知道连接器初始化做了什么事情，源码如下：</p><pre><code>    @Override    protected void initInternal() throws LifecycleException {        super.initInternal();        if (protocolHandler == null) {            throw new LifecycleException(                    sm.getString(&quot;coyoteConnector.protocolHandlerInstantiationFailed&quot;));        }        // Initialize adapter        adapter = new CoyoteAdapter(this);        protocolHandler.setAdapter(adapter);        if (service != null) {            protocolHandler.setUtilityExecutor(service.getServer().getUtilityExecutor());        }        // Make sure parseBodyMethodsSet has a default        if (null == parseBodyMethodsSet) {            setParseBodyMethods(getParseBodyMethods());        }        if (protocolHandler.isAprRequired() &amp;&amp; !AprLifecycleListener.isInstanceCreated()) {            throw new LifecycleException(sm.getString(&quot;coyoteConnector.protocolHandlerNoAprListener&quot;,                    getProtocolHandlerClassName()));        }        if (protocolHandler.isAprRequired() &amp;&amp; !AprLifecycleListener.isAprAvailable()) {            throw new LifecycleException(sm.getString(&quot;coyoteConnector.protocolHandlerNoAprLibrary&quot;,                    getProtocolHandlerClassName()));        }        if (AprLifecycleListener.isAprAvailable() &amp;&amp; AprLifecycleListener.getUseOpenSSL() &amp;&amp;                protocolHandler instanceof AbstractHttp11JsseProtocol) {            AbstractHttp11JsseProtocol&lt;?&gt; jsseProtocolHandler =                    (AbstractHttp11JsseProtocol&lt;?&gt;) protocolHandler;            if (jsseProtocolHandler.isSSLEnabled() &amp;&amp;                    jsseProtocolHandler.getSslImplementationName() == null) {                // OpenSSL is compatible with the JSSE configuration, so use it if APR is available                jsseProtocolHandler.setSslImplementationName(OpenSSLImplementation.class.getName());            }        }        try {            protocolHandler.init();        } catch (Exception e) {            throw new LifecycleException(                    sm.getString(&quot;coyoteConnector.protocolHandlerInitializationFailed&quot;), e);        }    }}</code></pre><p>根据上面源码，我们发现主要是处理<code>protocolHandler</code>并初始化它，同时我们注意到了<code>protocolHandler</code> 设置了一个适配器，我们看看这个适配器是做啥的，跟踪源码如下：</p><pre><code>   /**     * The adapter, used to call the connector.     *     * @param adapter The adapter to associate     */    public void setAdapter(Adapter adapter);</code></pre><p>这个注释已经说的很直白了，这个适配器就是用来调用连接器的。我们再继续看看<code>protocolHandler</code>的初始化方法</p><pre><code> /**     * Endpoint that provides low-level network I/O - must be matched to the     * ProtocolHandler implementation (ProtocolHandler using NIO, requires NIO     * Endpoint etc.).     */private final AbstractEndpoint&lt;S,?&gt; endpoint;public void init() throws Exception {        if (getLog().isInfoEnabled()) {            getLog().info(sm.getString(&quot;abstractProtocolHandler.init&quot;, getName()));            logPortOffset();        }        if (oname == null) {            // Component not pre-registered so register it            oname = createObjectName();            if (oname != null) {                Registry.getRegistry(null, null).registerComponent(this, oname, null);            }        }        if (this.domain != null) {            rgOname = new ObjectName(domain + &quot;:type=GlobalRequestProcessor,name=&quot; + getName());            Registry.getRegistry(null, null).registerComponent(                    getHandler().getGlobal(), rgOname, null);        }        String endpointName = getName();        endpoint.setName(endpointName.substring(1, endpointName.length()-1));        endpoint.setDomain(domain);        endpoint.init();    }</code></pre><p>这里出现了一个新的对象，<code>endpoint</code>,根据注释我们可以知道<code>endpoint</code>是用来处理网络IO的，而且必须匹配到指定的子类（比如Nio,就是NioEndPoint处理）。<code>endpoint.init()</code>实际上就是做一些网络的配置，然后就是初始化完毕了。根据我们上面的周期管理，我们知道<code>init()</code>后就是<code>start()</code>,所以我们查看<code>Connector</code>的<code>start()</code>源码：</p><pre><code> protected void startInternal() throws LifecycleException {        // Validate settings before starting        if (getPortWithOffset() &lt; 0) {            throw new LifecycleException(sm.getString(                    &quot;coyoteConnector.invalidPort&quot;, Integer.valueOf(getPortWithOffset())));        }        setState(LifecycleState.STARTING);        try {            protocolHandler.start();        } catch (Exception e) {            throw new LifecycleException(                    sm.getString(&quot;coyoteConnector.protocolHandlerStartFailed&quot;), e);        }    }</code></pre><p>其实就是主要调用<code>protocolHandler.start()</code>方法，继续跟踪，为了方便表述，我会把接下来的代码统一放在一起说明，代码如下：</p><pre><code>//1.类：AbstractProtocol implements ProtocolHandler,        MBeanRegistration public void start() throws Exception {     // 省略部分代码    endpoint.start();    }//2. 类：AbstractEndPoint   public final void start() throws Exception {       // 省略部分代码        startInternal();    } /**3.类：NioEndPoint extends AbstractJsseEndpoint&lt;NioChannel,SocketChannel&gt;     * Start the NIO endpoint, creating acceptor, poller threads.     */    @Override    public void startInternal() throws Exception {        //省略部分代码            // Start poller thread            poller = new Poller();            Thread pollerThread = new Thread(poller, getName() + &quot;-ClientPoller&quot;);            pollerThread.setPriority(threadPriority);            pollerThread.setDaemon(true);            pollerThread.start();            startAcceptorThread();        }    }</code></pre><p>到这里，其实整个启动代码就完成了，我们看到最后是在<code>NioEndPoint</code>创建了一个<code>Poller</code>,并且启动它，这里需要补充说明下，这里只是以NioEndPoint为示列，其实Tomcat 主要提供了三种实现，分别是<code>AprEndPoint</code>,<code>NioEndPoint</code>,<code>Nio2EndPoint</code>,这里表示了tomcat支持的I/O模型：</p><blockquote><p>APR:采用 Apache 可移植运行库实现,它根据不同操作系统，分别用c重写了大部分IO和系统线程操作模块,据说性能要比其他模式要好（未实测）。</p></blockquote><blockquote><p>NIO：非阻塞 I/O </p></blockquote><blockquote><p>NIO.2：异步 I/O</p></blockquote><p>上述代码主要是开启两个线程，一个是Poller,一个是开启Acceptor，既然是线程，核心的代码肯定是<code>run方法</code>，我们来查看源码，代码如下：</p><pre><code>//4.类：Acceptor&lt;U&gt; implements Runnable public void run() { //省略了部分代码                U socket = null;                    socket = endpoint.serverSocketAccept();                // Configure the socket                if (endpoint.isRunning() &amp;&amp; !endpoint.isPaused()) {                    // setSocketOptions() will hand the socket off to                    // an appropriate processor if successful                    //核心逻辑                    if (!endpoint.setSocketOptions(socket)) {                        endpoint.closeSocket(socket);                    }                } else {                    endpoint.destroySocket(socket);                }        state = AcceptorState.ENDED;}//5.类：NioEndpointprotected boolean setSocketOptions(SocketChannel socket) {        // Process the connection        //省略部分代码        try {            // Disable blocking, polling will be used            socket.configureBlocking(false);            Socket sock = socket.socket();            socketProperties.setProperties(sock);            NioSocketWrapper socketWrapper = new NioSocketWrapper(channel, this);            channel.setSocketWrapper(socketWrapper);            socketWrapper.setReadTimeout(getConnectionTimeout());            socketWrapper.setWriteTimeout(getConnectionTimeout());            socketWrapper.setKeepAliveLeft(NioEndpoint.this.getMaxKeepAliveRequests());            socketWrapper.setSecure(isSSLEnabled());            //核心逻辑            poller.register(channel, socketWrapper);            return true;    }</code></pre><p>这里可以发现<code>Acceptor</code>主要就是接受<code>socket</code>,然后把它注册到<code>poller</code>中，我们继续看看是如何注册的。</p><pre><code>/**6.类NioEndpoint         * Registers a newly created socket with the poller.         *         * @param socket    The newly created socket         * @param socketWrapper The socket wrapper         */        public void register(final NioChannel socket, final NioSocketWrapper socketWrapper) {            socketWrapper.interestOps(SelectionKey.OP_READ);//this is what OP_REGISTER turns into.            PollerEvent r = null;            if (eventCache != null) {                r = eventCache.pop();            }            if (r == null) {                r = new PollerEvent(socket, OP_REGISTER);            } else {                r.reset(socket, OP_REGISTER);            }            addEvent(r);        }/** 7.类：PollerEvent implements Runnable public void run() {    //省略部分代码    socket.getIOChannel().register(socket.getSocketWrapper().getPoller().getSelector(), SelectionKey.OP_READ, socket.getSocketWrapper());        }</code></pre><p> 这里发现最终就是采用NIO模型把其注册到通道中。(这里涉及NIO网络编程知识，不了解的同学可以传送<a href="http://ifeve.com/java-nio-all/" target="_blank" rel="noopener">这里</a>)。那么注册完毕后，我们看看Poller做了什么事情。</p><pre><code>*/          /**8.类：NioEndPoint内部类 Poller implements Runnable  **/    @Override        public void run() {            // Loop until destroy() is called            while (true) {                //省略部分代码                Iterator&lt;SelectionKey&gt; iterator =                    keyCount &gt; 0 ? selector.selectedKeys().iterator() : null;                // Walk through the collection of ready keys and dispatch                // any active event.                while (iterator != null &amp;&amp; iterator.hasNext()) {                    SelectionKey sk = iterator.next();                    NioSocketWrapper socketWrapper = (NioSocketWrapper) sk.attachment();                    // Attachment may be null if another thread has called                    // cancelledKey()                    if (socketWrapper == null) {                        iterator.remove();                    } else {                        iterator.remove();                        //sock处理                        processKey(sk, socketWrapper);                    }                }        //省略部分代码        }    </code></pre><p> 这个就是通过selector把之前注册的事件取出来，从而完成了调用。</p><pre><code> //9.类： NioEndPoint内部类 Poller  implements Runnable      protected void processKey(SelectionKey sk, NioSocketWrapper socketWrapper) {          //省略大部分代码            processSocket(socketWrapper, SocketEvent.OPEN_WRITE, true) } //10.类：AbstractEndPoint         public boolean processSocket(SocketWrapperBase&lt;S&gt; socketWrapper,            SocketEvent event, boolean dispatch) {        //省略部分代码            Executor executor = getExecutor();            if (dispatch &amp;&amp; executor != null) {                executor.execute(sc);            } else {                sc.run();            }        return true;    }   //11.类：SocketProcessorBase  implements Runnable   public final void run() {        synchronized (socketWrapper) {            // It is possible that processing may be triggered for read and            // write at the same time. The sync above makes sure that processing            // does not occur in parallel. The test below ensures that if the            // first event to be processed results in the socket being closed,            // the subsequent events are not processed.            if (socketWrapper.isClosed()) {                return;            }            doRun();        }    }//类：12.NioEndPoint   extends AbstractJsseEndpoint&lt;NioChannel,SocketChannel&gt; protected void doRun() {        //省略部分代码                if (handshake == 0) {                    SocketState state = SocketState.OPEN;                    // Process the request from this socket                    if (event == null) {                        state = getHandler().process(socketWrapper, SocketEvent.OPEN_READ);                    } else {                        state = getHandler().process(socketWrapper, event);                    }                    if (state == SocketState.CLOSED) {                        poller.cancelledKey(key, socketWrapper);                    }                }        } </code></pre><p><code>Poller</code>调用的<code>run</code>方法或者用Executor线程池去执行<code>run()</code>,最终调用都是各个子<code>EndPoint</code>中的<code>doRun()</code>方法，最终会取一个<code>Handler</code>去处理<code>socketWrapper</code>。继续看源码：</p><pre><code>//类：13.AbstractProtocol内部类ConnectionHandler implements AbstractEndpoint.Handler&lt;S&gt; public SocketState process(SocketWrapperBase&lt;S&gt; wrapper, SocketEvent status) {            //省略部分代码            state = processor.process(wrapper, status);            return SocketState.CLOSED;        }//类：14.AbstractProcessorLight implements Processor public SocketState process(SocketWrapperBase&lt;?&gt; socketWrapper, SocketEvent status)            throws IOException {            //省略部分代码            state = service(socketWrapper);        return state;    }</code></pre><p> 这部分源码表明最终调用的process是通过一个<code>Processor</code>接口的实现类来完成的，这里最终也是会调用到各个子类中，那么这里的处理器其实就是处理应用协议，我们可以查看<code>AbstractProcessorLight</code>的实现类，分别有<code>AjpProcessor</code>、<code>Http11Processor</code>、<code>StreamProcessor</code>，分别代表tomcat支持三种应用层协议，分别是：</p><ul><li><p><a href="https://baike.baidu.com/item/ajp" target="_blank" rel="noopener">AJP</a>协议</p></li><li><p><a href="https://baike.baidu.com/item/HTTP1.1" target="_blank" rel="noopener">HTTP.1</a>协议</p></li><li><p><a href="https://baike.baidu.com/item/HTTP%202.0/12520156" target="_blank" rel="noopener">HTTP2.0</a>协议</p><p>这里我们以常用的HTTP1.1为例，继续看源码：</p><pre><code>//类：15. Http11Processor extends AbstractProcessorpublic SocketState service(SocketWrapperBase&lt;?&gt; socketWrapper)     throws IOException {     //省略大部分代码          getAdapter().service(request, response);     //省略大部分代码        } //类：16   CoyoteAdapter implements Adapterpublic void service(org.apache.coyote.Request req, org.apache.coyote.Response res)         throws Exception {     Request request = (Request) req.getNote(ADAPTER_NOTES);     Response response = (Response) res.getNote(ADAPTER_NOTES);     postParseSuccess = postParseRequest(req, request, res, response);         if (postParseSuccess) {             //check valves if we support async             request.setAsyncSupported(                     connector.getService().getContainer().getPipeline().isAsyncSupported());             // Calling the container             connector.getService().getContainer().getPipeline().getFirst().invoke(                     request, response);         } }</code></pre></li></ul><p>这里我们发现协议处理器最终会调用适配器(<code>CoyoteAdapter</code>),而适配器最终的工作是转换<code>Request</code>和<code>Response</code>对象为<code>HttpServletRequest</code>和<code>HttpServletResponse</code>，从而可以去调用容器，到这里整个连接器的流程和作用我们就已经分析完了。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>那么我们来回忆下整个流程，我画了一张时序图来说明：</p><p><img src="https://github.com/kinglaw1204/blogImage/blob/master/tomcat-connector/time-flow.png?raw=true" alt=""></p><p>这张图包含了两个流程，一个是组件的初始化，一个是调用的流程。连接器(Connector)主要初始化了两个组件，<code>ProtcoHandler</code>和<code>EndPoint</code>,但是我们从代码结构发现，他们两个是父子关系，也就是说<code>ProtcoHandler</code>包含了<code>EndPoint</code>。后面的流程就是各个子组件的调用链关系，总结来说就是<code>Acceptor</code>负责接收请求，然后注册到<code>Poller</code>，<code>Poller</code>负责处理请求，然后调用<code>processor</code>处理器来处理，最后把请求转成符合<code>Servlet</code>规范的<code>request</code>和<code>response</code>去调用容器(<code>Container</code>)。</p><p>我们流程梳理清楚了，接下来我们来结构化的梳理下：</p><p>回到连接器（<code>Connector</code>）是源码，我们发现，上述说的模块只有<code>ProtocolHandler</code>和<code>Adapter</code>两个属于连接器中，也就是说，连接器只包含了这两大子模块，那么后续的<code>EndPoint</code>、<code>Acceptor</code>、<code>Poller</code>、<code>Processor</code>都是<code>ProtocolHandler</code>的子模块。<br>而<code>Acceptor</code>和<code>Poller</code>两个模块的核心功能都是在<code>EndPoint</code> 中完成的，所以是其子模块，而<code>Processor</code>比较独立，所以它和<code>EndPoint</code>是一个级别的子模块。</p><p>我们用图来说明下上述的关系：</p><p><img src="https://github.com/kinglaw1204/blogImage/blob/master/tomcat-connector/result.png?raw=true" alt=""></p><p>根据上图我们可以知道，连接器主要负责处理连接请求，然后通过适配器调用容器。那么具体流程细化可以如下：</p><ul><li><code>Acceptor</code>监听网络请求，获取请求。</li><li><code>Poller</code>获取到监听的请求提交线程池进行处理。</li><li><code>Processor</code>根据具体的应用协议（HTTP/AJP）来生成Tomcat Request对象。</li><li><code>Adapter</code>把Request对象转换成Servlet标准的Request对象，调用容器。</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>我们从连接器的源码，一步一步解析，分析了连接器主要包含了两大模块，<code>ProtocolHandler</code>和<code>Adapter</code>。<code>ProtocolHandler</code>主要包含了<code>Endpoint</code>模块和<code>Processor</code>模块。<code>Endpoint</code>模块主要的作用是连接的处理，它委托了<code>Acceptor</code>子模块进行连接的监听和注册,委托子模块<code>Poller</code>进行连接的处理；而<code>Processor</code>模块主要是应用协议的处理，最后提交给<code>Adapter</code>进行对象的转换，以便可以调用容器(Container)。另外我们也在分析源码的过程中补充了一些额外知识点：</p><ul><li>当前Tomcat版本支持的IO模型为：APR模型、NIO模型、NIO.2模型</li><li>Tomcat支持的协议是AJP和HTTP,其中HTTP又分为HTTP1.1和HTTP2.0</li></ul>]]></content>
      
      
      <categories>
          
          <category> Tomcat </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Tomcat </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Tomcat在SpringBoot中是如何启动的</title>
      <link href="/2019/08/12/Tomcat-start-in-springboot/"/>
      <url>/2019/08/12/Tomcat-start-in-springboot/</url>
      
        <content type="html"><![CDATA[<p><img src="https://cdn.pixabay.com/photo/2017/09/29/11/57/cat-2798804_1280.png" alt="image"></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>我们知道SpringBoot给我们带来了一个全新的开发体验，我们可以直接把web程序达成jar包，直接启动，这就得益于SpringBoot内置了容器，可以直接启动，本文将以Tomcat为例，来看看SpringBoot是如何启动Tomcat的，同时也将展开学习下Tomcat的源码，了解Tomcat的设计。</p><h2 id="从-Main-方法说起"><a href="#从-Main-方法说起" class="headerlink" title="从 Main 方法说起"></a>从 Main 方法说起</h2><p>用过SpringBoot的人都知道，首先要写一个main方法来启动</p><pre><code>@SpringBootApplicationpublic class TomcatdebugApplication {    public static void main(String[] args) {        SpringApplication.run(TomcatdebugApplication.class, args);    }}</code></pre><p>我们直接点击run方法的源码，跟踪下来，发下最终 的<code>run</code>方法是调用<code>ConfigurableApplicationContext</code>方法，源码如下：</p><pre><code>public ConfigurableApplicationContext run(String... args) {        StopWatch stopWatch = new StopWatch();        stopWatch.start();        ConfigurableApplicationContext context = null;        Collection&lt;springbootexceptionreporter&gt; exceptionReporters = new ArrayList&amp;lt;&amp;gt;();        //设置系统属性『java.awt.headless』，为true则启用headless模式支持        configureHeadlessProperty();        //通过*SpringFactoriesLoader*检索*META-INF/spring.factories*，       //找到声明的所有SpringApplicationRunListener的实现类并将其实例化，       //之后逐个调用其started()方法，广播SpringBoot要开始执行了        SpringApplicationRunListeners listeners = getRunListeners(args);        //发布应用开始启动事件        listeners.starting();        try {        //初始化参数            ApplicationArguments applicationArguments = new DefaultApplicationArguments(args);            //创建并配置当前SpringBoot应用将要使用的Environment（包括配置要使用的PropertySource以及Profile）,        //并遍历调用所有的SpringApplicationRunListener的environmentPrepared()方法，广播Environment准备完毕。            ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments);            configureIgnoreBeanInfo(environment);            //打印banner            Banner printedBanner = printBanner(environment);            //创建应用上下文            context = createApplicationContext();            //通过*SpringFactoriesLoader*检索*META-INF/spring.factories*，获取并实例化异常分析器            exceptionReporters = getSpringFactoriesInstances(SpringBootExceptionReporter.class,                    new Class[] { ConfigurableApplicationContext.class }, context);            //为ApplicationContext加载environment，之后逐个执行ApplicationContextInitializer的initialize()方法来进一步封装ApplicationContext，        //并调用所有的SpringApplicationRunListener的contextPrepared()方法，【EventPublishingRunListener只提供了一个空的contextPrepared()方法】，        //之后初始化IoC容器，并调用SpringApplicationRunListener的contextLoaded()方法，广播ApplicationContext的IoC加载完成，        //这里就包括通过**@EnableAutoConfiguration**导入的各种自动配置类。            prepareContext(context, environment, listeners, applicationArguments, printedBanner);            //刷新上下文            refreshContext(context);            //再一次刷新上下文,其实是空方法，可能是为了后续扩展。            afterRefresh(context, applicationArguments);            stopWatch.stop();            if (this.logStartupInfo) {                new StartupInfoLogger(this.mainApplicationClass).logStarted(getApplicationLog(), stopWatch);            }            //发布应用已经启动的事件            listeners.started(context);            //遍历所有注册的ApplicationRunner和CommandLineRunner，并执行其run()方法。        //我们可以实现自己的ApplicationRunner或者CommandLineRunner，来对SpringBoot的启动过程进行扩展。            callRunners(context, applicationArguments);        }        catch (Throwable ex) {            handleRunFailure(context, ex, exceptionReporters, listeners);            throw new IllegalStateException(ex);        }        try {        //应用已经启动完成的监听事件            listeners.running(context);        }        catch (Throwable ex) {            handleRunFailure(context, ex, exceptionReporters, null);            throw new IllegalStateException(ex);        }        return context;    }</code></pre><p>其实这个方法我们可以简单的总结下步骤为<br>&gt;  1. 配置属性<br>&gt; 2. 获取监听器，发布应用开始启动事件<br>&gt; 3. 初始化输入参数<br>&gt; 4. 配置环境，输出banner<br>&gt; 5. 创建上下文<br>&gt; 6. 预处理上下文<br>&gt; 7. 刷新上下文<br>&gt; 8. 再刷新上下文<br>&gt; 9. 发布应用已经启动事件<br>&gt; 10. 发布应用启动完成事件</p><p>其实上面这段代码，如果只要分析tomcat内容的话，只需要关注两个内容即可，上下文是如何创建的，上下文是如何刷新的，分别对应的方法就是<code>createApplicationContext()</code> 和<code>refreshContext(context)</code>，接下来我们来看看这两个方法做了什么。</p><pre><code>protected ConfigurableApplicationContext createApplicationContext() {        Class&lt;!--?--&gt; contextClass = this.applicationContextClass;        if (contextClass == null) {            try {                switch (this.webApplicationType) {                case SERVLET:                    contextClass = Class.forName(DEFAULT_SERVLET_WEB_CONTEXT_CLASS);                    break;                case REACTIVE:                    contextClass = Class.forName(DEFAULT_REACTIVE_WEB_CONTEXT_CLASS);                    break;                default:                    contextClass = Class.forName(DEFAULT_CONTEXT_CLASS);                }            }            catch (ClassNotFoundException ex) {                throw new IllegalStateException(                        &quot;Unable create a default ApplicationContext, &quot; + &quot;please specify an ApplicationContextClass&quot;,                        ex);            }        }        return (ConfigurableApplicationContext) BeanUtils.instantiateClass(contextClass);    }</code></pre><p>这里就是根据我们的<code>webApplicationType</code> 来判断创建哪种类型的Servlet,代码中分别对应着Web类型(SERVLET),响应式Web类型（REACTIVE),非Web类型（default),我们建立的是Web类型，所以肯定实例化<br><code>DEFAULT_SERVLET_WEB_CONTEXT_CLASS</code>指定的类，也就是<code>AnnotationConfigServletWebServerApplicationContext</code>类，我们来用图来说明下这个类的关系</p><p><img src="https://github.com/kinglaw1204/blogImage/blob/master/Tomcat%E5%9C%A8springboot%E4%B8%AD%E5%A6%82%E4%BD%95%E5%90%AF%E5%8A%A8%E7%9A%84/WebServerApplicationContext.png?raw=true" alt=""></p><p>通过这个类图我们可以知道，这个类继承的是<code>ServletWebServerApplicationContext</code>,这就是我们真正的主角，而这个类最终是继承了<code>AbstractApplicationContext</code>，了解完创建上下文的情况后，我们再来看看刷新上下文，相关代码如下：</p><pre><code>//类：SpringApplication.javaprivate void refreshContext(ConfigurableApplicationContext context) {    //直接调用刷新方法        refresh(context);        if (this.registerShutdownHook) {            try {                context.registerShutdownHook();            }            catch (AccessControlException ex) {                // Not allowed in some environments.            }        }    }//类：SpringApplication.javaprotected void refresh(ApplicationContext applicationContext) {        Assert.isInstanceOf(AbstractApplicationContext.class, applicationContext);        ((AbstractApplicationContext) applicationContext).refresh();    }</code></pre><p>这里还是直接传递调用本类的<code>refresh(context)</code>方法，最后是强转成父类<code>AbstractApplicationContext</code>调用其<code>refresh()</code>方法,该代码如下：</p><pre><code>// 类：AbstractApplicationContext    public void refresh() throws BeansException, IllegalStateException {        synchronized (this.startupShutdownMonitor) {            // Prepare this context for refreshing.            prepareRefresh();            // Tell the subclass to refresh the internal bean factory.            ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();            // Prepare the bean factory for use in this context.            prepareBeanFactory(beanFactory);            try {                // Allows post-processing of the bean factory in context subclasses.                postProcessBeanFactory(beanFactory);                // Invoke factory processors registered as beans in the context.                invokeBeanFactoryPostProcessors(beanFactory);                // Register bean processors that intercept bean creation.                registerBeanPostProcessors(beanFactory);                // Initialize message source for this context.                initMessageSource();                // Initialize event multicaster for this context.                initApplicationEventMulticaster();                // Initialize other special beans in specific context subclasses.这里的意思就是调用各个子类的onRefresh()                onRefresh();                // Check for listener beans and register them.                registerListeners();                // Instantiate all remaining (non-lazy-init) singletons.                finishBeanFactoryInitialization(beanFactory);                // Last step: publish corresponding event.                finishRefresh();            }            catch (BeansException ex) {                if (logger.isWarnEnabled()) {                    logger.warn(&quot;Exception encountered during context initialization - &quot; +                            &quot;cancelling refresh attempt: &quot; + ex);                }                // Destroy already created singletons to avoid dangling resources.                destroyBeans();                // Reset &#39;active&#39; flag.                cancelRefresh(ex);                // Propagate exception to caller.                throw ex;            }            finally {                // Reset common introspection caches in Spring&#39;s core, since we                // might not ever need metadata for singleton beans anymore...                resetCommonCaches();            }        }    }</code></pre><p>这里我们看到<code>onRefresh()</code>方法是调用其子类的实现，根据我们上文的分析，我们这里的子类是<code>ServletWebServerApplicationContext</code>。</p><pre><code>//类：ServletWebServerApplicationContextprotected void onRefresh() {        super.onRefresh();        try {            createWebServer();        }        catch (Throwable ex) {            throw new ApplicationContextException(&quot;Unable to start web server&quot;, ex);        }    }private void createWebServer() {        WebServer webServer = this.webServer;        ServletContext servletContext = getServletContext();        if (webServer == null &amp;amp;&amp;amp; servletContext == null) {            ServletWebServerFactory factory = getWebServerFactory();            this.webServer = factory.getWebServer(getSelfInitializer());        }        else if (servletContext != null) {            try {                getSelfInitializer().onStartup(servletContext);            }            catch (ServletException ex) {                throw new ApplicationContextException(&quot;Cannot initialize servlet context&quot;, ex);            }        }        initPropertySources();    }</code></pre><p>到这里，其实庐山真面目已经出来了，<code>createWebServer()</code>就是启动web服务，但是还没有真正启动Tomcat，既然<code>webServer</code>是通过<code>ServletWebServerFactory</code>来获取的，我们就来看看这个工厂的真面目。</p><p><img src="https://github.com/kinglaw1204/blogImage/blob/master/Tomcat%E5%9C%A8springboot%E4%B8%AD%E5%A6%82%E4%BD%95%E5%90%AF%E5%8A%A8%E7%9A%84/ServletWebServerFactory.png?raw=true" alt=""></p><h2 id="走进Tomcat内部"><a href="#走进Tomcat内部" class="headerlink" title="走进Tomcat内部"></a>走进Tomcat内部</h2><p>根据上图我们发现，工厂类是一个接口，各个具体服务的实现是由各个子类来实现的，所以我们就去看看<code>TomcatServletWebServerFactory.getWebServer()</code>的实现。</p><pre><code>    @Override    public WebServer getWebServer(ServletContextInitializer... initializers) {        Tomcat tomcat = new Tomcat();        File baseDir = (this.baseDirectory != null) ? this.baseDirectory : createTempDir(&quot;tomcat&quot;);        tomcat.setBaseDir(baseDir.getAbsolutePath());        Connector connector = new Connector(this.protocol);        tomcat.getService().addConnector(connector);        customizeConnector(connector);        tomcat.setConnector(connector);        tomcat.getHost().setAutoDeploy(false);        configureEngine(tomcat.getEngine());        for (Connector additionalConnector : this.additionalTomcatConnectors) {            tomcat.getService().addConnector(additionalConnector);        }        prepareContext(tomcat.getHost(), initializers);        return getTomcatWebServer(tomcat);    }</code></pre><p>根据上面的代码，我们发现其主要做了两件事情，第一件事就是把Connnctor(我们称之为连接器)对象添加到Tomcat中，第二件事就是<code>configureEngine</code>,这连接器我们勉强能理解（不理解后面会述说），那这个<code>Engine</code>是什么呢？我们查看<code>tomcat.getEngine()</code>的源码：</p><pre><code>    public Engine getEngine() {        Service service = getServer().findServices()[0];        if (service.getContainer() != null) {            return service.getContainer();        }        Engine engine = new StandardEngine();        engine.setName( &quot;Tomcat&quot; );        engine.setDefaultHost(hostname);        engine.setRealm(createDefaultRealm());        service.setContainer(engine);        return engine;    }</code></pre><p>根据上面的源码，我们发现，原来这个Engine是容器，我们继续跟踪源码，找到<code>Container</code>接口</p><p><img src="https://github.com/kinglaw1204/blogImage/blob/master/Tomcat%E5%9C%A8springboot%E4%B8%AD%E5%A6%82%E4%BD%95%E5%90%AF%E5%8A%A8%E7%9A%84/Container.png?raw=true" alt=""></p><p>上图中，我们看到了4个子接口，分别是Engine,Host,Context,Wrapper。我们从继承关系上可以知道他们都是容器，那么他们到底有啥区别呢？我看看他们的注释是怎么说的。</p><pre><code> /** If used, an Engine is always the top level Container in a Catalina * hierarchy. Therefore, the implementation&#39;s &lt;code&gt;setParent()&lt;/code&gt; method * should throw &lt;code&gt;IllegalArgumentException&lt;/code&gt;. * * @author Craig R. McClanahan */public interface Engine extends Container {    //省略代码}/** * &lt;p&gt; * The parent Container attached to a Host is generally an Engine, but may * be some other implementation, or may be omitted if it is not necessary. * &lt;/p&gt;&lt;p&gt; * The child containers attached to a Host are generally implementations * of Context (representing an individual servlet context). * * @author Craig R. McClanahan */public interface Host extends Container {//省略代码}/*** &lt;/p&gt;&lt;p&gt; * The parent Container attached to a Context is generally a Host, but may * be some other implementation, or may be omitted if it is not necessary. * &lt;/p&gt;&lt;p&gt; * The child containers attached to a Context are generally implementations * of Wrapper (representing individual servlet definitions). * &lt;/p&gt;&lt;p&gt; * * @author Craig R. McClanahan */public interface Context extends Container, ContextBind {    //省略代码}/**&lt;/p&gt;&lt;p&gt; * The parent Container attached to a Wrapper will generally be an * implementation of Context, representing the servlet context (and * therefore the web application) within which this servlet executes. * &lt;/p&gt;&lt;p&gt; * Child Containers are not allowed on Wrapper implementations, so the * &lt;code&gt;addChild()&lt;/code&gt; method should throw an * &lt;code&gt;IllegalArgumentException&lt;/code&gt;. * * @author Craig R. McClanahan */public interface Wrapper extends Container {    //省略代码}</code></pre><p>上面的注释翻译过来就是，<code>Engine</code>是最高级别的容器，其子容器是<code>Host</code>,<code>Host</code>的子容器是<code>Context</code>,<code>Wrapper</code>是<code>Context</code>的子容器，所以这4个容器的关系就是父子关系，也就是<code>Engine</code>&gt;<code>Host</code>&gt;<code>Context</code>&gt;<code>Wrapper</code>。<br>我们再看看<code>Tomcat</code>类的源码:</p><pre><code>//部分源码，其余部分省略。public class Tomcat {//设置连接器     public void setConnector(Connector connector) {        Service service = getService();        boolean found = false;        for (Connector serviceConnector : service.findConnectors()) {            if (connector == serviceConnector) {                found = true;            }        }        if (!found) {            service.addConnector(connector);        }    }    //获取service       public Service getService() {        return getServer().findServices()[0];    }    //设置Host容器     public void setHost(Host host) {        Engine engine = getEngine();        boolean found = false;        for (Container engineHost : engine.findChildren()) {            if (engineHost == host) {                found = true;            }        }        if (!found) {            engine.addChild(host);        }    }    //获取Engine容器     public Engine getEngine() {        Service service = getServer().findServices()[0];        if (service.getContainer() != null) {            return service.getContainer();        }        Engine engine = new StandardEngine();        engine.setName( &quot;Tomcat&quot; );        engine.setDefaultHost(hostname);        engine.setRealm(createDefaultRealm());        service.setContainer(engine);        return engine;    }    //获取server       public Server getServer() {        if (server != null) {            return server;        }        System.setProperty(&quot;catalina.useNaming&quot;, &quot;false&quot;);        server = new StandardServer();        initBaseDir();        // Set configuration source        ConfigFileLoader.setSource(new CatalinaBaseConfigurationSource(new File(basedir), null));        server.setPort( -1 );        Service service = new StandardService();        service.setName(&quot;Tomcat&quot;);        server.addService(service);        return server;    }    //添加Context容器      public Context addContext(Host host, String contextPath, String contextName,            String dir) {        silence(host, contextName);        Context ctx = createContext(host, contextPath);        ctx.setName(contextName);        ctx.setPath(contextPath);        ctx.setDocBase(dir);        ctx.addLifecycleListener(new FixContextListener());        if (host == null) {            getHost().addChild(ctx);        } else {            host.addChild(ctx);        }    //添加Wrapper容器         public static Wrapper addServlet(Context ctx,                                      String servletName,                                      Servlet servlet) {        // will do class for name and set init params        Wrapper sw = new ExistingStandardWrapper(servlet);        sw.setName(servletName);        ctx.addChild(sw);        return sw;    }}</code></pre><p>阅读<code>Tomcat</code>的<code>getServer()</code>我们可以知道，<code>Tomcat</code>的最顶层是<code>Server</code>,Server就是<code>Tomcat</code>的实例，一个<code>Tomcat</code>一个<code>Server</code>;通过<code>getEngine()</code>我们可以了解到Server下面是Service，而且是多个，一个Service代表我们部署的一个应用，而且我们还可以知道，<code>Engine</code>容器，一个<code>service</code>只有一个；根据父子关系，我们看<code>setHost()</code>源码可以知道，<code>host</code>容器有多个；同理，我们发现<code>addContext()</code>源码下，<code>Context</code>也是多个；<code>addServlet()</code>表明<code>Wrapper</code>容器也是多个，而且这段代码也暗示了，其实<code>Wrapper</code>和<code>Servlet</code>是一层意思。另外我们根据<code>setConnector</code>源码可以知道，连接器(<code>Connector</code>)是设置在<code>service</code>下的，而且是可以设置多个连接器(<code>Connector</code>)。</p><p>根据上面分析，我们可以小结下：<br>Tomcat主要包含了2个核心组件，连接器(Connector)和容器(Container),用图表示如下：</p><p><img src="https://github.com/kinglaw1204/blogImage/blob/master/Tomcat%E5%9C%A8springboot%E4%B8%AD%E5%A6%82%E4%BD%95%E5%90%AF%E5%8A%A8%E7%9A%84/Tomcat.png?raw=true" alt=""></p><p>一个<code>Tomcat</code>是一个<code>Server</code>,一个<code>Server</code>下有多个<code>service</code>，也就是我们部署的多个应用，一个应用下有多个连接器(<code>Connector</code>)和一个容器（<code>Container</code>）,容器下有多个子容器，关系用图表示如下：</p><p><img src="https://github.com/kinglaw1204/blogImage/blob/master/Tomcat%E5%9C%A8springboot%E4%B8%AD%E5%A6%82%E4%BD%95%E5%90%AF%E5%8A%A8%E7%9A%84/Container-struct.png?raw=true" alt=""></p><p><code>Engine</code>下有多个<code>Host</code>子容器，<code>Host</code>下有多个<code>Context</code>子容器，<code>Context</code>下有多个<code>Wrapper</code>子容器。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>  SpringBoot的启动是通过<code>new SpringApplication()</code>实例来启动的，启动过程主要做如下几件事情：<br>  &gt;  1. 配置属性<br>&gt; 2. 获取监听器，发布应用开始启动事件<br>&gt; 3. 初始化输入参数<br>&gt; 4. 配置环境，输出banner<br>&gt; 5. 创建上下文<br>&gt; 6. 预处理上下文<br>&gt; 7. 刷新上下文<br>&gt; 8. 再刷新上下文<br>&gt; 9. 发布应用已经启动事件<br>&gt; 10. 发布应用启动完成事件</p><p>而启动Tomcat就是在第7步中“刷新上下文”；Tomcat的启动主要是初始化2个核心组件，连接器(Connector)和容器（Container），一个Tomcat实例就是一个Server，一个Server包含多个Service，也就是多个应用程序，每个Service包含多个连接器（Connetor）和一个容器（Container),而容器下又有多个子容器，按照父子关系分别为：Engine,Host,Context,Wrapper，其中除了Engine外，其余的容器都是可以有多个。</p><h2 id="下期展望"><a href="#下期展望" class="headerlink" title="下期展望"></a>下期展望</h2><p>   本期文章通过SpringBoot的启动来窥探了Tomcat的内部结构，下一期，我们来分析下本次文章中的连接器(<code>Connetor</code>)和容器(Container)的作用，敬请期待。</p>]]></content>
      
      
      <categories>
          
          <category> Tomcat </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Tomcat </tag>
            
            <tag> SpringBoot </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java虚拟机垃圾回收相关知识点全梳理（下）</title>
      <link href="/2019/05/09/gc-jvm-02/"/>
      <url>/2019/05/09/gc-jvm-02/</url>
      
        <content type="html"><![CDATA[<h2 id="一、前言"><a href="#一、前言" class="headerlink" title="一、前言"></a>一、前言</h2><p>上一篇文章《<a href="https://www.luozhou.top/2019/04/28/jvm-gc-01/" target="_blank" rel="noopener">Java虚拟机垃圾回收相关知识点全梳理（上）</a>》我整理分享了JVM运行时数据区域的划分，垃圾判定算法以及垃圾回收算法，各种算法的适用场景。今天，我整理分享下JVM性能的度量指标，垃圾收集器的分类，最后分享一下JVM的调优建议。</p><h2 id="二、性能度量指标"><a href="#二、性能度量指标" class="headerlink" title="二、性能度量指标"></a>二、性能度量指标</h2><ul><li><p><strong>吞吐量</strong>：表示系统减去系统回收时间占总时间的比率，比如系统运行了100秒，垃圾回收占用了1秒，那么吞吐量量就是(100-1)/100=99%。</p></li><li><p><strong>垃圾回收消耗</strong>：和吞吐量相反，垃圾回收器消耗指垃圾回收器耗时与系统运行总时间的比值。</p></li><li><p><strong>停顿时间</strong>：指垃圾回收器运行时，系统停顿的时间。</p></li><li><p><strong>回收频率</strong>：指垃圾回收器多长时间会运行一次。一般来说，对于固定的应用而言，垃圾回收器的频率应该是越低越好。通常增大堆空间可以有效降低垃圾回收发生的频率，但是可能会增加回收产生的停顿时间。</p></li></ul><ul><li><strong>反应时间</strong>：当一个内存对象被标记为垃圾对象后到这个对象被真正回收产生的时间。</li></ul><p>根据这几个指标，我们可以知道，垃圾回收性能好的表现是：吞吐量高，垃圾回收消耗低，停顿时间少，回收频率低，反应时间快。但是，并没有这么完美的性能表现，这几个指标有些是互斥的，比如要降低回收频率，就要扩大空间，但是就会增加停顿时间；同样要想反应时间快，就必须要提高回收频率。所以，这些性能的追求就是一个博弈平衡的过程，我们可以根据我们追求的某一方面来进行调优，比如，对于客户端应用而言，应该尽可能降低其停顿时间，给用户良好的使用体验，为此，可以牺牲垃圾回收的吞吐量；对服务端程序来说，可能会更加关注吞吐量。</p><h2 id="三、垃圾回收器"><a href="#三、垃圾回收器" class="headerlink" title="三、垃圾回收器"></a>三、垃圾回收器</h2><h3 id="3-1-Serial-收集器"><a href="#3-1-Serial-收集器" class="headerlink" title="3.1 Serial 收集器"></a>3.1 Serial 收集器</h3><p>Serial 收集器是所有垃圾收集器中最古老的一种，也是JDK中最基本的垃圾收集器之一。Serial回收器主要有两个特点：第一：使用单线程进行垃圾回收；第二：独占式垃圾回收。</p><p>在串行收集器进行垃圾回收时，Java应用程序中的线程都需要暂停，等待垃圾回收完成。这种现象成为Stop-The-World。它将造成非常糟糕的用户体验，在实时性要求较高的应用场景中，这种现象往往是不能被接受的，但是它依然是在Client模式下默认的新生代收集器。在单核CPU环境下，由于没有线程间的切换，它甚至比并发收集器的性能都要好。（以下图片来源于网络）</p><p><img src="https://github.com/kinglaw1204/blogImage/blob/master/jvm-gc-02/Serial.png?raw=true" alt="图片来源于网络"></p><h3 id="3-2-ParNew-收集器"><a href="#3-2-ParNew-收集器" class="headerlink" title="3.2 ParNew 收集器"></a>3.2 ParNew 收集器</h3><p>ParNew 收集器是Serial 收集器的多线程版本。它的回收策略、算法以及参数和串行回收器一样。它是许多Server模式下新生代首选的收集器，除了他的多线程回收功能外，还有一点的就是只有他能与CMS收集器配合工作。开启ParNew 收集器可以使用以下参数：</p><p>-XX:+UseParNewGC：新生代使用并行收集器，老年代使用串行回收器。</p><p>-XX:+UseConcMarkSweepGC：新生代使用并行回收器，老年代使用CMS。</p><p>并行收集器工作时的线程数量可以使用 -XX:ParallelGCThreads 参数指定。一般最好与CPU数量相当，避免过多的线程数，影响垃圾收集性能。 在默认情况下，当CPU数量小于8个时，ParallelGCThreads 的值等于 CPU 数量；当 CPU 数量大于8个时，ParallelGCThreads 的值等于 3+[(5*CPU_Count)/8]</p><p><img src="https://github.com/kinglaw1204/blogImage/blob/master/jvm-gc-02/ParNew.png?raw=true" alt="图片来源于网络"></p><h3 id="3-3-Parallel-Scavenge-收集器"><a href="#3-3-Parallel-Scavenge-收集器" class="headerlink" title="3.3 Parallel Scavenge 收集器"></a>3.3 Parallel Scavenge 收集器</h3><p>Parallel Scavenge 收集器是新生代收集器，它是使用复制算法的收集器，同时也是多线程收集器。它和其他并发收集器不同的点是，Parallel Scavenge 收集器 关注吞吐量，其他的并行收集器关注的是降低停顿时间。<br>开启Parallel Scavenge 收集器可以使用以下参数：</p><p><code>-XX:+UseParallelGC</code>：新生代使用并行回收收集器，老年代使用串行回收器。</p><p><code>-XX:+UseParallelOldGC</code>：新生代与老年代都使用并行回收收集器。</p><p>并行回收收集器提供了两个重要的参数用于控制系统的吞吐量：</p><p><code>-XX:+MaxGCPauseMills</code>：设置最大垃圾收集停顿时间，它的值是一个大于 0 的整数。收集器在工作时会调整 Java 堆大小或者其他一些参数，尽可能地把停顿时间控制在 <code>MaxGCPauseMills</code> 以内。这里需要注意的是如果希望减少停顿时间，而把这个值设置得非常小，虚拟机为了达到预期的停顿时间，JVM 可能会使用一个较小的堆 (一个小堆比一个大堆回收快)，而这将导致垃圾回收变得很频繁，从而增加了垃圾回收总时间，降低了吞吐量。</p><p><code>-XX:+GCTimeRatio</code>：设置吞吐量大小，它的值是一个 0-100 之间的整数。假设 GCTimeRatio 的值为 n，那么系统将花费不超过 1/(1+n) 的时间用于垃圾收集。比如 GCTimeRatio 等于 19，则系统用于垃圾收集的时间不超过 1/(1+19)=5%。默认情况下，它的取值是 99，即不超过 1%的时间用于垃圾收集。</p><p>除此之外，Parallel Scavenge 收集器与ParNew 收集器另一个不同之处在于，前者支持一种自适应的 GC 调节策略，使用<code>-XX:+UseAdaptiveSizePolicy</code> 可以打开自适应 GC 策略。在这种模式下，新生代的大小、eden 和 survivor 的比例、晋升老年代的对象年龄等参数会被自动调整，以达到在堆大小、吞吐量和停顿时间之间的平衡点。在手工调优比较困难的场合，可以直接使用这种自适应的方式，仅指定虚拟机的最大堆、目标的吞吐量 (GCTimeRatio) 和停顿时间 (MaxGCPauseMills)，让虚拟机自己完成调优工作。</p><h3 id="3-4-Serial-Old-收集器"><a href="#3-4-Serial-Old-收集器" class="headerlink" title="3.4 Serial Old 收集器"></a>3.4 Serial Old 收集器</h3><p>Serial Old 收集器是Serial收集器的老年代版本，从名字我们就可以知道，它是一个单线程收集器，使用“标记-整理”算法。该虚拟机的主要使用场景是在Client模式下使用。它是CMS收集器的后备方案，当CMS收集器进行收集的时候，发生了<code>Concurrent Mode Failure</code>时，会触发使用Serial Old 收集器进行Full GC，此时会带来长时间的STW,进而影响系统响应，这也是CMS收集器的一个缺点。<br><img src="https://github.com/kinglaw1204/blogImage/blob/master/jvm-gc-02/Serial-Old.png?raw=true" alt="图片来源于网络"></p><h3 id="3-5-Parallel-Old-收集器"><a href="#3-5-Parallel-Old-收集器" class="headerlink" title="3.5 Parallel Old 收集器"></a>3.5 Parallel Old 收集器</h3><p>Parallel Old 收集器也是一种多线程并发的收集器。和Parallel Scavenge 收集器一样，它也是一种关注吞吐量的收集器。Parallel Old 收集器使用标记-压缩算法。<br><img src="https://github.com/kinglaw1204/blogImage/blob/master/jvm-gc-02/Parallel-Old.png?raw=true" alt="图片来源于网络"></p><h3 id="3-6-CMS-Concurrent-Mark-Sweep-收集器"><a href="#3-6-CMS-Concurrent-Mark-Sweep-收集器" class="headerlink" title="3.6 CMS(Concurrent Mark Sweep) 收集器"></a>3.6 CMS(Concurrent Mark Sweep) 收集器</h3><p>CMS 收集器是一个以获取最大回收停顿时间为目标的收集器，CMS垃圾回收的过程主要分为5步：初始标记、并发标记、重新标记、并发清除和并发重置。其中初始标记和重新标记是需要进行“Stop The World”，而并发标记、并发清除和并发重置是可以和用户线程一起执行的。因此，从整体上来说，CMS 收集不是独占式的，它可以在应用程序运行过程中进行垃圾回收<br>。CMS收集器也有三大缺点：</p><ul><li>对CPU资源比较敏感，在并发阶段，虽然不会导致用户线程停顿，但是还是会占用部分CPU资源，从而导致程序变慢，吞吐量下降。</li><li>CMS无法处理浮动垃圾，因为CMS进行垃圾收集是和用户线程一起运行的，所以在收集的过程中就会产生垃圾，这部分垃圾就被称为浮动垃圾，浮动垃圾只能等待下一次垃圾收集期间进行收集。因为垃圾收集过程与用户线程一起运行，所以收集过程中还是要预留空间给用户线程使用，如果空间不够，就会出现“Concurrent Mode Failure” 失败，接着就会出现备选方案的Serial Old收集器进行Full Gc，会进行长时间的停顿，进而影响性能。</li><li>CMS收集器是“标记-清除”算法的收集器，所以在垃圾收集过后会带来大量的内存碎片，CMS提供了一种内存压缩参数<code>+XX:+UseCMSCompactAtFullCollection</code>(默认是开启的)开启后CMS会在进行Full GC 的时候进行内存整理，<code>+XX:CMSFullGCsBeforeCompaction</code>可以设置执行多少次不压缩内存后再进行压缩的Full GC。</li></ul><p><img src="https://github.com/kinglaw1204/blogImage/blob/master/jvm-gc-02/cms.png?raw=true" alt="来源于网络"></p><h3 id="3-7-G1-Garbage-First-收集器"><a href="#3-7-G1-Garbage-First-收集器" class="headerlink" title="3.7 G1(Garbage-First) 收集器"></a>3.7 G1(Garbage-First) 收集器</h3><p>G1收集器是一款面向服务端的垃圾收集器，在jdk1.7后可以正式使用，可以通过命令<code>-XX:+UnlockExperimentalVMOptions –XX:+UseG1G</code>来启用G1收集器。G1收集器采用的是“标记-整理”算法，它也是一个进行可以预测停顿时间的垃圾收集器。可以通过参数设置停顿时间：</p><pre><code>-XX:MaxGCPauseMills = 20-XX:GCPauseIntervalMills = 200。</code></pre><p>以上参数指定在200ms内，停顿时间不超过20ms。这两个参数是G1回收器的目标，G1回收器并不保证能执行它们。<br>G1收集器的区域分布如下图所示：</p><p><img src="https://github.com/kinglaw1204/blogImage/blob/master/jvm-gc-02/g1.png?raw=true" alt="图片来源于网络"></p><p>在G1中把java堆分成了多个大小相等的独立区域（Region）,虽然保留了新生代和老年代的概念，但是他们都不是物理隔离的，只是逻辑上还有区分。</p><p>G1收集器进行垃圾收集分为4个阶段，初始标记，并发标记，最终标记，筛选回收。初始标记需要停顿用户线程，但是时间很短；并发标记是从GC Roots对堆中的对象进行可达性分析，这个阶段比较耗时，但是可以与用户线程并发执行；最终标记是修正在并发标记中产生的变动；筛选回收就是对标记好的垃圾对象进行价值和成本排序，根据用户设定的期望来进行回收（比如我们上面设置的200ms停顿时间不超过20ms）。</p><h3 id="3-8-ZGC-Z-Garbage-Collector-收集器"><a href="#3-8-ZGC-Z-Garbage-Collector-收集器" class="headerlink" title="3.8 ZGC(Z Garbage Collector) 收集器"></a>3.8 ZGC(Z Garbage Collector) 收集器</h3><p>ZGC 被称为“一个可伸缩低延迟的垃圾回收器”，这个垃圾回收器有什么神奇之处呢？它的主要特点就是能把回收时间控制在10ms以内，而且不受堆大小的影响，所以它可以支持TB级别的垃圾回收。</p><p>ZGC也是和G1收集器一样，并没有进行分代，而是把整个内存分成了多个region，官方后续会尝试采用分代的设计，目前完全因为是不分代这是最简单的设计。一次完整的 ZGC 回收周期分为以下几个阶段（Phase）：</p><ul><li><p><code>Pause Mark Start</code>：标记根对象；</p></li><li><p><code>Concurrent Mark</code>：并发标记阶段；</p></li><li><p><code>Concurrent Relocate</code>：并发重定位；</p></li></ul><ul><li><ul><li>活动对象被移动到了一个新的 <code>Heap Region</code> <code>B-region</code> 中，之前旧对象所在的 <code>Heap Region</code> <code>A-region</code> 即可复用；如果 <code>B-region</code> 中对象之间的引用关系将会在这一阶段被更新；</li></ul></li><li><ul><li>在重定位过程中，新旧对象的映射关系（同一对象在不同 <code>Region</code> 中的映射关系）被记录在了 <code>Forwarding Tables</code> 中。</li></ul></li></ul><ul><li><code>Pause Mark Start</code>：这个阶段实际上已经进入了新的 <code>ZGC Cycle</code>，同样也是标记根对象；</li></ul><ul><li><code>Concurrent Remap</code>：并发重映射。 这个阶段除了标记根对象直接引用的对象外，还会根据上个 <code>ZGC Cycle</code> 中生成的 <code>Forwarding Tables</code> 更新跨 <code>Heap Region</code> 的引用；</li></ul><p>ZGC还是有停顿的，在<code>Pause Mark Start</code> 阶段进行根对象扫描（<code>Root Scanning</code>）时会出现短暂的暂停。<br>流程示意图如下（图片来源于网络）</p><p><img src="https://github.com/kinglaw1204/blogImage/blob/master/jvm-gc-02/zgc.png?raw=true" alt=""></p><h2 id="四、一些JVM调优建议"><a href="#四、一些JVM调优建议" class="headerlink" title="四、一些JVM调优建议"></a>四、一些JVM调优建议</h2><h3 id="4-1将新对象预留在年轻代"><a href="#4-1将新对象预留在年轻代" class="headerlink" title="4.1将新对象预留在年轻代"></a>4.1将新对象预留在年轻代</h3><p>众所周知，由于 Full GC 的成本远远高于 Minor GC，因此某些情况下需要尽可能将对象分配在年轻代，这在很多情况下是一个明智的选择。虽然在大部分情况下，JVM 会尝试在 Eden 区分配对象，但是由于空间紧张等问题，很可能不得不将部分年轻对象提前向年老代压缩。因此，在 JVM 参数调优时可以为应用程序分配一个合理的年轻代空间，以最大限度避免新对象直接进入年老代的情况发生。这里实际上是为了避免“朝生夕灭”的大对象发生，尽可能的把设置合理新生代空间，把“朝生夕灭 ”对象留在新生代中。</p><h3 id="4-2-将大对象直接分配再老年代"><a href="#4-2-将大对象直接分配再老年代" class="headerlink" title="4.2 将大对象直接分配再老年代"></a>4.2 将大对象直接分配再老年代</h3><p>我们分配对象一般都是分配在年轻代，分配大对象在年轻代，需要年轻代提供足够的空间，这个时候会导致原有的大量小对象进入老年代，占用老年代空间。基于以上原因，可以将大对象直接分配到年老代，从而保留为年轻代保留了空间，保证了年轻代原有的目的，这样也可以提高 GC 的效率。如果一个大对象同时又是一个短命的对象，假设这种情况出现很频繁，那对于 GC 来说会是一场灾难。原本应该用于存放永久对象的年老代，被短命的对象塞满，这也意味着对堆空间进行了洗牌，扰乱了分代内存回收的基本思路。因此，在软件开发过程中，应该尽可能避免使用“朝生夕灭”这样短命的大对象。可以使用参数<code>-XX:PetenureSizeThreshold</code> 设置大对象直接进入年老代的阈值。当对象的大小超过这个值时，将直接在年老代分配。参数<code>-XX:PetenureSizeThreshold</code> 只对串行收集器和年轻代并行收集器有效，并行回收收集器不识别这个参数。</p><h3 id="4-3-设置对象进入老年代的年龄"><a href="#4-3-设置对象进入老年代的年龄" class="headerlink" title="4.3 设置对象进入老年代的年龄"></a>4.3 设置对象进入老年代的年龄</h3><p>堆中的每一个对象都有自己的年龄。一般情况下，年轻对象存放在年轻代，老年对象存放在老年代。为了做到这点，虚拟机为每个对象都维护一个年龄。如果对象在 Eden 区，经过一次 GC 后依然存活，则被移动到 Survivor 区中，对象年龄加 1。以后，如果对象每经过一次 GC 依然存活，则年龄再加 1。当对象年龄达到阈值时，就移入老年代，成为老年对象。那么设置一个合适的老年代的年龄就有利于提升系统性能，可以通过<code>-XX:MaxTenuringThreshold</code> 来设置，默认值是 15。虽然-XX:MaxTenuringThreshold 的值可能是 15 或者更大，但这不意味着新对象非要达到这个年龄才能进入老年代。如果在Survivor空间中相同年龄所有对象的大小总和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代。</p><h3 id="4-4-稳定的堆与震荡的堆"><a href="#4-4-稳定的堆与震荡的堆" class="headerlink" title="4.4 稳定的堆与震荡的堆"></a>4.4 稳定的堆与震荡的堆</h3><p>一般来说，稳定的堆大小对垃圾回收是有利的。获得一个稳定的堆大小的方法是使-Xms 和-Xmx 的大小一致，即最大堆和最小堆 (初始堆) 一样。如果这样设置，系统在运行时堆大小理论上是恒定的，稳定的堆空间可以减少 GC 的次数。因此，很多服务端应用都会将最大堆和最小堆设置为相同的数值。稳定的堆大小虽然可以减少 GC 次数，但同时也增加了每次 GC 的时间。让堆大小在一个区间中震荡，在系统不需要使用大内存时，压缩堆空间，使 GC 应对一个较小的堆，可以加快单次 GC 的速度。基于这样的考虑，JVM 还提供了两个参数用于压缩和扩展堆空间。</p><pre><code>XX:MinHeapFreeRatio: 设置堆的最小空闲比例，默认是40，当堆空间的空闲空间小于这个数值时，jvm会自动扩展空间。-XX：MaxHeapFreeRatio: 设置堆的最大空闲比例，默认是70，当堆空间的空闲空间大于这个数值时，jvm会自动压缩空间。当-Xmx 和-Xms 相等时，-XX:MinHeapFreeRatio 和-XX:MaxHeapFreeRatio 两个参数无效。</code></pre><h3 id="4-5-尝试使用大的内存分页"><a href="#4-5-尝试使用大的内存分页" class="headerlink" title="4.5 尝试使用大的内存分页"></a>4.5 尝试使用大的内存分页</h3><p>CPU 是通过寻址来访问内存的。32 位 CPU 的寻址宽度是 0~0xFFFFFFFF ，计算后得到的大小是 4G，也就是说可支持的物理内存最大是 4G。但在实践过程中，碰到了这样的问题，程序需要使用 4G 内存，而可用物理内存小于 4G，导致程序不得不降低内存占用。为了解决此类问题，现代 CPU 引入了 MMU（Memory Management Unit 内存管理单元）。MMU 的核心思想是利用虚拟地址替代物理地址，即 CPU 寻址时使用虚址，由 MMU 负责将虚址映射为物理地址。MMU 的引入，解决了对物理内存的限制，对程序来说，就像自己在使用 4G 内存一样。内存分页 (Paging) 是在使用 MMU 的基础上，提出的一种内存管理机制。它将虚拟地址和物理地址按固定大小（4K）分割成页 (page) 和页帧 (page frame)，并保证页与页帧的大小相同。这种机制，从数据结构上，保证了访问内存的高效，并使 OS 能支持非连续性的内存分配。在程序内存不够用时，还可以将不常用的物理内存页转移到其他存储设备上，比如磁盘，在windows下，这部分空间叫做虚拟内存，Linux下叫做SWAP分区。</p><p>在 Solaris 系统中，JVM 可以支持 Large Page Size 的使用。使用大的内存分页可以增强 CPU 的内存寻址能力，从而提升系统的性能。</p><pre><code>java –Xmx2506m –Xms2506m –Xmn1536m –Xss128k –XX:++UseParallelGC –XX:ParallelGCThreads=20 –XX:+UseParallelOldGC –XX:+LargePageSizeInBytes=256m–XX:+LargePageSizeInBytes：设置大页的大小。</code></pre><p>过大的内存分页会导致 JVM 在计算 Heap 内部分区（perm, new, old）内存占用比例时，会出现超出正常值的划分，最坏情况下某个区会多占用一个页的大小</p><h3 id="4-6-根据场景选择合适的收集器"><a href="#4-6-根据场景选择合适的收集器" class="headerlink" title="4.6 根据场景选择合适的收集器"></a>4.6 根据场景选择合适的收集器</h3><p>对于对响应时间不敏感的场景，可以选择吞吐量优先的收集器来提升性能，比如Parallel Old 收集器。如果是对响应时间要求高的场景，就需要选择低停顿的垃圾回收器，比如CMS,G1,ZGC（虽然目前还不是非常成熟）。</p><h2 id="五、总结"><a href="#五、总结" class="headerlink" title="五、总结"></a>五、总结</h2><p>这篇文章内容比较，主要分享了虚拟机的性能度量指标，垃圾回收器的分类，一些调优建议。最后放一张本文的脑图进行总结：</p><p><img src="https://github.com/kinglaw1204/blogImage/blob/master/jvm-gc-02/gc-summarize.png?raw=true" alt=""></p><h2 id="六、参考"><a href="#六、参考" class="headerlink" title="六、参考"></a>六、参考</h2><ul><li><a href="https://www.oracle.com/technetwork/java/javase/memorymanagement-whitepaper-150215.pdf" target="_blank" rel="noopener">Java内存管理白皮书</a></li><li>《深入理解jvm虚拟机 第二版》</li><li><a href="http://cr.openjdk.java.net/~pliden/slides/ZGC-FOSDEM-2018.pdf" target="_blank" rel="noopener">ZGC-FOSDEM-2018</a></li><li><a href="https://dinfuehr.github.io/blog/a-first-look-into-zgc/" target="_blank" rel="noopener">a-first-look-into-zgc</a></li><li><a href="https://www.cnblogs.com/yueshutong/p/9768298.html" target="_blank" rel="noopener">深入理解JAVA虚拟机（内存模型+GC算法+JVM调优）</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Jvm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>巴黎圣母院读后感</title>
      <link href="/2019/05/08/after-reading-notre-dame/"/>
      <url>/2019/05/08/after-reading-notre-dame/</url>
      
        <content type="html"><![CDATA[<p>无巧不成书吧！</p><p>其实自己有一份读书清单，而却鬼使神差般，先阅读了《巴黎圣母院》，这个阴雨连绵的春天，一边阅读着维克多.雨果的圣母院，却看到了今年四月份圣母院失火的新闻。</p><p>谈不上痛心疾首，实有一些遗憾又略感可惜的思绪萦绕在心头。</p><p>她因雨果的名著而后声名鹊起，游客络绎不绝。虽然我也不敢确定，我会不会有一天去到巴黎，一睹芳容。但总觉着历史名迹，存在几百年，闪发着自己的独一无二的光芒，为多少前人提供一个心灵的归属港湾，有多少人视她为精神寄托，精神支柱。她默默无闻付出着。</p><p>也许多年前，雨果失意时，她曾经给予过他安慰。也许……</p><p>她肯定有不少故事，也肯定有不少的故事在她这里发生过。</p><p>——纪念巴黎圣母院有感</p><p>言归正传，回到书中故事。一边鄙夷着爱斯梅拉达，一边可怜着她。谁又不是矛盾体呢？谁又是完美无缺的圣人呢？时常挂在嘴边严以律己，宽以待人。时时以此提醒自己，时时却反其道而行之。</p><p>看着她一心痴情于弗，上帝视角告诉我，这是个不配她爱的渣男，即使她真的认清他，又有什么用呢？能够立马抽身出来，就不爱了吗？未必吧，之所以为痴情，是明明了解，还自欺欺人，为对方想出一千个理由，不放手，在感情中自我折磨。</p><p>以爱之名的副教主，克洛德，人面兽心，道貌岸然的“君子”。好像这一时期的名著中，最不缺乏的就是这类人。很多名著中都有类似的，对此类人的暗讽，贬义。我想应该是太多打着高尚旗帜，实而做着见不得人的勾当的教主太多了，形成大多人都恶心的，甚至对此谈虎色变吧！一说到教主，就想到道貌岸然。不论是中国的，还是外国，不乏见到，清修之人实而是龌龊。</p><p>我想大部分人都是喜欢敲钟人卡西莫多的，外表丑陋，畸形；而实则善良，单纯。为吉卜赛姑娘不求回报的付出，终为其牺牲，步入万劫不复。我以为吉卜赛姑娘最终会感恩他，至少可以成为好朋友。看来我实在是小看人类以貌取人，这种根深蒂固的缺点。</p><p>当敲钟人为她拼尽所有，英勇奋战之时，她在克洛德的安排下出逃，居然都没想着大难临头，叫上他一起出逃。真叫人寒心。</p><p>也真不知道到底她到底是善良还是不善良。我想人之所以为人，是因为每个人都是多面的矛盾体吧！我想阅读一方面也是让自我直视人心，一方面引人深思，吾日三省吾身。</p><p>立夏之时，第一次阅读完本书，不知道是不是翻译者用词的原因，有些篇章于我而言有些冗长无味，有些措辞让我分分钟出戏。不管怎样，都很心怀感谢，感谢大师的创作，也感谢译者的翻译，让我有书可读，更是有好书！</p><p>窗外细雨蒙蒙，滋养大地；屋内细读名著，滋养心灵。</p>]]></content>
      
      
      <categories>
          
          <category> 读后感 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 巴黎圣母院 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java虚拟机垃圾回收相关知识点全梳理（上）</title>
      <link href="/2019/04/28/jvm-gc-01/"/>
      <url>/2019/04/28/jvm-gc-01/</url>
      
        <content type="html"><![CDATA[<h2 id="一、前言"><a href="#一、前言" class="headerlink" title="一、前言"></a>一、前言</h2><p>笔者最近在复习JVM的知识，本着记录分享的精神，整理下学习Java虚拟机垃圾回收相关知识点，由于整个垃圾回收内容比较多，我将整理成上下两篇文章去分享，上篇我会主要分享Java虚拟机的运行时数据区域划分，垃圾回收算法。下篇文章主要分享Java虚拟机的垃圾回收器以及一些虚拟机调优建议。</p><h2 id="二、运行时数据区"><a href="#二、运行时数据区" class="headerlink" title="二、运行时数据区"></a>二、运行时数据区</h2><p>Java虚拟机定义了程序在运行期间的多种数据区域，其中有些区域是在Java虚拟机创建的时候就创建了，只有在虚拟机退出后才会被销毁。根据Java虚拟机定义，我们可以数据区域做如下区分，分为：堆、Java虚拟机栈、程序计数器、方法区（元数据区、运行时常量池、本地方法栈。下面我们来详细介绍下每个区域的作用。</p><p><img src="https://github.com/kinglaw1204/blogImage/blob/master/Jvm-gc-01/runtime-area.png?raw=true" alt=""></p><h3 id="2-1-程序计数器"><a href="#2-1-程序计数器" class="headerlink" title="2.1 程序计数器"></a>2.1 程序计数器</h3><p>程序计数器是一块线程私有的区域，是一个较小的内存块，用来存放当前线程执行的字节码的指令地址，如果执行的是本地方法（Native),这个计数器就会为空（Undefined)。</p><h3 id="2-2-Java虚拟机栈"><a href="#2-2-Java虚拟机栈" class="headerlink" title="2.2 Java虚拟机栈"></a>2.2 Java虚拟机栈</h3><p>Java虚拟机栈是线程私有的区域，生命周期与线程相同，它存储的是栈帧（Stack Frame),栈帧会来存储局部变量表、操作数栈、动态链接、方法出口和返回地址等信息。每一个方法从调用到执行完成的过程，都对应着一个栈帧在虚拟机栈中入栈到出栈的过程。如果线程请求的栈深度大于虚拟机所允许的最大深度，就会抛出StackOverflowError异常；如果申请栈内存不够，也会导致抛出OutOfMemoryError异常。</p><pre><code>Jvm参数 -Xss:栈空间大小；栈的空间大小决定了栈能创建的深度</code></pre><p>栈结构如下：</p><p><img src="https://github.com/kinglaw1204/blogImage/blob/master/Jvm-gc-01/stack.png?raw=true" alt=""></p><h3 id="2-3本地方法栈"><a href="#2-3本地方法栈" class="headerlink" title="2.3本地方法栈"></a>2.3本地方法栈</h3><p>本地方法栈和java方法栈非常类似，他们之前的区别主要是Java方法栈是提供给字节码服务的，本地方法栈是给本地方法（C语言实现）调用服务的。Java虚拟机并没有对本地方法栈中使用的语言、数据结构等进行强制规定，所以虚拟机可以自行实现它。Sun HotSpot虚拟机把虚拟机栈和Java方法栈进行了合二为一。本地方法栈也会和虚拟机栈一样抛出StackOverFlowError和OutOfMemoryError异常。</p><h3 id="2-4-堆"><a href="#2-4-堆" class="headerlink" title="2.4 堆"></a>2.4 堆</h3><p>Java堆是一个所有线程共享的区域，堆用来存储几乎所有对象的实例和数组，堆按照分代的思想进行划分，可以划分了新生代（YoungGeneration)和老年代(Old/Tenured Generation)，新生代又可进一步细分为 eden、survivor space0（s0 或者 from space）和 survivor space1（s1或者to space）。我们用图来表示下堆的划分：</p><p><img src="https://github.com/kinglaw1204/blogImage/blob/master/Jvm-gc-01/heap.png?raw=true" alt=""></p><p>eden区：新建对象一般都放在该区域，除非是新建了大对象，该区域放不下就直接存放在老年代（Tenured)。<br>S0和S1区：该区域放置的对象至少经历了一次垃圾回收（Minor GC）,如果经历了多次回收，到达指定次数还存活，那么就会被转移到老年代。</p><p>Java虚拟机规范规定堆可以是物理上不连续的空间，只需要逻辑上连续即可，我们可以通过命令（-Xmx和-Xms ）来调整堆空间，如果申请的堆内存超过了堆的最大内存，将会抛出OutOfMemoryError异常。</p><pre><code>Jvm参数 -Xmx:最大堆空间大小 -Xms:最小堆空间大小 -Xmn:新生代空间大小</code></pre><h3 id="2-5-方法区（元数据区）"><a href="#2-5-方法区（元数据区）" class="headerlink" title="2.5 方法区（元数据区）"></a>2.5 方法区（元数据区）</h3><p>方法区是线程共享的区域，它用于存放已经被虚拟机加载的类信息、常量池、静态变量、即时编译器编译后的代码等数据。类信息包括类的完整名称、父类的完整名称、类型修饰符（public/protected/private）和类型的直接接口类表；常量池指运行时常量池（后面有介绍）；方法区又被称为非堆（Non-Heap)。</p><p>在Host Spot虚拟机的实现中，方法区也被称为永久区，是一块独立于 Java 堆的内存空间。虽然叫永久区，但是永久区中的对象同样可以被 GC 回收的（注：方法区是 JVM 的一种规范，永久区是一种具体实现，在 Java8 中，永久区已经被 Metaspace 元空间取而代之。相应的，<code>JVM参数 PermSize 和 MaxPermSize 被 MetaSpaceSize 和 MaxMetaSpaceSize 取代</code>）。对永久区 GC 的回收，通常主要从两个方面分析：一是 GC 对永久区常量池的回收；二是永久区对类元数据的回收。</p><p>当方法区无法满足内存分配需求时，将抛出OutOfMemoryError异常。</p><h3 id="2-5-1运行时常量池"><a href="#2-5-1运行时常量池" class="headerlink" title="2.5.1运行时常量池"></a>2.5.1运行时常量池</h3><p>运行时常量池（Run-Time Constant Pool）是方法区的一部分，它主要用来存放编译期生成的各种<a href="https://baike.baidu.com/item/%E5%AD%97%E9%9D%A2%E9%87%8F" target="_blank" rel="noopener">字面量</a>和符号引用，既然是运行时常量池，理所应当的可以存放运行时产生的常量，比如调用<code>String.intern()</code>方法产生的字符串常量就会被放入运行池常量中。</p><h2 id="三、垃圾判定算法"><a href="#三、垃圾判定算法" class="headerlink" title="三、垃圾判定算法"></a>三、垃圾判定算法</h2><h3 id="3-1-引用计数算法"><a href="#3-1-引用计数算法" class="headerlink" title="3.1 引用计数算法"></a>3.1 引用计数算法</h3><p>引用计数法的思想比较简单，每个对象都有一个引用计数器，只要对象被引用，计数器就+1，当对象不再被引用时候，计数器就减一。这种算法很高效，但是有一个致命缺点，就是有循环引用的问题。对于两个无用对象的互相引用，就会导致两个对象的计数器不为0，从而无法被判定为无用对象，无法回收内存。</p><h3 id="3-2-可达性分析算法"><a href="#3-2-可达性分析算法" class="headerlink" title="3.2 可达性分析算法"></a>3.2 可达性分析算法</h3><p>由于引用计数法有互相引用的缺陷，所以Java虚拟机采用了可达性分析算法来判定垃圾对象。这个算法的思想是，以一系列称为“GC Roots”的对象作为起始点，从这些起点往下搜索，搜索所走过的路径称为引用链（Referenc Chain),当一个对象到GC Roots没有任何引用链（从GC Roots到这个对象不可达）时，就说明这个对象不可用，可以被回收。</p><p>可以作为GC Roots的对象包括：</p><ul><li>虚拟机栈中引用的对象(局部变量)。</li><li>方法区中类静态属性引用的对象（静态变量）。</li><li>方法区中常量引用的对象（常量）。</li><li>本地方法栈中JNI(即本地方法)引用的对象。</li></ul><p><strong>那为什么上面四种对象就可以作为GC Roots呢？</strong></p><p>1.虚拟机栈中当前引用的对象，因为虚拟机栈中的对象是随着线程的生命周期存活的，那么在垃圾判断的时候，当前线程还存活，也就意味着栈中持有的对象肯定是存活的，所以可以作为GC Roots，本地方法栈也是一样的道理。</p><p>2.对于方法区中的静态变量引用和常量，我的理解是使用方法区中的对象作为GC Roots并不是一定就会以里面所有的对象作为GC Roots,虽然Java虚拟机并没有规定方法区要进行回收，但是该区域在目前的JVM实现中都有回收，由于方法区也会对“废弃常量”和“无用类”进行回收，所以选择GC Roots只会选择方法区内的有效对象。”废弃常量”判断比较简单，对于“无用类”的判断，Java虚拟机只会判断动态加载的类，对于原始加载的类，虚拟机永远不会自动卸载。所以判断动态加载的类为无用类可以有以下原则：</p><ul><li>该类所有的实例都已经被回收，堆中不存在该类的任何实例。</li><li>该类对于的类加载器已经被回收</li><li>该类对应的java.lang.Class对象没有在任何地方引用，无法通过反射访问该类的方法。<br><img src="https://github.com/kinglaw1204/blogImage/blob/master/Jvm-gc-01/gcroots.png?raw=true" alt=""></li></ul><h2 id="四、垃圾回收算法"><a href="#四、垃圾回收算法" class="headerlink" title="四、垃圾回收算法"></a>四、垃圾回收算法</h2><h3 id="4-1-标记-清除算法"><a href="#4-1-标记-清除算法" class="headerlink" title="4.1 标记-清除算法"></a>4.1 标记-清除算法</h3><p>标记-清除算法分为“标记”和“清除”两个阶段，首先需要标记出需要回收的对象，标记完成后再进行统一的垃圾回收。该算法有两个缺点：1.效率不高；2.清除后会产生大量不连续的内存碎片，内存碎片会导致分配大对象时候，无法找到足够的内存，从而提前触发一次GC.</p><p><img src="https://github.com/kinglaw1204/blogImage/blob/master/Jvm-gc-01/mark-clean.png?raw=true" alt=""></p><h3 id="4-2-复制算法"><a href="#4-2-复制算法" class="headerlink" title="4.2 复制算法"></a>4.2 复制算法</h3><p>上面的标记清除算法效率不高，为了解决这个问题，就有了复制算法，复制算法就是把内存容量划分为大小相等的两块，每次只用其中一块，当一块内存用完后就将存活的对象复制到另外一块内存上，然后再对原内存块进行清理。这种算法的优点就是内存分配不用考虑碎片的问题，只需要移动堆顶的内存指针，按顺序分配内存即可。但是这算法的缺点就是空间利用率不高，将内存缩小为原来的一半，有一半的内存没有被真正利用起来。</p><p>虽然内存利用率不高，但是目前的虚拟机中堆中的新生代就是采用这种算法进行垃圾回收的。上面我们提到新生代分为 eden 空间、form 空间和 to空间3个部分。其中 from 和 to 空间可以视为用于复制的两块大小相同、地位相等，且可进行角色互换的空间块。from 和 to 空间也称为 survivor 空间，即幸存者空间，用于存放未被回收的对象。</p><p>在垃圾回收时，eden空间中存活的对象会被复制到未使用的survivor空间中（假设是 to），正在使用的survivor空间（假设是 from）中的年轻对象也会被复制到to空间中（大对象或者老年对象会直接进入老年代，如果to空间已满，则对象也会进入老年代）。此时eden和from空间中剩余对象就是垃圾对象，直接清空，to空间则存放此次回收后存活下来的对象。</p><p><img src="https://github.com/kinglaw1204/blogImage/blob/master/Jvm-gc-01/copy-clean.png?raw=true" alt=""></p><h3 id="4-3-标记-压缩算法"><a href="#4-3-标记-压缩算法" class="headerlink" title="4.3 标记-压缩算法"></a>4.3 标记-压缩算法</h3><p>复制算法只适用于存活率较低的新生代中，如果存活率较高就需要进行过多的复制操作，效率将会降低。老年代的存活率比较高，所以复制算法不适用于老年代的场景，之前提到的“标记-清除”算法，如果不会产生内存碎片的话，还是可以满足老年代的，那么有没有不产生碎片的类似算法呢？答案是有，“标记-整理”算法就派上用处了。它的核心思想是：先对可回收对象进行标记，然后把所有存活的对象移动到一端，接着直接清理掉边界意外的内存区域。因为清理过后，存活对象都紧密的在一端，所以不会产生内存碎片。</p><p><img src="https://github.com/kinglaw1204/blogImage/blob/master/Jvm-gc-01/mark-zip.png?raw=true" alt=""></p><h2 id="八、总结"><a href="#八、总结" class="headerlink" title="八、总结"></a>八、总结</h2><p>本篇文章我整理了Java虚拟机的运行区划分，每个区域的作用，同时分享了垃圾判断算法和垃圾回收算法。运行时数据区划分为：程序计数器、Java虚拟机栈、本地方法栈、堆、方法区、运行时常量池。有的文章中提到Jdk1.7及以后的版本把运行时常量从方法区移除，这里我想说明下，Java虚拟机规范还是要求在方法区分配，这只是个别虚拟机的自己实现，比如说Hot Spot虚拟机。</p><p>垃圾判定算法现在虚拟机主要使用可达性分析算法，垃圾回收算法有“标记-清除”算法、“复制”算法、“标记-整理”算法。“复制”算法比较适合存活对象较少的新生代，“标记-整理”算法比较适合老年代，整理的作用就是为了有连续的内存空间，防止内存碎片太多无法存放大对象。</p><h2 id="九、参考"><a href="#九、参考" class="headerlink" title="九、参考"></a>九、参考</h2><ul><li><p>《深入理解jvm虚拟机 第二版》</p></li><li><p><a href="https://docs.oracle.com/javase/specs/jvms/se12/html/jvms-2.html" target="_blank" rel="noopener">Java虚拟机规范第12版</a></p></li><li><p><a href="http://mihaimoldovan.com/download/Inside-Java-Virtual-Machine.pdf" target="_blank" rel="noopener">《Inside Java Virtual Machine》</a></p></li></ul>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> jvm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>对于MySQL你必须要了解的锁知识</title>
      <link href="/2019/04/15/mysql-lock/"/>
      <url>/2019/04/15/mysql-lock/</url>
      
        <content type="html"><![CDATA[<h2 id="一、前言"><a href="#一、前言" class="headerlink" title="一、前言"></a>一、前言</h2><p>MySQL 的锁按照范围可以分为全局锁、表锁、行锁，其中行锁是由数据库引擎实现的，并不是所有的引擎都提供行锁，MyISAM 就不支持行锁，所以文章介绍行锁会以InnoDB引擎为例来介绍行锁。</p><h2 id="二、全局锁"><a href="#二、全局锁" class="headerlink" title="二、全局锁"></a>二、全局锁</h2><p>MySQL 提供全局锁来对整个数据库实例加锁。</p><p>语法：</p><pre><code>FLUSH TABLES WITH READ LOCK</code></pre><p>这条语句一般都是用来备份的，当执行这条语句后，数据库所有打开的表都会被关闭，并且使用全局读锁锁定数据库的所有表，同时，其他线程的更新语句（增删改），数据定义语句（建表，修改表结构）和更新类的事务提交都会被阻塞。</p><p>在mysql 8.0 以后，对于备份，mysql可以直接使用备份锁。</p><p>语句：</p><pre><code>LOCK INSTANCE FOR BACKUPUNLOCK INSTANCE</code></pre><p>这个锁的作用范围更广，这个锁会阻止文件的创建，重命名，删除，包括 <code>REPAIR TABLE TRUNCATE TABLE, OPTIMIZE TABLE</code>操作以及账户的管理都会被阻塞。当然这些操作对于内存临时表来说是可以执行的，为什么内存表不受这些限制呢？因为内存表不需要备份，所以也就没必要满足这些条件。</p><h2 id="三、表锁"><a href="#三、表锁" class="headerlink" title="三、表锁"></a>三、表锁</h2><p>Mysql的表级别锁分为两类，一类是元数据锁（Metadata Lock，MDL），一种是表锁。</p><p><strong>元数据锁(MDL)</strong> 不需要显式使用，在访问一个表的时候会被自动加上。这个特性需要MySQL5.5版本以上才会支持，当对一个表做增删改查的时候，该表会被加MDL读锁；当对表做结构变更的时候，加MDL写锁。MDL锁有一些规则：</p><ul><li>读锁之间不互斥，所以可以多线程多同一张表进行增删改查。</li><li>读写锁、写锁之间是互斥的，为了保证表结构变更的安全性，所以如果要多线程对同一个表加字段等表结构操作，就会变成串行化，需要进行锁等待。</li><li>MDL的写锁优先级比MDL读锁的优先级，但是可以设置max_write_lock_count系统变量来改变这种情况，当写锁请求超过这个变量设置的数后，MDL读锁的优先级会比MDL写锁的优先级高。（默认情况下，这个数字会很大，所以不用担心写锁的优先级下降）</li><li>MDL的锁释放必须要等到事务结束才会释放</li></ul><p>所以我们在操作数据库表结构时候必须要注意不要使用长事务，这里具体是什么意思呢？我举个例子说明下：</p><p><img src="!%5B%5D(https://user-gold-cdn.xitu.io/2019/4/13/16a15bcad254b77d?w=602&amp;h=553&amp;f=png&amp;s=16968" alt=""></p><p>上图表示演示了4个session执行语句，首先SessionA开启了事务没有提交，接着sessionB执行查询，因为是获取MDL读锁，所以互相不影响，可以正常执行，SessionC新增一个字段，由于MDL写和读是互斥的，所以SessionC会被阻塞，之后SessionD开始执行一个查询语句，由于SessionC的阻塞，所以SessionD也阻塞了。所以，我们模拟的SessionA的事务是长事务，然后后面执行了修改表结构，会导致后续对该表所有的读写操作都不可行了。所以在实际场景中，如果业务请求比较频繁的时候，对表结构进行修改的时候就有可能导致该库的线程被阻塞满。</p><p><strong>表锁</strong> 的语法如下：</p><pre><code>LOCK TABLES    tbl_name [[AS] alias] lock_type    [, tbl_name [[AS] alias] lock_type] ...lock_type: {    READ [LOCAL]  | [LOW_PRIORITY] WRITE}UNLOCK TABLES</code></pre><p><strong>表锁分为读锁和写锁</strong>，读锁不互斥，但是获取读锁不能写入数据,其他没有获取到读锁的session也是可以读取表的，所以读锁的目的就是限制表被写。如果表被读锁锁住后，再执行插入语句会报错，报错如下：</p><pre><code>1099 - Table &#39;XXXX&#39; was locked with a READ lock and can&#39;t be updated</code></pre><p><strong>写锁</strong>被获取后可以对表进行读写，写锁是互斥的，一旦某个session获取到表的写锁，另外的session无法访问这个表，直到写锁被释放。</p><p>表的解锁可以使用<code>unlock tables</code>解锁，也可以客户端口自动解锁。<code>lock tables</code>锁表会独占式的锁住表，除了限制其他线程对该表的读写，也会限制本线程接下来的操作对象。</p><h2 id="四、行锁-InnoDB"><a href="#四、行锁-InnoDB" class="headerlink" title="四、行锁(InnoDB)"></a>四、行锁(InnoDB)</h2><p>MySQL的行锁是在引擎层面实现的，所以这里讨论的也是InnoDB引擎下的行锁，下面会详细介绍InnoDB下常见的几种行锁</p><h3 id="4-1-共享锁"><a href="#4-1-共享锁" class="headerlink" title="4.1 共享锁"></a>4.1 共享锁</h3><p>共享锁能允许事务获取到锁后进行读操作，共享锁是不互斥的，一个事务获取到共享锁后，另外一个事务也可以获取共享锁，获取共享锁后不能进行写操作。</p><h3 id="4-2-排它锁"><a href="#4-2-排它锁" class="headerlink" title="4.2 排它锁"></a>4.2 排它锁</h3><p>排他锁允许事务获取到锁后进行更新一行或者删除某一行操作，排他锁顾名思义是互斥的，一个事务获取到排他锁后，其他事务不能获取到排他锁，直到这个锁被释放。</p><h3 id="4-3-意向锁"><a href="#4-3-意向锁" class="headerlink" title="4.3 意向锁"></a>4.3 意向锁</h3><p>InnoDB支持多种粒度的锁，允许行锁和表锁共存，这里说的<strong>意向锁其实是一种表级别的锁</strong>，但是我把它放在行锁里面是因为它不会单独存在，它的出现肯定会伴随着行锁（共享锁或者排他锁），它主要的目的就是表示将要锁定表中的行或者正在锁定表中的行。</p><p>意向锁根据和行锁的组合可以分为：</p><ul><li><p>意向排他锁：表明将要在表中的某些行获取排他锁</p></li><li><p>意向共享锁：表明将要在表中的某些行获取共享锁</p></li></ul><p>意向锁的获取必须在行锁获取之前，也就是说获取共享锁之前必须先要获取共享意向锁，对于排他锁也是一样的道理。</p><p><strong>那么这个意向锁到底有什么作用呢？</strong></p><p>解释这个之前，我们先看看意向锁和行锁之前的兼容关系：</p><table><thead><tr><th>—</th><th>排他锁（X）</th><th>意向排他锁（IX)</th><th>共享锁(S)</th><th>意向共享锁(IS)</th></tr></thead><tbody><tr><td>排他锁(X）</td><td>冲突</td><td>冲突</td><td>冲突</td><td>冲突</td></tr><tr><td>意向排他锁（IX)</td><td>冲突</td><td>兼容</td><td>冲突</td><td>兼容</td></tr><tr><td>共享锁(S)</td><td>冲突</td><td>冲突</td><td>兼容</td><td>兼容</td></tr><tr><td>意向共享锁(IS)</td><td>冲突</td><td>兼容</td><td>兼容</td><td>兼容</td></tr></tbody></table><p>我们假设有2个事务A和事务B，事务获取到了共享锁，锁住了表中的某一行，这一行只能读，不能写，现在事务B要申请整个表的写锁。如果事务B申请成功，那么肯定是可以对表中所有的行进行写操作的，那么肯定与A获取的行锁冲突。数据库为了避免这种冲突，就会进行冲突检测，那么如何去检测呢？有两种方式：</p><ul><li>判断表是否已经被其他事务用表级锁锁住。</li><li>判断表中的每一行是否被行锁锁住。</li></ul><p>判断表中的每一行需要遍历所有记录，效率太差，所以数据库就用第一种方式去做冲突检测，也就是用到了意向锁。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文主要从MySQL的加锁范围来分析了MySQL的锁，MySQL根据加锁范围可以分为全局锁、表锁、行锁。全局锁和表锁是MySQL自己实现，行锁都是由引擎层面去实现。InnoDB下的行锁主要分为共享锁和排他锁。共享锁请求后，行只能读，共享锁之间不互斥。排他锁获取后能更新和删除行，排他锁与其他锁都互斥。最后我在行锁的基础上提到了意向锁，意向锁主要表示正在锁住行或者即将锁住行，为了在锁冲突检测中提高效率。当然InnoDB下还有其他锁，比如间隙锁，记录锁，Next-Key锁等，这些都不在本文的探讨范围之内，如有兴趣的同学可以自行研究。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><p><a href="https://dev.mysql.com/doc/refman/5.7/en/innodb-locking.html" target="_blank" rel="noopener">MySQL用户手册之InnoDB锁</a></p></li><li><p><a href="https://dev.mysql.com/doc/refman/5.7/en/lock-tables.html" target="_blank" rel="noopener">MySQL用户手册之事务和锁</a></p></li><li><p>《MySQL实战45讲》</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>牛虻读后感</title>
      <link href="/2018/07/06/after-reading-niu-meng/"/>
      <url>/2018/07/06/after-reading-niu-meng/</url>
      
        <content type="html"><![CDATA[<p>其实，这是我第一次阅读牛虻，而且一直文盲地以为书名为《牛氓》。才疏学浅闹笑话。从小学就耳闻过世界名著牛虻，而先入为主的思想让我一直自以为是一本中国近代小说，更有些荒谬地认为是讲关于一个没有文化知识，目不识丁的农民的故事。</p><p>这种自以为是，来的莫名其妙。好像从我知道书名起就是这么认为的。人有时候的先入为主真的很荒唐。就像第一眼看见一个人，自己给对方设定了一个人物性格。可能这也是一种另类的缘分吧。</p><p>很庆幸自己翻开了这本著作，推翻了自己所有的自以为是，进一步证明以貌取人或以貌取书是不可取的，是非常狭隘的观点。</p><p>其实翻开这本书，很大的原因是，晓霞的那掏炭的男人。那场景久久不能挥之去，少平他窝在那张破乱不堪，蚊帐挂地乱七八糟的床上，拿着牛虻，如饥似渴地读着。而他经历了一天艰巨的劳作，整个背被石砖硌的淤紫；还挑灯夜读，不为功名，不为利禄。真喜欢少平这小子。所以他后来的进步我一点都不惊讶，那是必然的。</p><p>言归正传，我始终相信命。亚瑟决定背井离乡，隐姓埋名；这个决定，少了其中任何一个因素都不可能导致。如果说詹玛没有给那一耳光，或者生父之事没有爆发，都不会有后来的牛虻。</p><p>读了前言，我一直以为亚瑟后面变成了一个十恶不赦，彻头彻尾的牛虻；无恶不作，或者说笑面虎；然后他还是那个善良的亚瑟，看到奄奄一息的孩子，出手相救；快要伤到蒙太尼里时，宁可被捕，也不愿伤到红衣主教。虽然他语言犀利，甚至有人认为他尖酸刻薄。但是历经苦难，谁不需要伪装刺猬呢？当然，中国有句话叫做时势造英雄。当时的意大利的形式，更需要这样一个敢于叫醒装睡人的人，大多人都属于打打牙祭，不敢有大的作为。</p><p>我一直对牛虻的女郎念念不忘，这个真心真意爱过牛虻的女孩，后来，怎么样了呢？也许人生往往就是没有结局，没有后来，缘起而聚，缘尽而散，不可强求。</p><p>而我诧异于蒙太尼里的不知变通，虽然亚瑟逼着你选其一，但是你大可不必默认军事法庭。可能真的也是万般皆是命，半点不由人。不过我总觉得牺牲是不可避免的，总有人付出生命。革命必须有流血的代价。必须有这样的启示，人们才能自危，才能觉醒。然后牛虻的是决裂而伟大的。人固有一死，或轻于鸿毛或重于泰山。而牛虻的牺牲无疑是重于泰山的。</p>]]></content>
      
      
      <categories>
          
          <category> 读后感 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 牛虻 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
